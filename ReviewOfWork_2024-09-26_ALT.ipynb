{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a45f3f6",
   "metadata": {},
   "source": [
    "# 0️⃣ ReviewOfWork (Main Notebook) - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:20.608442900Z",
     "start_time": "2023-11-16T23:21:20.217442100Z"
    },
    "collapsed": true,
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "doc_output_parent_folder: /home/halechr/repos/Spike3D/EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation\n",
      "DAY_DATE_STR: 2024-09-26, DAY_DATE_TO_USE: 2024-09-26\n",
      "NOW_DATETIME: 2024-09-26_1213PM, NOW_DATETIME_TO_USE: 2024-09-26_1213PM\n",
      "global_data_root_parent_path changed to /media/halechr/MAX/Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49caf1de5cdd4da9bf2759aaa23b7ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Data Root:', layout=Layout(width='auto'), options=(PosixPath('/media/halechr/MAX/Data'), PosixPath('/home/halechr/FastData'), PosixPath('/home/halechr/cloud/turbo/Data')), style=ToggleButtonsStyle(button_width='max-content'), tooltip='global_data_root_parent_path', value=PosixPath('/media/halechr/MAX/Data'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "# %xmode Verbose\n",
    "# %xmode context\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "# !pip install viztracer\n",
    "%load_ext viztracer\n",
    "from viztracer import VizTracer\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "import importlib\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "from attrs import define, field, fields, Factory, make_class\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "import builtins\n",
    "\n",
    "import IPython\n",
    "from IPython.core.formatters import PlainTextFormatter\n",
    "from IPython import get_ipython\n",
    "\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "# Jupyter-lab enable printing for any line on its own (instead of just the last one in the cell)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# BEGIN PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "## IPython pprint\n",
    "from pyphocorehelpers.pprint import wide_pprint, wide_pprint_ipython, wide_pprint_jupyter, MAX_LINE_LENGTH\n",
    "# Override default pprint\n",
    "builtins.pprint = wide_pprint\n",
    "\n",
    "from pho_jupyter_preview_widget.display_helpers import array_repr_with_graphical_preview\n",
    "from pho_jupyter_preview_widget.ipython_helpers import PreviewWidgetMagics\n",
    "\n",
    "ip = get_ipython()\n",
    "\n",
    "# Register the magic\n",
    "ip.register_magics(PreviewWidgetMagics)\n",
    "\n",
    "\n",
    "# from pyphocorehelpers.ipython_helpers import MyMagics\n",
    "\n",
    "# %config_ndarray_preview width=500\n",
    "\n",
    "# Register the custom display function for NumPy arrays\n",
    "# ip.display_formatter.formatters['text/html'].for_type(np.ndarray, lambda arr: array_preview_with_graphical_shape_repr_html(arr))\n",
    "# ip = array_repr_with_graphical_shape(ip=ip)\n",
    "ip = array_repr_with_graphical_preview(ip=ip)\n",
    "# ip = dataframe_show_more_button(ip=ip)\n",
    "\n",
    "text_formatter: PlainTextFormatter = ip.display_formatter.formatters['text/plain']\n",
    "text_formatter.max_width = MAX_LINE_LENGTH\n",
    "text_formatter.for_type(object, wide_pprint_jupyter)\n",
    "\n",
    "\n",
    "# END PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "from pyphocorehelpers.print_helpers import get_now_time_str, get_now_day_str\n",
    "from pyphocorehelpers.indexing_helpers import get_dict_subset\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path, file_uri_from_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "import pyphocorehelpers.programming_helpers as programming_helpers\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns, parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies, paired_incremental_sorting\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, document_active_variables\n",
    "\n",
    "## Pho Programming Helpers:\n",
    "import inspect\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, TypePrintMode, print_keys_if_possible, debug_dump_object_member_shapes, print_value_overview_only, document_active_variables\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers, PythonDictionaryDefinitionFormat, MemoryManagement, inspect_callable_arguments, get_arguments_as_optional_dict, GeneratedClassDefinitionType, CodeConversion\n",
    "from pyphocorehelpers.notebook_helpers import NotebookCellExecutionLogger\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative, dict_to_full_array\n",
    "\n",
    "doc_output_parent_folder: Path = Path('EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation').resolve() # ../.\n",
    "print(f\"doc_output_parent_folder: {doc_output_parent_folder}\")\n",
    "assert doc_output_parent_folder.exists()\n",
    "\n",
    "_notebook_path:Path = Path(IPythonHelpers.try_find_notebook_filepath(IPython.extract_module_locals())).resolve() # Finds the path of THIS notebook\n",
    "# _notebook_execution_logger: NotebookCellExecutionLogger = NotebookCellExecutionLogger(notebook_path=_notebook_path, enable_logging_to_file=False) # Builds a logger that records info about this notebook\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_evaluate_required_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphocorehelpers.exception_helpers import ExceptionPrintingContext, CapturedException\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsResult, TrackTemplates, DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions,  RankOrderComputationsContainer, RankOrderResult, RankOrderAnalyses\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ComputationFunctionRegistryHolder import ComputationFunctionRegistryHolder, computation_precidence_specifying_function, global_function\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "from neuropy.utils.mixins.binning_helpers import transition_matrix\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import TransitionMatrixComputations\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "# %matplotlib inline\n",
    "# %matplotlib auto\n",
    "\n",
    "\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap, visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "# from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, render_colors\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "DAY_DATE_STR: str = date.today().strftime(\"%Y-%m-%d\")\n",
    "DAY_DATE_TO_USE = f'{DAY_DATE_STR}' # used for filenames throught the notebook\n",
    "print(f'DAY_DATE_STR: {DAY_DATE_STR}, DAY_DATE_TO_USE: {DAY_DATE_TO_USE}')\n",
    "\n",
    "NOW_DATETIME: str = get_now_rounded_time_str()\n",
    "NOW_DATETIME_TO_USE = f'{NOW_DATETIME}' # used for filenames throught the notebook\n",
    "print(f'NOW_DATETIME: {NOW_DATETIME}, NOW_DATETIME_TO_USE: {NOW_DATETIME_TO_USE}')\n",
    "\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import build_global_data_root_parent_path_selection_widget\n",
    "all_paths = [Path('/Volumes/SwapSSD/Data'), Path('/Users/pho/data'), Path(r'/media/halechr/MAX/Data'), Path(r'/home/halechr/FastData'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/Users/pho/cloud/turbo/Data')] # Path('/Volumes/FedoraSSD/FastData'), \n",
    "global_data_root_parent_path = None\n",
    "def on_user_update_path_selection(new_path: Path):\n",
    "    global global_data_root_parent_path\n",
    "    new_global_data_root_parent_path = new_path.resolve()\n",
    "    global_data_root_parent_path = new_global_data_root_parent_path\n",
    "    print(f'global_data_root_parent_path changed to {global_data_root_parent_path}')\n",
    "    assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "            \n",
    "global_data_root_parent_path_widget = build_global_data_root_parent_path_selection_widget(all_paths, on_user_update_path_selection)\n",
    "global_data_root_parent_path_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db844b",
   "metadata": {},
   "source": [
    "# 0️⃣ Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f07773d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir: /media/halechr/MAX/Data/KDIBA/gor01/two/2006-6-07_16-40-19\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-07_11-26-53')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # 2024-04-30 - Completely cleaned. 2024-07-15 DONE with custom replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # Working wcorr_shuffle and trial_by_trial - DONE, might be the BEST SESSION, good example session with lots of place cells, clean replays, and clear bar graphs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays ---- VERY weird effect of the replays, a sharp drop to strongly negative values more than 3/4 through the experiment.\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD, 2023-07-14, unsure why still.\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays! Interesting see-saw! #TODO 2024-07-05 23:07: - [ ] This was the one I processed\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE, Added replay selections. Very \"jumpy\" between the starts and ends of the track. 2024-07-10 DONE with custom replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # 2024-05-28 __ DEAD # 2024-01-10 new RANKORDER APOGEE | DONE, Added replay selections. A TON of putative replays in general, most bad, but some good. LOOKIN GOOD! 2024-07-10 DONE with custom replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='twolong_LR_pf1Dsession_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52') # DONE 2024-09-24\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15') # DONE 2024-09-24\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55') # DONE 2024-09-24\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13') # DONE 2024-09-24\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # BAD: Confirmed frequent jumping off of the track in this session. DONE, good. Many good pfs, many good replays. Noticed very strange jumping off the track in the 3D behavior/spikes viewer. Is there something wrong with this session?\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE, good?, replays selected, few  # BAD: Seems like in 3D view there's also jumping off of the track in this session.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE, very few replays\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3') ### KeyError: 'maze1_odd'\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5') ### \n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # NEWDONE, replays selected, quite a few replays but few are very good.\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25')\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# \n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21478b32",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [],
   "source": [
    "extended_computations_include_includelist=['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation',\n",
    "    'pf_dt_sequential_surprise',\n",
    "    'ratemap_peaks_prominence2d',\n",
    "    'extended_stats',\n",
    "    'long_short_decoding_analyses',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    # 'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'merged_directional_placefields',\n",
    "    'rank_order_shuffle_analysis',\n",
    "    'directional_train_test_split',\n",
    "    'directional_decoders_decode_continuous',\n",
    "    'directional_decoders_evaluate_epochs',\n",
    "    'directional_decoders_epoch_heuristic_scoring',\n",
    "    'perform_wcorr_shuffle_analysis',\n",
    "    'trial_by_trial_metrics',\n",
    "    'extended_pf_peak_information',\n",
    "] # do only specified\n",
    "force_recompute_override_computations_includelist = None\n",
    "# force_recompute_override_computations_includelist = ['merged_directional_placefields']\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis'] # , 'directional_decoders_decode_continuous'\n",
    "# force_recompute_override_computations_includelist = ['directional_decoders_decode_continuous'] # \n",
    "# force_recompute_override_computations_includelist = ['long_short_inst_spike_rate_groups','firing_rate_trends','extended_stats','long_short_decoding_analyses','jonathan_firing_rate_analysis','long_short_fr_indicies_analyses','long_short_post_decoding',]\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous'] # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70141a66",
   "metadata": {},
   "source": [
    "## 2024-06-25 - Load from saved custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679473aa",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# Loads custom pipeline pickles that were saved out via `custom_save_filepaths['pipeline_pkl'] = curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename=custom_save_filenames['pipeline_pkl'])`\n",
    "\n",
    "## INPUTS: global_data_root_parent_path, active_data_mode_name, basedir, saving_mode, force_reload, custom_save_filenames\n",
    "# custom_suffix: str = '_withNewKamranExportedReplays'\n",
    "\n",
    "# custom_suffix: str = '_withNewComputedReplays'\n",
    "custom_suffix: str = '_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0'\n",
    "\n",
    "\n",
    "custom_save_filenames = {\n",
    "    'pipeline_pkl':f'loadedSessPickle{custom_suffix}.pkl',\n",
    "    'global_computation_pkl':f\"global_computation_results{custom_suffix}.pkl\",\n",
    "    'pipeline_h5':f'pipeline{custom_suffix}.h5',\n",
    "}\n",
    "print(f'custom_save_filenames: {custom_save_filenames}')\n",
    "custom_save_filepaths = {k:v for k, v in custom_save_filenames.items()}\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# PIPELINE LOADING                                                                                                     #\n",
    "# ==================================================================================================================== #\n",
    "# load the custom saved outputs\n",
    "active_pickle_filename = custom_save_filenames['pipeline_pkl'] # 'loadedSessPickle_withParameters.pkl'\n",
    "print(f'active_pickle_filename: \"{active_pickle_filename}\"')\n",
    "# assert active_pickle_filename.exists()\n",
    "active_session_h5_filename = custom_save_filenames['pipeline_h5'] # 'pipeline_withParameters.h5'\n",
    "print(f'active_session_h5_filename: \"{active_session_h5_filename}\"')\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "## DO NOT allow recompute if the file doesn't exist!!\n",
    "# Computing loaded session pickle file results : \"W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle_withNewComputedReplays.pkl\"... done.\n",
    "# Failure loading W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle_withNewComputedReplays.pkl.\n",
    "proposed_load_pkl_path = basedir.joinpath(active_pickle_filename).resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: proposed_load_pkl_path\n",
    "assert proposed_load_pkl_path.exists(), f\"for a saved custom the file must exist!\"\n",
    "\n",
    "epoch_name_includelist=None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination', 'pf_computation','firing_rate_trends', 'position_decoding']\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True, active_pickle_filename=proposed_load_pkl_path) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        if saving_mode == PipelineSavingScheme.SKIP_SAVING:\n",
    "            print(f'WARNING: PipelineSavingScheme.SKIP_SAVING but need to save post_compute_validate changes!!')\n",
    "        else:\n",
    "            curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except BaseException as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "print(f'Pipeline loaded from custom pickle!!')\n",
    "## OUTPUT: curr_active_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88868964",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Global computations loading:                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "# Loads saved global computations that were saved out via: `custom_save_filepaths['global_computation_pkl'] = curr_active_pipeline.save_global_computation_results(override_global_pickle_filename=custom_save_filenames['global_computation_pkl'])`\n",
    "## INPUTS: custom_save_filenames\n",
    "## INPUTS: curr_active_pipeline, override_global_computation_results_pickle_path, extended_computations_include_includelist\n",
    "\n",
    "override_global_computation_results_pickle_path = None\n",
    "# override_global_computation_results_pickle_path = custom_save_filenames['global_computation_pkl']\n",
    "print(f'override_global_computation_results_pickle_path: \"{override_global_computation_results_pickle_path}\"')\n",
    "\n",
    "# Pre-load ___________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list\n",
    "\n",
    "# Try Unpickling Global Computations to update pipeline ______________________________________________________________ #\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # INPUTS: override_global_computation_results_pickle_path\n",
    "        sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(override_global_computation_results_pickle_path=override_global_computation_results_pickle_path,\n",
    "                                                                                        allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist, ) # is new\n",
    "        print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except BaseException as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "# Post-Load __________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "# Compute ____________________________________________________________________________________________________________ #\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# Post-compute _______________________________________________________________________________________________________ #\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98170b",
   "metadata": {},
   "source": [
    "## 0️⃣ Normal Pipeline Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8167df1c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loaded session pickle file results : \"/media/halechr/MAX/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl\"... build_logger(full_logger_string=\"2024-09-26_12-09-13.RDLU0039.kdiba.gor01.two.2006-6-07_16-40-19\", file_logging_dir: None):\n",
      "done.\n",
      "Loading pickled pipeline success: /media/halechr/MAX/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_train_test_split', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'perform_wcorr_shuffle_analysis', 'trial_by_trial_metrics', 'extended_pf_peak_information'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "Pre-load global computations: needs_computation_output_dict: ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'directional_train_test_split', 'trial_by_trial_metrics', 'long_short_decoding_analyses', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'wcorr_shuffle_analysis', 'extended_pf_peak_information', 'lap_direction_determination', 'ratemap_peaks_prominence2d', 'extended_stats', 'pfdt_computation', 'pf_dt_sequential_surprise']\n",
      "Computing loaded session pickle file results : \"/media/halechr/MAX/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/global_computation_results.pkl\"... done.\n",
      "sucessfully_updated_keys: ['DirectionalLaps', 'DirectionalMergedDecoders', 'RankOrder', 'DirectionalDecodersDecoded', 'DirectionalDecodersEpochsEvaluations', 'TrialByTrialActivity', 'long_short_leave_one_out_decoding_analysis', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analysis', 'jonathan_firing_rate_analysis', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap', 'SequenceBased']\n",
      "successfully_loaded_keys: ['DirectionalLaps', 'DirectionalMergedDecoders', 'RankOrder', 'DirectionalDecodersDecoded', 'DirectionalDecodersEpochsEvaluations', 'TrialByTrialActivity', 'long_short_leave_one_out_decoding_analysis', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analysis', 'jonathan_firing_rate_analysis', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap', 'SequenceBased']\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination', 'pf_computation',\n",
    "                                            #    'pfdt_computation',\n",
    "                                                'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise', \n",
    "                                            #    'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # 'position_decoding_two_step', \n",
    "                                            #    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                            #     'long_short_inst_spike_rate_groups',\n",
    "                                            #     'long_short_endcap_analysis',\n",
    "                                            # 'split_to_directional_laps',\n",
    "]\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=False) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # curr_active_pipeline.load_pickled_global_computation_results()\n",
    "        sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist) # is new\n",
    "        print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except BaseException as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcac55a8",
   "metadata": {
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_train_test_split', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'perform_wcorr_shuffle_analysis', 'trial_by_trial_metrics', 'extended_pf_peak_information'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "WARNING: FIXME TODO 2024-05-08 08:20: - [ ] Disabled checking for 'combined_best_direction_indicies', which is missing from both the laps and ripple dataframes after fresh computation for some reason.\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "Post-load global computations: needs_computation_output_dict: ['split_to_directional_laps', 'directional_train_test_split', 'wcorr_shuffle_analysis', 'extended_pf_peak_information', 'lap_direction_determination', 'ratemap_peaks_prominence2d', 'extended_stats', 'pfdt_computation', 'pf_dt_sequential_surprise']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9738b166",
   "metadata": {
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_train_test_split', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'perform_wcorr_shuffle_analysis', 'trial_by_trial_metrics', 'extended_pf_peak_information'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze_any\"\n",
      "`lap_direction_determination` missing.\n",
      "\t Recomputing `lap_direction_determination`...\n",
      "===>|> for filtered_session with filter named \"maze1_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_lap_direction_determination'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_lap_direction_determination at 0x7fc295633f70>\n",
      "WARN: Laps._compute_lap_dir_from_smoothed_velocity(...): the velocity-determined lap direction (\"is_LR_dir\") substantially differs from the previous (\"lap_dir\") column. This might be because it initially used simple ODD/EVEN determination for the direction.\n",
      "\tWARN: overwriting the \"lap_dir\" column of Laps with the \"is_LR_dir\" column. Do things need to be recomputed after this?\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "`ratemap_peaks_prominence2d` missing.\n",
      "\t Recomputing `ratemap_peaks_prominence2d`...\n",
      "===>|> for filtered_session with filter named \"maze1_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.8910038673692668\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:535: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = 6 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = {ybin_outer_extrema[1]} to matching_vertical_scan_y_idxs')\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:530: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = -1 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = {ybin_outer_extrema[0]} to matching_vertical_scan_y_idxs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.891\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:535: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = 6 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = {ybin_outer_extrema[1]} to matching_vertical_scan_y_idxs')\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:524: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:530: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = -1 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = {ybin_outer_extrema[0]} to matching_vertical_scan_y_idxs')\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:543: UserWarning: \tWARNING: peak_y_bin_idx (0) == ybin_indicies[0] (0): setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: peak_y_bin_idx ({peak_y_bin_idx}) == ybin_indicies[0] ({ybin_indicies[0]}): setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.8910023340225576\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:530: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = -1 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing lower extrema, adding ybin_outer_extrema[0] = {ybin_outer_extrema[0]} to matching_vertical_scan_y_idxs')\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:535: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = 6 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = {ybin_outer_extrema[1]} to matching_vertical_scan_y_idxs')\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:543: UserWarning: \tWARNING: peak_y_bin_idx (0) == ybin_indicies[0] (0): setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: peak_y_bin_idx ({peak_y_bin_idx}) == ybin_indicies[0] ({ybin_indicies[0]}): setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:524: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:535: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = 6 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = {ybin_outer_extrema[1]} to matching_vertical_scan_y_idxs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:535: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = 6 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = {ybin_outer_extrema[1]} to matching_vertical_scan_y_idxs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.8920268037179523\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.4955704465099735\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.8910003391088342\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.8954385439553483\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.49746585775297125\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:524: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:535: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = 6 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = {ybin_outer_extrema[1]} to matching_vertical_scan_y_idxs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:524: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:535: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = 6 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = {ybin_outer_extrema[1]} to matching_vertical_scan_y_idxs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.891\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.495\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:524: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:535: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = 6 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = {ybin_outer_extrema[1]} to matching_vertical_scan_y_idxs')\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:543: UserWarning: \tWARNING: peak_y_bin_idx (0) == ybin_indicies[0] (0): setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: peak_y_bin_idx ({peak_y_bin_idx}) == ybin_indicies[0] ({ybin_indicies[0]}): setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldDensityAnalysisComputationFunctions._perform_pf_find_ratemap_peaks_peak_prominence2d_computation at 0x7fc2955c2f70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.8911996409412434\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.8910023940432917\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.49500133002405095\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.891\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:422: UserWarning: n_contours is 0 for level: 0.495\n",
      "  warn( f\"n_contours is 0 for level: {levii}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:524: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = (-1, 6)\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 0: setting matching_vertical_scan_y_idxs = {ybin_outer_extrema}')\n",
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/PlacefieldDensityAnalysisComputationFunctions.py:535: UserWarning: \tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = 6 to matching_vertical_scan_y_idxs\n",
      "  warn(f'\\tWARNING: len(matching_vertical_scan_y_idxs) == 1: missing upper extrema, adding ybin_outer_extrema[1] = {ybin_outer_extrema[1]} to matching_vertical_scan_y_idxs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "`extended_stats` missing.\n",
      "\t Recomputing `extended_stats`...\n",
      "===>|> for filtered_session with filter named \"maze1_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_extended_statistics_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_extended_statistics_computation at 0x7fc2955ce670>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "`pfdt_computation` missing.\n",
      "\t Recomputing `pfdt_computation`...\n",
      "===>|> for filtered_session with filter named \"maze1_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_placefield_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function PlacefieldComputations._perform_time_dependent_placefield_computation at 0x7fc2955bcc10>\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "`pf_dt_sequential_surprise` missing.\n",
      "\t Recomputing `pf_dt_sequential_surprise`...\n",
      "===>|> for filtered_session with filter named \"maze1_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_pf_sequential_surprise_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_pf_sequential_surprise_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_pf_sequential_surprise_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_pf_sequential_surprise_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_pf_sequential_surprise_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_pf_sequential_surprise_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_pf_sequential_surprise_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_pf_sequential_surprise_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_time_dependent_pf_sequential_surprise_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function ExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation at 0x7fc2955ce790>\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "WARNING: FIXME TODO 2024-05-08 08:20: - [ ] Disabled checking for 'combined_best_direction_indicies', which is missing from both the laps and ripple dataframes after fresh computation for some reason.\n",
      "`directional_train_test_split` missing.\n",
      "\t Recomputing `directional_train_test_split`...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_split_train_test_laps_data'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._split_train_test_laps_data at 0x7fc292fb30d0>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DirectionalPlacefieldGlobalComputationFunctions._split_train_test_laps_data at 0x7fc09df60040>\n",
      "training_data_portion: 0.8333333333333334, test_data_portion: 0.16666666666666663\n",
      "training_data_portion: 0.8333333333333334, test_data_portion: 0.16666666666666663\n",
      "a_modern_name: long_LR, old_directional_lap_name: maze1_odd\n",
      "a_modern_name: long_RL, old_directional_lap_name: maze1_even\n",
      "a_modern_name: short_LR, old_directional_lap_name: maze2_odd\n",
      "a_modern_name: short_RL, old_directional_lap_name: maze2_even\n",
      "['long_LR_train', 'long_RL_train', 'short_LR_train', 'short_RL_train']\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "`wcorr_shuffle_analysis` missing.\n",
      "\t Recomputing `wcorr_shuffle_analysis`...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['perform_wcorr_shuffle_analysis'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function SequenceBasedComputationsGlobalComputationFunctions.perform_wcorr_shuffle_analysis at 0x7fc23e137a60>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function SequenceBasedComputationsGlobalComputationFunctions.perform_wcorr_shuffle_analysis at 0x7fc06b2af4c0>\n",
      "WARN: perform_wcorr_shuffle_analysis(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "perform_wcorr_shuffle_analysis(..., num_shuffles=1024)\n",
      "len(active_epochs_df): 718\n",
      "min_num_unique_aclu_inclusions: 10\n",
      "len(active_epochs_df): 520\n",
      "len(active_epochs_df): 718\n",
      "min_num_unique_aclu_inclusions: 10\n",
      "len(active_epochs_df): 520\n",
      "build_complete_all_scores_merged_df(...):\n",
      "needs Marginalized Probability columns. adding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_decoder_ripple_weighted_corr_arr: (515, 4)\n",
      "n_prev_completed_shuffles: 0.\n",
      "needed num_shuffles: 1024.\n",
      "need desired_new_num_shuffles: 1024 more shuffles.\n",
      "a_shuffle_IDXs: [24 22 25  0 18  8 31  3 32  2 26 39  7 43 19 29 36  9  5 40  1 30 21 42 44 34 12 20 37 35 38 23 45 16 10 14 13 27  6 15  4 28 41 11 33 17], a_shuffle_aclus: [35 33 39  3 27 15 46  7 48  6 40 55 12 63 28 44 52 17 10 56  5 45 32 62 64 50 20 31 53 51 54 34 65 25 18 23 21 41 11 24  8 43 60 19 49 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 36 39 30 42  1 12 23  2 20  6 18  5  4 29 45 17 34 33 24  0 10 44 38  8 43 35  9  3 21 28 11  7 41 14 37 40 15 26 19 31 22 27 13 16 32], a_shuffle_aclus: [39 52 55 45 62  5 20 34  6 31 11 27 10  8 44 65 26 50 49 35  3 18 64 54 15 63 51 17  7 32 43 19 12 60 23 53 56 24 40 28 46 33 41 21 25 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 41 17 43 33 10 29 23 30 37 36 13 15 14  5 34 38 26  8 32  6 21 19 12  0 24 11 27 22 28  7 45 42 18 39 44 31 25  2  9  1  4 16 40 20 35], a_shuffle_aclus: [ 7 60 26 63 49 18 44 34 45 53 52 21 24 23 10 50 54 40 15 48 11 32 28 20  3 35 19 41 33 43 12 65 62 27 55 64 46 39  6 17  5  8 25 56 31 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 44 23  0  7 40 42 11  6 35 37 34 17 15 26 18 16 29 33 28 13 19 22 24 10 27  8 31  9 20 25  3 39 43 36 14 12 32 41  5  4 30  1 45  2 38], a_shuffle_aclus: [32 64 34  3 12 56 62 19 11 51 53 50 26 24 40 27 25 44 49 43 21 28 33 35 18 41 15 46 17 31 39  7 55 63 52 23 20 48 60 10  8 45  5 65  6 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 19 41 44 13 38 10 27 29 42 23  8 14 21 26 34 32  7  9 11  4 20 30  0 31 18 40 28  3 17  2 22 45 36 33 39 24  5 12  1 37 15 16 25  6 43], a_shuffle_aclus: [51 28 60 64 21 54 18 41 44 62 34 15 23 32 40 50 48 12 17 19  8 31 45  3 46 27 56 43  7 26  6 33 65 52 49 55 35 10 20  5 53 24 25 39 11 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 35 42  1 11  8 40 19  5 22 26 23 10  7 17 24  2  4 44 38  9 31 43 32 14 13 30 21  0 37 27 15 12 28 45 34  6 36 16 25 39 20 41  3 18 33], a_shuffle_aclus: [44 51 62  5 19 15 56 28 10 33 40 34 18 12 26 35  6  8 64 54 17 46 63 48 23 21 45 32  3 53 41 24 20 43 65 50 11 52 25 39 55 31 60  7 27 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41  4 39 35 43 42  0  6 10 12 26 16 44 29 18 36 20 34  2 28 37  9 15  7 21 22 31 17  1 40 38 11 24 23 45 27  5 32 13 25 33  3 19 30  8 14], a_shuffle_aclus: [60  8 55 51 63 62  3 11 18 20 40 25 64 44 27 52 31 50  6 43 53 17 24 12 32 33 46 26  5 56 54 19 35 34 65 41 10 48 21 39 49  7 28 45 15 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 11 16  4  9 39 20 37  1 24 17 18 35 33 22 12 13 38 45 32 43 25  3 44 15 21 31 26 14  8 41 29 19  2 36  6 30 27 42 28  7 40 23  0 10 34], a_shuffle_aclus: [10 19 25  8 17 55 31 53  5 35 26 27 51 49 33 20 21 54 65 48 63 39  7 64 24 32 46 40 23 15 60 44 28  6 52 11 45 41 62 43 12 56 34  3 18 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 34 16 13 20 15 33 45 24  6  2 43  5 27 17 29 37 25  7 38 12 32 44 14  0 39 30  3 36  1  4 28  8 42 10 11 21 22 41 40 19  9 31 23 26 18], a_shuffle_aclus: [51 50 25 21 31 24 49 65 35 11  6 63 10 41 26 44 53 39 12 54 20 48 64 23  3 55 45  7 52  5  8 43 15 62 18 19 32 33 60 56 28 17 46 34 40 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18  4  7  5 29 38 12 11 30  0 14 25  3  2 35 43 42 44 36 39 31 20  8  6 45 32 27 17 33 22 37 34 16 40 24 21 13 23 41 26 28  9 15 19  1 10], a_shuffle_aclus: [27  8 12 10 44 54 20 19 45  3 23 39  7  6 51 63 62 64 52 55 46 31 15 11 65 48 41 26 49 33 53 50 25 56 35 32 21 34 60 40 43 17 24 28  5 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 43 31 17  2  7 45  5 26 11 21  0  8 28  9  4 10 27 44 20 12 38 39 25 35 34 33 40 37 23 24 15 14 32 19  6 18 36 42 13  1 41 30 22 16  3], a_shuffle_aclus: [44 63 46 26  6 12 65 10 40 19 32  3 15 43 17  8 18 41 64 31 20 54 55 39 51 50 49 56 53 34 35 24 23 48 28 11 27 52 62 21  5 60 45 33 25  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 28 38  1 25 16 20 26  8 10  5 32  4  2 31 23 14 45 13 30 22 39 11 33 18 21 42  3 15  0 19 24 43  6 17 36 40  7 34 41 35 37  9 44 27 12], a_shuffle_aclus: [44 43 54  5 39 25 31 40 15 18 10 48  8  6 46 34 23 65 21 45 33 55 19 49 27 32 62  7 24  3 28 35 63 11 26 52 56 12 50 60 51 53 17 64 41 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 16 43 42 21 14 15 17 37 27 40  5 22 45  9 38  0  2 11  4  8 19 10 20 23 12 41 33 28 29 26 39 44  7 36 25 31  1 18 24 32  3 34 30 35  6], a_shuffle_aclus: [21 25 63 62 32 23 24 26 53 41 56 10 33 65 17 54  3  6 19  8 15 28 18 31 34 20 60 49 43 44 40 55 64 12 52 39 46  5 27 35 48  7 50 45 51 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33 28 16 31  6 14  8 41 17 18 35  7 19 32 23 29 40 15  5 36  3 38 22 12 10 25 20  9 27 26  0  2 45 34 43 42 24  1 30 13 44  4 21 37 39 11], a_shuffle_aclus: [49 43 25 46 11 23 15 60 26 27 51 12 28 48 34 44 56 24 10 52  7 54 33 20 18 39 31 17 41 40  3  6 65 50 63 62 35  5 45 21 64  8 32 53 55 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 39 30 29 25 42 21 11 37 36 33  6 28 41 22 35 44  2  4 23 17 24 32 34  3 43 14  7 38 13 45  1 31 20 10  8 19 27 18 16 40  0  5 12 26 15], a_shuffle_aclus: [17 55 45 44 39 62 32 19 53 52 49 11 43 60 33 51 64  6  8 34 26 35 48 50  7 63 23 12 54 21 65  5 46 31 18 15 28 41 27 25 56  3 10 20 40 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38 12 11 17 25  1 26 29 40  6  2 14  8 30 33 15  0 31 28 37 34 27  7 44 23 18 32  3 45 13 10  4  9 20  5 35 24 43 41 16 19 42 22 36 21 39], a_shuffle_aclus: [54 20 19 26 39  5 40 44 56 11  6 23 15 45 49 24  3 46 43 53 50 41 12 64 34 27 48  7 65 21 18  8 17 31 10 51 35 63 60 25 28 62 33 52 32 55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30  0 41  1 13 29 12 21 38  8 43 24 18 20 45 19  2 42 22 28 44 14 15 25 11 31 26 36  9 17 27 34 40 35 33 39 10  4  6  7  5 23 37 16  3 32], a_shuffle_aclus: [45  3 60  5 21 44 20 32 54 15 63 35 27 31 65 28  6 62 33 43 64 23 24 39 19 46 40 52 17 26 41 50 56 51 49 55 18  8 11 12 10 34 53 25  7 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [22  2 27 31 14 23  7 11 30 36 17 29  6 16 18 38  0 26 42  3 13 44 32 12 39 19 41  8 43 25 35 10 45 33  4 40 37 15 21 28 24 34  5 20  1  9], a_shuffle_aclus: [33  6 41 46 23 34 12 19 45 52 26 44 11 25 27 54  3 40 62  7 21 64 48 20 55 28 60 15 63 39 51 18 65 49  8 56 53 24 32 43 35 50 10 31  5 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 19 27 11 21  7 33  2 37 34 23 32  8 41 15  0 44 42 25  5 12 30 45 18 26 14 39 31 10 35 38 16 13 17 28  3 20 40 22 24 36  1  9  6 43 29], a_shuffle_aclus: [ 8 28 41 19 32 12 49  6 53 50 34 48 15 60 24  3 64 62 39 10 20 45 65 27 40 23 55 46 18 51 54 25 21 26 43  7 31 56 33 35 52  5 17 11 63 44]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43  6 32 19 40 39  9 16  4 35 17 15 23 42 25 21  3  0 31 27 34 38 26 13 20 45 14  8  1 22  5 12 11  7 33 28  2 18 36 30 24 10 37 41 44 29], a_shuffle_aclus: [63 11 48 28 56 55 17 25  8 51 26 24 34 62 39 32  7  3 46 41 50 54 40 21 31 65 23 15  5 33 10 20 19 12 49 43  6 27 52 45 35 18 53 60 64 44]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 23 44 40  0 22 16 43  3  4 31 27 28 10 17 42 34 29 39  6  1 41 32 24 13 33  7 37 11 15  8 18 45  2 20 38 25 26 36  9 30 14 21 19  5 12], a_shuffle_aclus: [51 34 64 56  3 33 25 63  7  8 46 41 43 18 26 62 50 44 55 11  5 60 48 35 21 49 12 53 19 24 15 27 65  6 31 54 39 40 52 17 45 23 32 28 10 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 31  8 14 25  4 13 40 32 30 23 20  9 19 36 37  6 33 16 42 10 29 27 24  5 43 22 12  1 17  7 21 26  3 41 39 35  0 15 38  2 34 11 44 18 28], a_shuffle_aclus: [65 46 15 23 39  8 21 56 48 45 34 31 17 28 52 53 11 49 25 62 18 44 41 35 10 63 33 20  5 26 12 32 40  7 60 55 51  3 24 54  6 50 19 64 27 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 10 41 34 21  8 26  6 45 13  9 43 28 36 42 44 35 15 14  0 16 22 39 27 30 38 29  4 25 40  1 12  5 20 11 24 19 18 33 17 37  3 23  7 32 31], a_shuffle_aclus: [ 6 18 60 50 32 15 40 11 65 21 17 63 43 52 62 64 51 24 23  3 25 33 55 41 45 54 44  8 39 56  5 20 10 31 19 35 28 27 49 26 53  7 34 12 48 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 45 20 18 10 44  9 33 16 21 34 42 36  7 39 29 22  1 11 31 28 13 32 38 24 15 26 23 12  6 14 37  2 30  4 27 40 25 17 19  0 41 43  3  5  8], a_shuffle_aclus: [51 65 31 27 18 64 17 49 25 32 50 62 52 12 55 44 33  5 19 46 43 21 48 54 35 24 40 34 20 11 23 53  6 45  8 41 56 39 26 28  3 60 63  7 10 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 35  0 37 40 36 26 41 25  8 18 27 17 32 42  2 28 33 45 30 39 43 16 21  3 12  1 15 24 19 29  7 13 23  4 38 10  6 14 31 22  9 11 34 20  5], a_shuffle_aclus: [64 51  3 53 56 52 40 60 39 15 27 41 26 48 62  6 43 49 65 45 55 63 25 32  7 20  5 24 35 28 44 12 21 34  8 54 18 11 23 46 33 17 19 50 31 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 25  0 12  1 45  2 21  5 34  3 41 35 40 28 31  4 32 16 44 13 29 20 18 26 22  8 14 38 11 42  7 39 43 17 19 27 15 30 23 33 36  9 37 24 10], a_shuffle_aclus: [11 39  3 20  5 65  6 32 10 50  7 60 51 56 43 46  8 48 25 64 21 44 31 27 40 33 15 23 54 19 62 12 55 63 26 28 41 24 45 34 49 52 17 53 35 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 42 38  3 15  5 14 27  7 44 30 31 13 20  2 26 35  6 10 25 19 23  0 32 12 33  4 37 28 21 24 41 40 22 16 43 36 17 45 18 11 29 34 39  1  8], a_shuffle_aclus: [17 62 54  7 24 10 23 41 12 64 45 46 21 31  6 40 51 11 18 39 28 34  3 48 20 49  8 53 43 32 35 60 56 33 25 63 52 26 65 27 19 44 50 55  5 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 39 31 29 26  4 35 34 42 13 36 25 18 41 14 38  9 22 19 33 32 17 45 16  7  8  6 11 20  0 23  3 37  2  1  5 44 15 43 21 10 30 24 12 40 28], a_shuffle_aclus: [41 55 46 44 40  8 51 50 62 21 52 39 27 60 23 54 17 33 28 49 48 26 65 25 12 15 11 19 31  3 34  7 53  6  5 10 64 24 63 32 18 45 35 20 56 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19 18 16 36  2 32 41 26 25 43  3 34 12 20 44 30 33 37 15 42  8  1 28  9 21  4 10 29 24  0 38  5 11 23 27  7 22  6 39 17 45 40 13 31 35 14], a_shuffle_aclus: [28 27 25 52  6 48 60 40 39 63  7 50 20 31 64 45 49 53 24 62 15  5 43 17 32  8 18 44 35  3 54 10 19 34 41 12 33 11 55 26 65 56 21 46 51 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 27 16  1 30 17  8 43  0  2 44 22 45 40  9 28 19  6 18 23 13 15 32 38 21 24 10  7 37 39 42 25  3 20 29  4 31 14 26 34  5 41 12 11 33 35], a_shuffle_aclus: [52 41 25  5 45 26 15 63  3  6 64 33 65 56 17 43 28 11 27 34 21 24 48 54 32 35 18 12 53 55 62 39  7 31 44  8 46 23 40 50 10 60 20 19 49 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15 11 36 22 27  4 24 13  9 20  1 39 10 29  8 16 31 17 18 32  5  2 30 45 34 43 44 19 38 41 33 37  0 26  7  6  3 35 28 12 14 42 25 21 23 40], a_shuffle_aclus: [24 19 52 33 41  8 35 21 17 31  5 55 18 44 15 25 46 26 27 48 10  6 45 65 50 63 64 28 54 60 49 53  3 40 12 11  7 51 43 20 23 62 39 32 34 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 39  5 34 14 15 44  3 25 27 13 19  8 24  9 29  2 18 23 20 22 21 26 32 41  1 36 40 31 45  4 11  7  6 38 30 33 42 35 37 17 28 43 10 16 12], a_shuffle_aclus: [ 3 55 10 50 23 24 64  7 39 41 21 28 15 35 17 44  6 27 34 31 33 32 40 48 60  5 52 56 46 65  8 19 12 11 54 45 49 62 51 53 26 43 63 18 25 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 31 38 37 35 39  9 32 16 20 27 14 22 28 44 40 43  6  2  0 34 30 42 36 24 23 25 41  5  7 26 11 21  1 10 19 18  4 33 45 13 17 29 15  3  8], a_shuffle_aclus: [20 46 54 53 51 55 17 48 25 31 41 23 33 43 64 56 63 11  6  3 50 45 62 52 35 34 39 60 10 12 40 19 32  5 18 28 27  8 49 65 21 26 44 24  7 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 33 25 13 10 31 38  6  1 35 22 29 41 30 34  9 14 27  0 17 18 42 40 44 15 24 23  2 12 32 16 20 26 11 28 21 37 45 43  8 19  3 39  7  5  4], a_shuffle_aclus: [52 49 39 21 18 46 54 11  5 51 33 44 60 45 50 17 23 41  3 26 27 62 56 64 24 35 34  6 20 48 25 31 40 19 43 32 53 65 63 15 28  7 55 12 10  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1 25 39  5 42 22 33 15 23 31 27 10 34 28 44 18 26 30 36 16  2 41 14  8 32  0 29 45 24  4 38 43 19  7  6 20 13 17 12 35 11  9 21 40 37  3], a_shuffle_aclus: [ 5 39 55 10 62 33 49 24 34 46 41 18 50 43 64 27 40 45 52 25  6 60 23 15 48  3 44 65 35  8 54 63 28 12 11 31 21 26 20 51 19 17 32 56 53  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3  8  2 27 45 25  1 26 35 30 22 12 38  4 40 10 33 29 15 31 36  7 17 18 39 37 11 19 43 34 32  0 42 41  5 44 23 28 24  6 20  9 14 16 13 21], a_shuffle_aclus: [ 7 15  6 41 65 39  5 40 51 45 33 20 54  8 56 18 49 44 24 46 52 12 26 27 55 53 19 28 63 50 48  3 62 60 10 64 34 43 35 11 31 17 23 25 21 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40 38 45 35 22 24 44  5 20 19 13 16  8  0 33 28 34  1 32 10 26  9 11 21 30 14 29 25  6 12 39 15 37 43 18 42 23  7  4  3 41 31 27 36  2 17], a_shuffle_aclus: [56 54 65 51 33 35 64 10 31 28 21 25 15  3 49 43 50  5 48 18 40 17 19 32 45 23 44 39 11 20 55 24 53 63 27 62 34 12  8  7 60 46 41 52  6 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28  7 44 14  9 15 12 34 23 43 33 11  3 24 13 29 21 18 42  2 35  6 30  4 25 27  8 36 19 16 41  0 39 40 17 22 45 26 10 20 31 32  1 38  5 37], a_shuffle_aclus: [43 12 64 23 17 24 20 50 34 63 49 19  7 35 21 44 32 27 62  6 51 11 45  8 39 41 15 52 28 25 60  3 55 56 26 33 65 40 18 31 46 48  5 54 10 53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 16 30 10 33 32 18 13 29 14  9 44 39  3 24  7 42  4 22 43 31  2 11 19 45 17 41 21  1 12 35 23 36  8 26 34  5 27 20 40 38  0 15  6 28 25], a_shuffle_aclus: [53 25 45 18 49 48 27 21 44 23 17 64 55  7 35 12 62  8 33 63 46  6 19 28 65 26 60 32  5 20 51 34 52 15 40 50 10 41 31 56 54  3 24 11 43 39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 31 36  8 45 13 14 22 39 30 19  6  5 33 24 44 18  9 41 40 20 17 42 32 27 15  7 43 10 37  0  4 35 34 26  2 11 38 23 16 29 12 25 21  3  1], a_shuffle_aclus: [43 46 52 15 65 21 23 33 55 45 28 11 10 49 35 64 27 17 60 56 31 26 62 48 41 24 12 63 18 53  3  8 51 50 40  6 19 54 34 25 44 20 39 32  7  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 13 35 38 25 26  8 15 14 17 30 22 27  2 37 11  3 36 18 24  7  9 28  6 40 39 31 32  5  1 33 20 43 42 29 12 41 19 10  4  0 34 16 45 44 23], a_shuffle_aclus: [32 21 51 54 39 40 15 24 23 26 45 33 41  6 53 19  7 52 27 35 12 17 43 11 56 55 46 48 10  5 49 31 63 62 44 20 60 28 18  8  3 50 25 65 64 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 20 16 36 30 11 45 41 40 15 10 37 29  6  5  9 18  1 26  0 12 14 43 21 44 35 24 23 19 28  4 31 39  8 38  2 17 22 32 42  7 33 34 25 27 13], a_shuffle_aclus: [ 7 31 25 52 45 19 65 60 56 24 18 53 44 11 10 17 27  5 40  3 20 23 63 32 64 51 35 34 28 43  8 46 55 15 54  6 26 33 48 62 12 49 50 39 41 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 35 11  0  9 30 21 40 43 17 14  8 38  2 33 42 41 45 36  1 10 39 34 32 12  3  6 22 27 28 23 20 15  5 13 24 18 37  7 16 31  4 26 29 19 25], a_shuffle_aclus: [64 51 19  3 17 45 32 56 63 26 23 15 54  6 49 62 60 65 52  5 18 55 50 48 20  7 11 33 41 43 34 31 24 10 21 35 27 53 12 25 46  8 40 44 28 39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 14 42 34  4 18  8 20  2 23  9 39 10 15  3 27 13 21 12 35 38 44 11 40 29 16 33 43 24 25  6  5 41 36 37 31  7  1 26  0 19 22 32 17 30 28], a_shuffle_aclus: [65 23 62 50  8 27 15 31  6 34 17 55 18 24  7 41 21 32 20 51 54 64 19 56 44 25 49 63 35 39 11 10 60 52 53 46 12  5 40  3 28 33 48 26 45 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 30  4 20 17  5 28 16 21  0  3 24 23  9 12  7 36 35  2 14 41 26 18 31 29 45 42 34 32  6 38 10 15 40 13  1  8 37 33 25 19 11 22 27 44 43], a_shuffle_aclus: [55 45  8 31 26 10 43 25 32  3  7 35 34 17 20 12 52 51  6 23 60 40 27 46 44 65 62 50 48 11 54 18 24 56 21  5 15 53 49 39 28 19 33 41 64 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 32 19 14 39 35 18 34 36 17 45  2 28 38 16 26 22 29 21 41 24 31  3 23 33 10 40 42 37 43  1 20  5 11  4  0  6 25 30 15 44  9  7 27 12 13], a_shuffle_aclus: [15 48 28 23 55 51 27 50 52 26 65  6 43 54 25 40 33 44 32 60 35 46  7 34 49 18 56 62 53 63  5 31 10 19  8  3 11 39 45 24 64 17 12 41 20 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12  5 29  9 33 44 16  3 32 37 14  2 24 43 20 41 17 15 19 21  0  1 36 18 39  8 34 23 25 11 30 22 35 27 40 42  7  6 26 31 13 28 38 45  4 10], a_shuffle_aclus: [20 10 44 17 49 64 25  7 48 53 23  6 35 63 31 60 26 24 28 32  3  5 52 27 55 15 50 34 39 19 45 33 51 41 56 62 12 11 40 46 21 43 54 65  8 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12  4  3 31 33  1 20 10 26 25 27 17 21 30 19 41 32 13 14 40  6 39 24 23  5 16  8 11  0  9 45 43 15 37 35 22 34 38 28 36  2  7 18 44 29 42], a_shuffle_aclus: [20  8  7 46 49  5 31 18 40 39 41 26 32 45 28 60 48 21 23 56 11 55 35 34 10 25 15 19  3 17 65 63 24 53 51 33 50 54 43 52  6 12 27 64 44 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 27  3 13 16  1 34 10 17  8 30 11 40  7 37 20 25 36 21 32  4  0 26 29 39 41 24  5 23 28 15 44 38 14 12 33  2 35 43  9 45 18 31 22  6 19], a_shuffle_aclus: [62 41  7 21 25  5 50 18 26 15 45 19 56 12 53 31 39 52 32 48  8  3 40 44 55 60 35 10 34 43 24 64 54 23 20 49  6 51 63 17 65 27 46 33 11 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 24 15 19 18 20  3  2 35 37 31  6 42 32 40 14 17 45 34 16 12 27  1 26  9 11 33 30 39 23 43 36  0 10 28 41 38 13  8  7  4 29 21  5 25 22], a_shuffle_aclus: [64 35 24 28 27 31  7  6 51 53 46 11 62 48 56 23 26 65 50 25 20 41  5 40 17 19 49 45 55 34 63 52  3 18 43 60 54 21 15 12  8 44 32 10 39 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38 16 20  6  0 10 21 32 33  7 39 28 17 44  2 40  5 14 19  4 30 31 13 36 24 25 11  9 37 42 23 27 45 22  1 12  3 15 26  8 43 41 34 18 29 35], a_shuffle_aclus: [54 25 31 11  3 18 32 48 49 12 55 43 26 64  6 56 10 23 28  8 45 46 21 52 35 39 19 17 53 62 34 41 65 33  5 20  7 24 40 15 63 60 50 27 44 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 16 27 21 14 43 45 15 11  8 25 36 44 39 41 24  6 29 38 18  0 10 34  7  3  9 13 17 31 33  1 19  4 28 35 22 20 32  2  5 40 42 30 37 23 26], a_shuffle_aclus: [20 25 41 32 23 63 65 24 19 15 39 52 64 55 60 35 11 44 54 27  3 18 50 12  7 17 21 26 46 49  5 28  8 43 51 33 31 48  6 10 56 62 45 53 34 40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10  5 11 16 23 21  8 45  0  6 43 19 14  1  4 42 24  2 30 39 13 26 18 20  3 44 34 25 31 17 12 35 28 40 27 22 37 33 38 32  9 41 36 15 29  7], a_shuffle_aclus: [18 10 19 25 34 32 15 65  3 11 63 28 23  5  8 62 35  6 45 55 21 40 27 31  7 64 50 39 46 26 20 51 43 56 41 33 53 49 54 48 17 60 52 24 44 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 31 20 29 32  7  2 39 44 42 17 18 45 14  9 38 40 35 27 30  8 24 21 34 43  6 10  5  0  4 23 13 41 12  3 16 28 11 33 37 22  1 15 19 25 26], a_shuffle_aclus: [52 46 31 44 48 12  6 55 64 62 26 27 65 23 17 54 56 51 41 45 15 35 32 50 63 11 18 10  3  8 34 21 60 20  7 25 43 19 49 53 33  5 24 28 39 40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 23 17 22 28 41 35 42 39  2 34 21 37 29 33 36 24 15 32 20  9 13 18 40 14 16 19 26 44  4 25 38  5  8 11  6  1 43 10 27 31 12 45 30  0  7], a_shuffle_aclus: [ 7 34 26 33 43 60 51 62 55  6 50 32 53 44 49 52 35 24 48 31 17 21 27 56 23 25 28 40 64  8 39 54 10 15 19 11  5 63 18 41 46 20 65 45  3 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34  3 39 45 27 10 21 31 33 32 13 19 15 12 38 43 29 30 37 24 18  7 36 22 25  2 17 41 20 11  9  8  6  0 16 44 23 42  1 28 26 40  5 35 14  4], a_shuffle_aclus: [50  7 55 65 41 18 32 46 49 48 21 28 24 20 54 63 44 45 53 35 27 12 52 33 39  6 26 60 31 19 17 15 11  3 25 64 34 62  5 43 40 56 10 51 23  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 13 31 45 30 33 41  8 22  3 35 18  5  7  4 23 25 10 21  1 32 40 17 16  0 19 34 24 38 27 28 15 26 37 12 36 44  2  6 39  9 43 20 42 11 29], a_shuffle_aclus: [23 21 46 65 45 49 60 15 33  7 51 27 10 12  8 34 39 18 32  5 48 56 26 25  3 28 50 35 54 41 43 24 40 53 20 52 64  6 11 55 17 63 31 62 19 44]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 43 14 40  8 39 35 19  3  1 37 24  2  5 15 17 22 26 41  4  6 44 25 33 45 13  7 21 18  0 20 16  9 11 29 38 10 36 27 42 12 23 34 32 31 28], a_shuffle_aclus: [45 63 23 56 15 55 51 28  7  5 53 35  6 10 24 26 33 40 60  8 11 64 39 49 65 21 12 32 27  3 31 25 17 19 44 54 18 52 41 62 20 34 50 48 46 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 40  0 45 24 23 38 21 32 34 27 28 17 19 20 13 16  9 14  8 41  5  2 35 12  1  4 18  6 26 43  7 33 31 15 25 22 37 36 44  3 30 39 10 42 11], a_shuffle_aclus: [44 56  3 65 35 34 54 32 48 50 41 43 26 28 31 21 25 17 23 15 60 10  6 51 20  5  8 27 11 40 63 12 49 46 24 39 33 53 52 64  7 45 55 18 62 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 34  5 30 36 26 19 18 16 27  2  4 33 10 44 11 31  3 39 20 35  1 22 28  8 12 41 24 17  7 21 38 32  0  6  9 45 15 14 40 37 29 43 42 13 23], a_shuffle_aclus: [39 50 10 45 52 40 28 27 25 41  6  8 49 18 64 19 46  7 55 31 51  5 33 43 15 20 60 35 26 12 32 54 48  3 11 17 65 24 23 56 53 44 63 62 21 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 36 23 32 39  0  2 38 16  4 43 10 25 33 26  7  5 22 28 11 13 40 30 35  1  3 17 27 42  6 15 45 19 41 44 21  8 18 31 20 37 14 24  9 29 12], a_shuffle_aclus: [50 52 34 48 55  3  6 54 25  8 63 18 39 49 40 12 10 33 43 19 21 56 45 51  5  7 26 41 62 11 24 65 28 60 64 32 15 27 46 31 53 23 35 17 44 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 27  5  8 19 41 36 26 10 39 15  7 22 37 43  9  1 32 12  2 20 29 40 28 14 30 45 35 44  4 16 31 23 38 33 17  6 34  0 11 18 21 24 25 42 13], a_shuffle_aclus: [ 7 41 10 15 28 60 52 40 18 55 24 12 33 53 63 17  5 48 20  6 31 44 56 43 23 45 65 51 64  8 25 46 34 54 49 26 11 50  3 19 27 32 35 39 62 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 35 37 18 11 21 16 40 43 27 36 24  4 19 15  6 13 25  8  1 34 42  5 14 38 45  3 26 10 30 41 32 20  9 23 39 17 22 33 31  7 44 29 12 28  0], a_shuffle_aclus: [ 6 51 53 27 19 32 25 56 63 41 52 35  8 28 24 11 21 39 15  5 50 62 10 23 54 65  7 40 18 45 60 48 31 17 34 55 26 33 49 46 12 64 44 20 43  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37  2 28  0 20 14 11 23 18 24 36  7 21 27 10 34 38 29 32 15 33 41 17 31 39 16 40 35  8 25 44  3 22  5 12  4  9 19 45 26  1 43  6 42 30 13], a_shuffle_aclus: [53  6 43  3 31 23 19 34 27 35 52 12 32 41 18 50 54 44 48 24 49 60 26 46 55 25 56 51 15 39 64  7 33 10 20  8 17 28 65 40  5 63 11 62 45 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 45 44  4 30  5 19 22 39 26 25 27 36  9 38 15 35  8  6 21 20 17 37 28  0  2 13 14 43  1 34  3 42 24 33 16 11 18 23 31  7 32 41 12 10 40], a_shuffle_aclus: [44 65 64  8 45 10 28 33 55 40 39 41 52 17 54 24 51 15 11 32 31 26 53 43  3  6 21 23 63  5 50  7 62 35 49 25 19 27 34 46 12 48 60 20 18 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 41 17  8  7 40 23 45 24  0  6 13  3 42 32 16 21 20  4 14 36  5 31 44  9 38 26 35 27  1 11 39 43 12 34 10 22 19 15 25 33 30  2 29 28 18], a_shuffle_aclus: [53 60 26 15 12 56 34 65 35  3 11 21  7 62 48 25 32 31  8 23 52 10 46 64 17 54 40 51 41  5 19 55 63 20 50 18 33 28 24 39 49 45  6 44 43 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 17 26 13 15  7 23 18 24 27 37 40  4  3 39  2 31 38 32 10 29 35 34 45 21 19  9 41 22  6 42 28 33 16 43  0 11  1  8  5 20 25 44 12 30 14], a_shuffle_aclus: [52 26 40 21 24 12 34 27 35 41 53 56  8  7 55  6 46 54 48 18 44 51 50 65 32 28 17 60 33 11 62 43 49 25 63  3 19  5 15 10 31 39 64 20 45 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 11 24 39 38 28 25  2 12 10 19 20 30 13  9  8 43 26 36 31 34  7 23 16  3 41 44 27 22 18 21 45 40  4 17  0  5 42 32  6 37 15 14 33  1 35], a_shuffle_aclus: [44 19 35 55 54 43 39  6 20 18 28 31 45 21 17 15 63 40 52 46 50 12 34 25  7 60 64 41 33 27 32 65 56  8 26  3 10 62 48 11 53 24 23 49  5 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [31 38 37 22 33 39 27 29 30  8 43 21 25 36 34 17 40  7 23  4 15 44  6  2 24 13 32 12 10  3 41  1 35 20 28  5 14 42 18 26  0 16  9 11 19 45], a_shuffle_aclus: [46 54 53 33 49 55 41 44 45 15 63 32 39 52 50 26 56 12 34  8 24 64 11  6 35 21 48 20 18  7 60  5 51 31 43 10 23 62 27 40  3 25 17 19 28 65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 33 25 31 30 32 37 45 18  6 11  7 12 43 19 22 34  8 44 28 21 27 15 36 40 35  1 24 26 20 17 14  4 13  5  3 41 39  2 10  0 42 16 38 23  9], a_shuffle_aclus: [44 49 39 46 45 48 53 65 27 11 19 12 20 63 28 33 50 15 64 43 32 41 24 52 56 51  5 35 40 31 26 23  8 21 10  7 60 55  6 18  3 62 25 54 34 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 10 26 21 38 11  8 45 15  7 19 34 29 12  9  1 33 13 24  5 23 14 37 40 30 35 44 25 43 41  3 42 16 31 36 27 17 22 28 32 20  2  0 39 18  6], a_shuffle_aclus: [ 8 18 40 32 54 19 15 65 24 12 28 50 44 20 17  5 49 21 35 10 34 23 53 56 45 51 64 39 63 60  7 62 25 46 52 41 26 33 43 48 31  6  3 55 27 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2  1 24 31 27 14 16  5 35 44 34  8 39 22 42  7  4 18 38  9 28 26 17 43 29 32  0 36 12 15 20  3 30 37 41  6 19 40 10 13 25 45 11 33 23 21], a_shuffle_aclus: [ 6  5 35 46 41 23 25 10 51 64 50 15 55 33 62 12  8 27 54 17 43 40 26 63 44 48  3 52 20 24 31  7 45 53 60 11 28 56 18 21 39 65 19 49 34 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 28 39  9  1  2 23  3  6  0 34 14 41 20 42 26  5 35  8 12 25 17 10 15 37 40 45 38 11 33 16 29 22 43 24 30 13 32 31 21 18 19 44  4 36  7], a_shuffle_aclus: [41 43 55 17  5  6 34  7 11  3 50 23 60 31 62 40 10 51 15 20 39 26 18 24 53 56 65 54 19 49 25 44 33 63 35 45 21 48 46 32 27 28 64  8 52 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 38 20 30 39  4 44 32  2 14  0 15 35 23 41 12 33 45 25  6 13  8 40 43 27 10 21 42  9 34 11 22  7  1 18 29 24 36 26  5 28 16  3 17 31 19], a_shuffle_aclus: [53 54 31 45 55  8 64 48  6 23  3 24 51 34 60 20 49 65 39 11 21 15 56 63 41 18 32 62 17 50 19 33 12  5 27 44 35 52 40 10 43 25  7 26 46 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 40 11  0 32 36 26 42  3  7 15 27 23 17  5 24  1 39 13 31 22 38 34 12 25 30 43 20 18 19 10 35 14 41  6  8 21 45 29  9  4  2 33 28 16 37], a_shuffle_aclus: [64 56 19  3 48 52 40 62  7 12 24 41 34 26 10 35  5 55 21 46 33 54 50 20 39 45 63 31 27 28 18 51 23 60 11 15 32 65 44 17  8  6 49 43 25 53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23  3 29 20  4 22 28  6 44  9 42 26 39 25 17 12  5 40 38 27  8 36 33 14  7 10 34 30 13 43 32 15 37 41  2 24  1 21 19 18  0 45 31 11 35 16], a_shuffle_aclus: [34  7 44 31  8 33 43 11 64 17 62 40 55 39 26 20 10 56 54 41 15 52 49 23 12 18 50 45 21 63 48 24 53 60  6 35  5 32 28 27  3 65 46 19 51 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 31 29 25  4 19  9 28 41 21 22  7 35 43 26  0  3 37 45 14 11  2 38 42 36  5  8 30 10 17 40 12 20  1 44 34 15 27 33 23 24 32 13  6 39 16], a_shuffle_aclus: [27 46 44 39  8 28 17 43 60 32 33 12 51 63 40  3  7 53 65 23 19  6 54 62 52 10 15 45 18 26 56 20 31  5 64 50 24 41 49 34 35 48 21 11 55 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 21  4  5 39 33 36  1 18 16  3 27 14 45  6 22  7 40  0 26 44  9 15 12 42 28  2 23 43 34 41 29  8 17 24 13 11 32 20 30 19 38 25 31 10 35], a_shuffle_aclus: [53 32  8 10 55 49 52  5 27 25  7 41 23 65 11 33 12 56  3 40 64 17 24 20 62 43  6 34 63 50 60 44 15 26 35 21 19 48 31 45 28 54 39 46 18 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 24 22 26 30 38 15  8 12 34  4 35 36  9  0 16 37 23 19 21 32 33  3  2 11  5 27  6 20 45  1 17 40 18 10 31 43 44 42 28  7 13 14 29 41 25], a_shuffle_aclus: [55 35 33 40 45 54 24 15 20 50  8 51 52 17  3 25 53 34 28 32 48 49  7  6 19 10 41 11 31 65  5 26 56 27 18 46 63 64 62 43 12 21 23 44 60 39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41 19  8 36 27 14 18 39 29 40 24  5 34 12 28 44 22 25 33 21 30 10  4 11 15 31 13 23  3 45 32 37  9 43 20  0 17 26  6  7 38  1 35 16  2 42], a_shuffle_aclus: [60 28 15 52 41 23 27 55 44 56 35 10 50 20 43 64 33 39 49 32 45 18  8 19 24 46 21 34  7 65 48 53 17 63 31  3 26 40 11 12 54  5 51 25  6 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36  4  7  9 17 26 25 22  6 10 34 16 12 23 38 44 14 29 18  3 45 21 20 24 31 32 41  1 30  8  0 42 39 11 27  2 19 40 28 15 33 35 37 13 43  5], a_shuffle_aclus: [52  8 12 17 26 40 39 33 11 18 50 25 20 34 54 64 23 44 27  7 65 32 31 35 46 48 60  5 45 15  3 62 55 19 41  6 28 56 43 24 49 51 53 21 63 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 27 38 31 25 17  6  0 21 43 20 26  5  8 29  3 34 14 18 19 41  9 32 42 15 37 35 22 33 12 40 16 24  7 39  2 13 23 45 30  1 44 36 10  4 28], a_shuffle_aclus: [19 41 54 46 39 26 11  3 32 63 31 40 10 15 44  7 50 23 27 28 60 17 48 62 24 53 51 33 49 20 56 25 35 12 55  6 21 34 65 45  5 64 52 18  8 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 18 34 14 41 33 10  9 27 45 12 24 20 42  1 19  2 38  5 13 37 11 36 23 17  6 31 32 25 22 35  4  8 39  3 29 44  0 15 43  7 30 40 26 16 28], a_shuffle_aclus: [32 27 50 23 60 49 18 17 41 65 20 35 31 62  5 28  6 54 10 21 53 19 52 34 26 11 46 48 39 33 51  8 15 55  7 44 64  3 24 63 12 45 56 40 25 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 34  3 11 36  4 25 39 10 14 29 22 21 40  0  9 19 38 28  2 20 12 17 45 44 13 18 41 26  7 15  6  8 33  5 30 43 31 24 27 23  1 32 42 37 16], a_shuffle_aclus: [51 50  7 19 52  8 39 55 18 23 44 33 32 56  3 17 28 54 43  6 31 20 26 65 64 21 27 60 40 12 24 11 15 49 10 45 63 46 35 41 34  5 48 62 53 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 25  9  4 23 16 44  0 34 31 37 40  7 39 32 35 24  5 38 43 12  3 29 21 36 10 33  6 22 42  8 11 30 19 28 41 45 14 26 27  2  1 17 20 18 15], a_shuffle_aclus: [21 39 17  8 34 25 64  3 50 46 53 56 12 55 48 51 35 10 54 63 20  7 44 32 52 18 49 11 33 62 15 19 45 28 43 60 65 23 40 41  6  5 26 31 27 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20 28 12 29  1 22 26 13 37 21 44 34 30  2 25 10 23 35  7 14 18 38 15 17 19 43 24 36 27 42 31 45  3 33 11 39  5  9  8  6 16 40 41  4 32  0], a_shuffle_aclus: [31 43 20 44  5 33 40 21 53 32 64 50 45  6 39 18 34 51 12 23 27 54 24 26 28 63 35 52 41 62 46 65  7 49 19 55 10 17 15 11 25 56 60  8 48  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 45 18 39 30  6  4  7  2 38  9 12  1 10 14 27  5 44 43 41 24 37 26 16 23 22 17 28 33 35 11 32 42 34 25  8 15 20 13 29 36 19  0 21 40 31], a_shuffle_aclus: [ 7 65 27 55 45 11  8 12  6 54 17 20  5 18 23 41 10 64 63 60 35 53 40 25 34 33 26 43 49 51 19 48 62 50 39 15 24 31 21 44 52 28  3 32 56 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40  9 33 29 39 24 14  7 42  8 20 30  0 21 38 45 37 19 12 28 25 34 44 22 18 27 15 16  3  6 17 31  1 41 26 13 35  2  4  5 23 32 43 11 10 36], a_shuffle_aclus: [56 17 49 44 55 35 23 12 62 15 31 45  3 32 54 65 53 28 20 43 39 50 64 33 27 41 24 25  7 11 26 46  5 60 40 21 51  6  8 10 34 48 63 19 18 52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30  7 19  4 40 45  8 34 20 22 43  9 17  3 44 21 41 33 31 39 37 15 24  6 32  2 26 10 14 42 38 27 25 23 35 13  0 11 16 36 18 12  5 28 29  1], a_shuffle_aclus: [45 12 28  8 56 65 15 50 31 33 63 17 26  7 64 32 60 49 46 55 53 24 35 11 48  6 40 18 23 62 54 41 39 34 51 21  3 19 25 52 27 20 10 43 44  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 25 11 18 22 32 38 17  2 12 36 14  7 41 20 29 37 27  8  3 43 45 26 40 33 15 24  4 21 16  5 31  0 19  1 44 30 13 10 23 35 28 39 34  9 42], a_shuffle_aclus: [11 39 19 27 33 48 54 26  6 20 52 23 12 60 31 44 53 41 15  7 63 65 40 56 49 24 35  8 32 25 10 46  3 28  5 64 45 21 18 34 51 43 55 50 17 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [16 34 42  1  5 19  9  2 41 25 15  8  4 12 21  3 22 45 24 29 17 27 11 44 36 38 20 18 10 43 28 30 37 14 23 32 26 33  0  7 31 13 35 39 40  6], a_shuffle_aclus: [25 50 62  5 10 28 17  6 60 39 24 15  8 20 32  7 33 65 35 44 26 41 19 64 52 54 31 27 18 63 43 45 53 23 34 48 40 49  3 12 46 21 51 55 56 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [26 19  7 15 32 14 34 12  2 13 43 18 29 16 33 30  5  4  0 21  9  6 39 23 22 37 27  3 20 11 31 28 41 42 38  1 44 35 36  8 25 40 24 45 10 17], a_shuffle_aclus: [40 28 12 24 48 23 50 20  6 21 63 27 44 25 49 45 10  8  3 32 17 11 55 34 33 53 41  7 31 19 46 43 60 62 54  5 64 51 52 15 39 56 35 65 18 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 21 32 20  7 12 26 30  6 18 16 39 35 23 43 28 27 10 41  8  5 44  3  9 11 13  1 19 42  4 24 15 31 25 36 29 40  0  2 33 34 17 38 45 14 22], a_shuffle_aclus: [53 32 48 31 12 20 40 45 11 27 25 55 51 34 63 43 41 18 60 15 10 64  7 17 19 21  5 28 62  8 35 24 46 39 52 44 56  3  6 49 50 26 54 65 23 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 10 14 44 45 17 34 28  5 29  4 40 43  2  3 35  7 19 13 39 42  1 26 11  8 36 32 25 12 21 33 18 24 22 31 16 38 30  0  9  6 15 41 23 20 27], a_shuffle_aclus: [53 18 23 64 65 26 50 43 10 44  8 56 63  6  7 51 12 28 21 55 62  5 40 19 15 52 48 39 20 32 49 27 35 33 46 25 54 45  3 17 11 24 60 34 31 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 37 34  7 16 35  5  2  1 27  3 38 36 43 30 10 24 15 29 39 26 11 25 21 19 22 20 40 42 14  0 23  9 18 33 12 44  4 31 41 32  6  8 28 13 45], a_shuffle_aclus: [26 53 50 12 25 51 10  6  5 41  7 54 52 63 45 18 35 24 44 55 40 19 39 32 28 33 31 56 62 23  3 34 17 27 49 20 64  8 46 60 48 11 15 43 21 65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 42 44 34 37 32 19 18 30 29  5  7 41 25 45  2 17 28 43 16 38 15  3 24  4  6 39 27  0 36 20  1 23 10 21 14 13  8  9 26 33 40 11 35 31 22], a_shuffle_aclus: [20 62 64 50 53 48 28 27 45 44 10 12 60 39 65  6 26 43 63 25 54 24  7 35  8 11 55 41  3 52 31  5 34 18 32 23 21 15 17 40 49 56 19 51 46 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39  6 14 33  3 29 45 27 26 43 42 28 37 10 34 38 20 31 22 36 21  7 44  8 40 16 15 18  1 25 12 35 30  2  9 32 13 17 19  0 11 41  5 23  4 24], a_shuffle_aclus: [55 11 23 49  7 44 65 41 40 63 62 43 53 18 50 54 31 46 33 52 32 12 64 15 56 25 24 27  5 39 20 51 45  6 17 48 21 26 28  3 19 60 10 34  8 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 12 32 26  5 14 18 10  6  3  9 21 45 16 42 41 33  2 35 34 17 38 13 31  1 40 28 11 36  7  8 39 43 20  0 30  4 22 15 23 19 27 37 24 44 25], a_shuffle_aclus: [44 20 48 40 10 23 27 18 11  7 17 32 65 25 62 60 49  6 51 50 26 54 21 46  5 56 43 19 52 12 15 55 63 31  3 45  8 33 24 34 28 41 53 35 64 39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41  6 25 11 18 33 22 24 38 39 37 36 45 31 15  8 44 42 27 28  1 21 10 26 13 35 14 12 23 43  0 32 34 30  2  4 17  7 16  5  3  9 20 29 19 40], a_shuffle_aclus: [60 11 39 19 27 49 33 35 54 55 53 52 65 46 24 15 64 62 41 43  5 32 18 40 21 51 23 20 34 63  3 48 50 45  6  8 26 12 25 10  7 17 31 44 28 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 35  6 41 38 20 11 34  8 31  1 26 33  3 25  2 30 19 32  4 22 28 24 18 15 42 40  9  0 29 21 17 14 44 16 27 45 10 13 12  5  7 23 39 36 43], a_shuffle_aclus: [53 51 11 60 54 31 19 50 15 46  5 40 49  7 39  6 45 28 48  8 33 43 35 27 24 62 56 17  3 44 32 26 23 64 25 41 65 18 21 20 10 12 34 55 52 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 40 32  4 41 22  3  7 18 36 16  0 35 26 12 28 43 27 34  1 42 20  9  8 33 31  5 19  6  2 15 38 11 21 29 39 44 25 23 30 24 13 37 10 14 45], a_shuffle_aclus: [26 56 48  8 60 33  7 12 27 52 25  3 51 40 20 43 63 41 50  5 62 31 17 15 49 46 10 28 11  6 24 54 19 32 44 55 64 39 34 45 35 21 53 18 23 65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 39 22 21 43  4  5 11 28 17 13 25 33 19  1 36 24 32 12  0 20 41 18  7 42 35 44 27  2 10  8 40 31 34 37 26 15  3 30 23 45 14 16 29  9 38], a_shuffle_aclus: [11 55 33 32 63  8 10 19 43 26 21 39 49 28  5 52 35 48 20  3 31 60 27 12 62 51 64 41  6 18 15 56 46 50 53 40 24  7 45 34 65 23 25 44 17 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 40 44 16 43 37 30  8 11 19 25 17 12 10  4 24 41 31  1  9 26 35  5 15 32 13  6 29 45 20 28 21  0  3  7 14 42 36 38 34 18 22 27 39  2 33], a_shuffle_aclus: [34 56 64 25 63 53 45 15 19 28 39 26 20 18  8 35 60 46  5 17 40 51 10 24 48 21 11 44 65 31 43 32  3  7 12 23 62 52 54 50 27 33 41 55  6 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 33 13 10 19 36  4 28 43 42  2 16 31 41 22 45  6  5 24  1 44 21 27  7 26 40 20 32 18 11 15 12  9 37 29 14  8 35 38 30  3 25 23 34 17  0], a_shuffle_aclus: [55 49 21 18 28 52  8 43 63 62  6 25 46 60 33 65 11 10 35  5 64 32 41 12 40 56 31 48 27 19 24 20 17 53 44 23 15 51 54 45  7 39 34 50 26  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 12 33 19  3 11 35  5  1  6 10  2 39 20 27 31 37 44 38 18 23  9 25  8 43 41 40 29 36 28 26 42 45  7 30 14  4 22 17 32 15 34 16  0 24 13], a_shuffle_aclus: [32 20 49 28  7 19 51 10  5 11 18  6 55 31 41 46 53 64 54 27 34 17 39 15 63 60 56 44 52 43 40 62 65 12 45 23  8 33 26 48 24 50 25  3 35 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 42  0 25 38 21 22 41  3 45 20 28 15 26 29 11 33  6 37  4 18 10 35 40  1 36 12 31 39 30 32 43  5 13 23 44 14  9 34 24 19 17  7  8  2 16], a_shuffle_aclus: [41 62  3 39 54 32 33 60  7 65 31 43 24 40 44 19 49 11 53  8 27 18 51 56  5 52 20 46 55 45 48 63 10 21 34 64 23 17 50 35 28 26 12 15  6 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43  1 28 38 10 16 18 44 41 45 40 23 20 30  0 12 15 11  9 37  6  5 42 25 34 14 22  7 27  4  3 19 17 31 33 32 26 29 21 39 35 13 36  8 24  2], a_shuffle_aclus: [63  5 43 54 18 25 27 64 60 65 56 34 31 45  3 20 24 19 17 53 11 10 62 39 50 23 33 12 41  8  7 28 26 46 49 48 40 44 32 55 51 21 52 15 35  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 40  2  8  4 13 17  7  5 25 38 30 41  6 28 22 19  1 39 43 21 29 10 11 23 20 14 37 32  0 35 24 42  9 31 34 44 18 16 33 45 15 12 36 26 27], a_shuffle_aclus: [ 7 56  6 15  8 21 26 12 10 39 54 45 60 11 43 33 28  5 55 63 32 44 18 19 34 31 23 53 48  3 51 35 62 17 46 50 64 27 25 49 65 24 20 52 40 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [16  4 12 44 14  9 23 28 32 33 15 27 30 42 11 45 37 18 17 35 20 26 40 38  0 39 43 13 19 25  6 31 34  5 29  7 41 24  1 36 21  8 10  2 22  3], a_shuffle_aclus: [25  8 20 64 23 17 34 43 48 49 24 41 45 62 19 65 53 27 26 51 31 40 56 54  3 55 63 21 28 39 11 46 50 10 44 12 60 35  5 52 32 15 18  6 33  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 31  6 25  2 37 41 27  5 34 19  8 22 18  1  7 32 29 39 13 45 43 20 38 10 16 26  3  0 28 40 33 36 14 23 17 30  9 42 24 11 44 15  4 35 12], a_shuffle_aclus: [32 46 11 39  6 53 60 41 10 50 28 15 33 27  5 12 48 44 55 21 65 63 31 54 18 25 40  7  3 43 56 49 52 23 34 26 45 17 62 35 19 64 24  8 51 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 42 34  3 22 14 28  2 21  8 36 39 38 13  0 32 40 41 24 27 15 18 43 26 10 25 16  9  5 19 17 30 33 31 35 20 23  1 37  4 44 12  7  6 11 45], a_shuffle_aclus: [44 62 50  7 33 23 43  6 32 15 52 55 54 21  3 48 56 60 35 41 24 27 63 40 18 39 25 17 10 28 26 45 49 46 51 31 34  5 53  8 64 20 12 11 19 65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 38  8 35 40 18 33  5 43  7  2 32 28  3 31 30  0 22 39 24 26 41  9 13 21 27 16  1 19 34 11 37 42 36 23 15 45 25 20 10 14  4 12 29  6 44], a_shuffle_aclus: [26 54 15 51 56 27 49 10 63 12  6 48 43  7 46 45  3 33 55 35 40 60 17 21 32 41 25  5 28 50 19 53 62 52 34 24 65 39 31 18 23  8 20 44 11 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 25 20  2 39 27 15 31  1 40 21  6  7 10 19 14 16 28 38 43 24 29 35 22  9  0  8 34 23 17  4 18 30 44 42 12 32 45  5 11 33  3 26 36 37 41], a_shuffle_aclus: [21 39 31  6 55 41 24 46  5 56 32 11 12 18 28 23 25 43 54 63 35 44 51 33 17  3 15 50 34 26  8 27 45 64 62 20 48 65 10 19 49  7 40 52 53 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41 11  0 38 17 14 30 16 24 19  4  1 31 36 45 27 22 34 43 10 44 13  7 21 40  9  3  8 37 35 15  2 42 29 12  5 25 33 32 23 20 39 26  6 28 18], a_shuffle_aclus: [60 19  3 54 26 23 45 25 35 28  8  5 46 52 65 41 33 50 63 18 64 21 12 32 56 17  7 15 53 51 24  6 62 44 20 10 39 49 48 34 31 55 40 11 43 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 17 31 27 18  6 34 43 39 26  2 38  9  7 12 44 16 25 28 11 40 20  0 37 41 21 22 15  4 24 32  1 36 33  5 35 14 45  3 30 42  8 29 19 13 23], a_shuffle_aclus: [18 26 46 41 27 11 50 63 55 40  6 54 17 12 20 64 25 39 43 19 56 31  3 53 60 32 33 24  8 35 48  5 52 49 10 51 23 65  7 45 62 15 44 28 21 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 31 36 22 38 40 34 43 32 39 21  6 20  8 15 30 13 28 27 17 33 25 42 14  0 26 10  7 41 16  3 35 23  4 24 29  1 45 18 12  9 19 11 44 37  5], a_shuffle_aclus: [ 6 46 52 33 54 56 50 63 48 55 32 11 31 15 24 45 21 43 41 26 49 39 62 23  3 40 18 12 60 25  7 51 34  8 35 44  5 65 27 20 17 28 19 64 53 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 19 37 13  5 10 22 41 38  3 15 16  2 25 11 18  6 21  1 45 28 34 14 17 31 36 27 42  4 12 29 40  9 32 24 30 44 23 33 39 35 26 43  7 20  8], a_shuffle_aclus: [ 3 28 53 21 10 18 33 60 54  7 24 25  6 39 19 27 11 32  5 65 43 50 23 26 46 52 41 62  8 20 44 56 17 48 35 45 64 34 49 55 51 40 63 12 31 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33 30 13 10 39 22 42 41 31 17 26 38 29  3  9 40 12 19 27 16 11 23  6  1  4 18 37 20  5 43 21 25  8 34  2  7  0 36 15 24 28 14 45 35 32 44], a_shuffle_aclus: [49 45 21 18 55 33 62 60 46 26 40 54 44  7 17 56 20 28 41 25 19 34 11  5  8 27 53 31 10 63 32 39 15 50  6 12  3 52 24 35 43 23 65 51 48 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 37  9 44 30 36  0 14 27 26 17 42 45  3 32 24 38 31  8 40 41 33 22 10 34  2  4  5 19 16 35 39  1 20 28  7 11  6 23 43 25 12 18 15 29 13], a_shuffle_aclus: [32 53 17 64 45 52  3 23 41 40 26 62 65  7 48 35 54 46 15 56 60 49 33 18 50  6  8 10 28 25 51 55  5 31 43 12 19 11 34 63 39 20 27 24 44 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 43 25  7 36 27 40 16 23 20  5 24 34 18 11 39 32 41 26 19 33 10  4 21 17 28 30  9 45  1 15  0  3  6  8 31 44 22 42 29  2 35 37 14 12 38], a_shuffle_aclus: [21 63 39 12 52 41 56 25 34 31 10 35 50 27 19 55 48 60 40 28 49 18  8 32 26 43 45 17 65  5 24  3  7 11 15 46 64 33 62 44  6 51 53 23 20 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 28 40 13  9 25 29 35 22 27  3 44 36 30 34 11  0 31 38 24 26 19 41 42  4 23 20 33 12 37 15 14 45 10  6 32 21  8  5  7 43 16 18  1 39 17], a_shuffle_aclus: [ 6 43 56 21 17 39 44 51 33 41  7 64 52 45 50 19  3 46 54 35 40 28 60 62  8 34 31 49 20 53 24 23 65 18 11 48 32 15 10 12 63 25 27  5 55 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 44 37 26 20 34 23  6 29  9 22 36 24 43 15 25  1 14 12  0 17 39  3 30 21 18 19  5 13 35 16  7 11 38 31 28 32 40 33 27  4 45 42  2  8 41], a_shuffle_aclus: [18 64 53 40 31 50 34 11 44 17 33 52 35 63 24 39  5 23 20  3 26 55  7 45 32 27 28 10 21 51 25 12 19 54 46 43 48 56 49 41  8 65 62  6 15 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 20 19  3  7 13 36 27 30 25 45  4 41 44 12 21 17 23 26  5 34 15 37 38 22 11 18  0 33 29 40 39 42 35 14 24 43 16  2 32  9  6 28 31  1  8], a_shuffle_aclus: [18 31 28  7 12 21 52 41 45 39 65  8 60 64 20 32 26 34 40 10 50 24 53 54 33 19 27  3 49 44 56 55 62 51 23 35 63 25  6 48 17 11 43 46  5 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 37 42  2 15 11 16  6 25 38 27 20  3 35 44  5 32 34 33 22 39  0 29 31 40 13 43 10  7 17 12 19 36 23  1 41 18 26 14  9 21 30  4  8 28 24], a_shuffle_aclus: [65 53 62  6 24 19 25 11 39 54 41 31  7 51 64 10 48 50 49 33 55  3 44 46 56 21 63 18 12 26 20 28 52 34  5 60 27 40 23 17 32 45  8 15 43 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35  7 21 37 18 15 16  8 19 13  2  0 22 14 39 34  4 25 42 29 30 20 32 26  1 27 44 31  3 24  5 10 33 28 41  9 12 38 40 23 36  6 17 45 43 11], a_shuffle_aclus: [51 12 32 53 27 24 25 15 28 21  6  3 33 23 55 50  8 39 62 44 45 31 48 40  5 41 64 46  7 35 10 18 49 43 60 17 20 54 56 34 52 11 26 65 63 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 20 16 21 28 19 39 42  0 37 25 34 41  8 13  4 24 18 10 23 12 15  7 17 22  2 40 27 45  6 44 35 11 14 43 30  5 26  3 38 32  9 31  1 29 33], a_shuffle_aclus: [52 31 25 32 43 28 55 62  3 53 39 50 60 15 21  8 35 27 18 34 20 24 12 26 33  6 56 41 65 11 64 51 19 23 63 45 10 40  7 54 48 17 46  5 44 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 26 42 19 18 13 15  1  2 44  6 16 10 14 12 32  7 37  4 38 27 25 29 40 24 34  3 45 31 35 33  5 22 28 36  9 43 11 30 17 20 39 23 21 41  0], a_shuffle_aclus: [15 40 62 28 27 21 24  5  6 64 11 25 18 23 20 48 12 53  8 54 41 39 44 56 35 50  7 65 46 51 49 10 33 43 52 17 63 19 45 26 31 55 34 32 60  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 36  1 12 25 39 33 40 18 45 20 21 16 32 17 30 26 42 31 11 19 24 38  3  5  4 14 37  7 23  6 41  0 34 10 29  2 27 15 44 28  9  8 43 35 22], a_shuffle_aclus: [21 52  5 20 39 55 49 56 27 65 31 32 25 48 26 45 40 62 46 19 28 35 54  7 10  8 23 53 12 34 11 60  3 50 18 44  6 41 24 64 43 17 15 63 51 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [26  1  5 41 25 38 36  7 28 15 45 31 37 34 21 12  4 10  2 18 16 40 30 35 11 23 39 42 27 33 14  8 43 24 17  0 22 44 29  9 32 20 19 13  3  6], a_shuffle_aclus: [40  5 10 60 39 54 52 12 43 24 65 46 53 50 32 20  8 18  6 27 25 56 45 51 19 34 55 62 41 49 23 15 63 35 26  3 33 64 44 17 48 31 28 21  7 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 41 10 20 36 11 22 31  1 45 23 32 19 14 35 43 13 26 44  6  0 40 17 15 16  4 27  3 33 12 34  9 29 39 38 37 24 21 18  7  5  8  2 42 25 30], a_shuffle_aclus: [43 60 18 31 52 19 33 46  5 65 34 48 28 23 51 63 21 40 64 11  3 56 26 24 25  8 41  7 49 20 50 17 44 55 54 53 35 32 27 12 10 15  6 62 39 45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 10 41 39 34 40 27 12 24  8 16 22  5 17  9 21 44 45 20  2 26 19 36 29 28 38 13 33 23 32 15 11 30  1 18 42  6  7 43 35  3 25  0 14  4 31], a_shuffle_aclus: [53 18 60 55 50 56 41 20 35 15 25 33 10 26 17 32 64 65 31  6 40 28 52 44 43 54 21 49 34 48 24 19 45  5 27 62 11 12 63 51  7 39  3 23  8 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 29 21  0 43 27 14 34 24  5 26 18 41 30 31 32 25 22 11 15  9  1  3 23  7 40 45 20 28 35 16 39  8 17  4  6 19 36 37 38 33 13 12  2 42 44], a_shuffle_aclus: [18 44 32  3 63 41 23 50 35 10 40 27 60 45 46 48 39 33 19 24 17  5  7 34 12 56 65 31 43 51 25 55 15 26  8 11 28 52 53 54 49 21 20  6 62 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42  4  7 41 16 35 12  5 18 31 28  3 25  9 30 33 21  8 23 26 17 10 11 27 44 32 22 20 39 43 45  0 29 19 38 14 37  6  2  1 36 40 24 15 34 13], a_shuffle_aclus: [62  8 12 60 25 51 20 10 27 46 43  7 39 17 45 49 32 15 34 40 26 18 19 41 64 48 33 31 55 63 65  3 44 28 54 23 53 11  6  5 52 56 35 24 50 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38  7 18 26  1 22 42 24 16 32  9 43 23 37  5  6 33 25 13  8 15  0 27 39  2 29  3 21  4 30 14 45 28 41 20 31 12 36 40 35 44 34 19 17 10 11], a_shuffle_aclus: [54 12 27 40  5 33 62 35 25 48 17 63 34 53 10 11 49 39 21 15 24  3 41 55  6 44  7 32  8 45 23 65 43 60 31 46 20 52 56 51 64 50 28 26 18 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21  4 30 15  1 14  0 35 38 12 25 29  2 45 41 19 43 34 37 23 44  8 11 18 13 31  6  9 42 36  3 26 22 17 40  7 20 39 27 32 24 16  5 33 10 28], a_shuffle_aclus: [32  8 45 24  5 23  3 51 54 20 39 44  6 65 60 28 63 50 53 34 64 15 19 27 21 46 11 17 62 52  7 40 33 26 56 12 31 55 41 48 35 25 10 49 18 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 26 42 12 17 40 41  0 19 35  2 15 30  5 43 29  4 27 28 23 16 21 39  3  1 31 14 34 32 24 10 13 33  7 38 25  8  6 20 36 45  9 22 44 11 37], a_shuffle_aclus: [27 40 62 20 26 56 60  3 28 51  6 24 45 10 63 44  8 41 43 34 25 32 55  7  5 46 23 50 48 35 18 21 49 12 54 39 15 11 31 52 65 17 33 64 19 53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41 21  2 43 16 26 35 40  4 12 25  0 20 42 24  6 11 31 37 33 30  5 34  7  8 13 39  9 36 44 14 19 22 10 45 29 32 38  3 27 15 18 28  1 17 23], a_shuffle_aclus: [60 32  6 63 25 40 51 56  8 20 39  3 31 62 35 11 19 46 53 49 45 10 50 12 15 21 55 17 52 64 23 28 33 18 65 44 48 54  7 41 24 27 43  5 26 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [26 12 13 24 43 34 11 21 28 31 45 39  6 42 38  0 41 35  1  3 44 25 33 18 17 20  5 19 22 23 37 30  9 15  7 40 10 32 14  8 27 16 29 36  2  4], a_shuffle_aclus: [40 20 21 35 63 50 19 32 43 46 65 55 11 62 54  3 60 51  5  7 64 39 49 27 26 31 10 28 33 34 53 45 17 24 12 56 18 48 23 15 41 25 44 52  6  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 10 20 38 45 15 36 21 30 34 31  1 44  3 37 42 41  8 14  4 17 39 35 29 27 33 23 16 19  6 11 24 22  7 43  9 28 12 32 25 26  5  0 18 40  2], a_shuffle_aclus: [21 18 31 54 65 24 52 32 45 50 46  5 64  7 53 62 60 15 23  8 26 55 51 44 41 49 34 25 28 11 19 35 33 12 63 17 43 20 48 39 40 10  3 27 56  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 13 11 41  2 16 34 25 23 20  0 15 42  7 44 19 24 33  1 38 27 12 37 28 18 30  5 17 36  8 39 14 43  4  9 32 10  6 22 21 35 40 26  3 29 31], a_shuffle_aclus: [65 21 19 60  6 25 50 39 34 31  3 24 62 12 64 28 35 49  5 54 41 20 53 43 27 45 10 26 52 15 55 23 63  8 17 48 18 11 33 32 51 56 40  7 44 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 15 14 34  6 44 43  1 33 27 26 30 45 28 11 10  4 17 19 36  2  9 13 25 38 37 24 23 31  3 39 41  7 20 16 35 18  8 29 42 12 21 22  5 32 40], a_shuffle_aclus: [ 3 24 23 50 11 64 63  5 49 41 40 45 65 43 19 18  8 26 28 52  6 17 21 39 54 53 35 34 46  7 55 60 12 31 25 51 27 15 44 62 20 32 33 10 48 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 37  4  8 30 42  2 36 11 12  0 13 28  6  3 23 26 17 31 29 41 27  5 33 22 35 40 16 15 45 44 10 43  7 20 24 19 25 38 21 18 14  9 39 34  1], a_shuffle_aclus: [48 53  8 15 45 62  6 52 19 20  3 21 43 11  7 34 40 26 46 44 60 41 10 49 33 51 56 25 24 65 64 18 63 12 31 35 28 39 54 32 27 23 17 55 50  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17  8 14 42 34  4 36 16 11 41 44 40 45  7 32 19  5 26 28 20  2 18 35 38 27 31 22  9 12 23 29 43 39 13  6 24 10 25  1  0 37 33 21 15  3 30], a_shuffle_aclus: [26 15 23 62 50  8 52 25 19 60 64 56 65 12 48 28 10 40 43 31  6 27 51 54 41 46 33 17 20 34 44 63 55 21 11 35 18 39  5  3 53 49 32 24  7 45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33 29 28 43 10 44  2 15 38 31  9  4 16 17 42 14 36 11 18 32 26 39 34  3 41 20 13  6 12 27 22 19 24 35  0 45  7 21 30  1  8 40 37 23 25  5], a_shuffle_aclus: [49 44 43 63 18 64  6 24 54 46 17  8 25 26 62 23 52 19 27 48 40 55 50  7 60 31 21 11 20 41 33 28 35 51  3 65 12 32 45  5 15 56 53 34 39 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19 31 33 38 25  8 14 28 21 20 32 15 42 17 40 43  3 16  4 45 23  9  5  6 35 24 44 13 10 11 30 12 26 37 18 29  1 27 39  7 34  0 36 41 22  2], a_shuffle_aclus: [28 46 49 54 39 15 23 43 32 31 48 24 62 26 56 63  7 25  8 65 34 17 10 11 51 35 64 21 18 19 45 20 40 53 27 44  5 41 55 12 50  3 52 60 33  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 20 15 45  3  6 16 11 33 21  8 19  4 42 32 27 24 31 40 28 36 10  2 29 38 18 13 22 12 23  7 26 17  5 37 35 25  1 14 39 34  9  0 43 30 41], a_shuffle_aclus: [64 31 24 65  7 11 25 19 49 32 15 28  8 62 48 41 35 46 56 43 52 18  6 44 54 27 21 33 20 34 12 40 26 10 53 51 39  5 23 55 50 17  3 63 45 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 31 39 40 44 43 34 11  8 16 23  6 27 19 45  7 12 32 13 38 26 42 37 22  0 36 41 28  1 35 17  3 21  5  9 30  2 14 25 20 18 29 33 24 15  4], a_shuffle_aclus: [18 46 55 56 64 63 50 19 15 25 34 11 41 28 65 12 20 48 21 54 40 62 53 33  3 52 60 43  5 51 26  7 32 10 17 45  6 23 39 31 27 44 49 35 24  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 13 22 29  2 40 21  5 44 30 32  9 18  8 17 38 41 20 36 31  1 16 26 19 37 25 24 14 15  3 45  7  6 11 23  4 33 12 43 27 34 42 10 39 28 35], a_shuffle_aclus: [ 3 21 33 44  6 56 32 10 64 45 48 17 27 15 26 54 60 31 52 46  5 25 40 28 53 39 35 23 24  7 65 12 11 19 34  8 49 20 63 41 50 62 18 55 43 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 12 31 11 20 33 23 19 38 37  8 22  2  0 45  3  4 40 35 15 21  5 36 42 41 13 32 14 18 24 26 43 44  7 17 30 10 34 16 29  9  1 25 27 39 28], a_shuffle_aclus: [11 20 46 19 31 49 34 28 54 53 15 33  6  3 65  7  8 56 51 24 32 10 52 62 60 21 48 23 27 35 40 63 64 12 26 45 18 50 25 44 17  5 39 41 55 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10  9 45 44 26  3  0 24  1 40 30  5 29 13 21 39  8 17 27 12 43  2 19 11 38 15 28 31 33 32  7 35 16 20  6 42 23 18 25 41 22 14 36  4 37 34], a_shuffle_aclus: [18 17 65 64 40  7  3 35  5 56 45 10 44 21 32 55 15 26 41 20 63  6 28 19 54 24 43 46 49 48 12 51 25 31 11 62 34 27 39 60 33 23 52  8 53 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 15 25  4 31 30 11 14 36 28 38 27  0 37  6 24 17  8 40 19 10 42 22 45 43 26 34  3 39 12 23 18 16 29 33  1 32 44  5 21  2 41 13  9  7 20], a_shuffle_aclus: [51 24 39  8 46 45 19 23 52 43 54 41  3 53 11 35 26 15 56 28 18 62 33 65 63 40 50  7 55 20 34 27 25 44 49  5 48 64 10 32  6 60 21 17 12 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3  2  0 29 41  1  8 25 32 34 37 23 24 36 22 28 12 45 44 31 27 20 14 18 10 26 38  4 13 39 30 40  6  7  9 35 16 19 11 43 17 33 21 15  5 42], a_shuffle_aclus: [ 7  6  3 44 60  5 15 39 48 50 53 34 35 52 33 43 20 65 64 46 41 31 23 27 18 40 54  8 21 55 45 56 11 12 17 51 25 28 19 63 26 49 32 24 10 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44  5 30  3 33 31 15  4 16 39 10 18 24 25  8 28  2 11 19 22 14 32 23 38 26 41 12 20 40  9  6 45 34 43 29 13 42 36 37 21  1  0 35 17  7 27], a_shuffle_aclus: [64 10 45  7 49 46 24  8 25 55 18 27 35 39 15 43  6 19 28 33 23 48 34 54 40 60 20 31 56 17 11 65 50 63 44 21 62 52 53 32  5  3 51 26 12 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36  7 17  0 12 13 42 25  9 45 24 33 38 10 19 40  8 20 30 39  3 35  4 27 23 11 31 29  6 16 32 43  2  1  5 26 44 21 22 18 28 41 37 34 14 15], a_shuffle_aclus: [52 12 26  3 20 21 62 39 17 65 35 49 54 18 28 56 15 31 45 55  7 51  8 41 34 19 46 44 11 25 48 63  6  5 10 40 64 32 33 27 43 60 53 50 23 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 35 44 14 22 36 30 18  9  1  2 23 37 12 11 16 27 43 29 20 40  8 31 33 21 28 45  5 41 42 15  0 34 10  6 38  7 32 19  3 39 25  4 24 17 26], a_shuffle_aclus: [21 51 64 23 33 52 45 27 17  5  6 34 53 20 19 25 41 63 44 31 56 15 46 49 32 43 65 10 60 62 24  3 50 18 11 54 12 48 28  7 55 39  8 35 26 40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 26 24 13 29 39 10 14 38  4 19 32 21 33 22 41  0  8 25 45  2 15  5 42 43 30 11 37 31 20  1 18 40 44 16 12  7 23  3 36  6 17 34 28  9 35], a_shuffle_aclus: [41 40 35 21 44 55 18 23 54  8 28 48 32 49 33 60  3 15 39 65  6 24 10 62 63 45 19 53 46 31  5 27 56 64 25 20 12 34  7 52 11 26 50 43 17 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 27 38 13 28 21  5  4 34 37  8 36 15  3 23 14 25 17  7 41 16 22 35 44 39 19 12 33 24 18 10 20 11 31  2 29  9  1 30 40 26 32 45  0 43  6], a_shuffle_aclus: [62 41 54 21 43 32 10  8 50 53 15 52 24  7 34 23 39 26 12 60 25 33 51 64 55 28 20 49 35 27 18 31 19 46  6 44 17  5 45 56 40 48 65  3 63 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 17 16 39  7  4 33 42 40 23 10 12 30 13  6 27 28  2  3 26 22  0  1 38 20 43 36 41 25  5 24  8 21 37 18 35 45 31 11 32 34 29 19  9 15 44], a_shuffle_aclus: [23 26 25 55 12  8 49 62 56 34 18 20 45 21 11 41 43  6  7 40 33  3  5 54 31 63 52 60 39 10 35 15 32 53 27 51 65 46 19 48 50 44 28 17 24 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 13  9 32 38  3 25 23 10 24 18  0 28 31 39  4 20 37 12 34  5 19 33 35 27 40  6 43  2 26 41 42 15 14 22  1 11 29 30 16 17 45 36 44  7  8], a_shuffle_aclus: [32 21 17 48 54  7 39 34 18 35 27  3 43 46 55  8 31 53 20 50 10 28 49 51 41 56 11 63  6 40 60 62 24 23 33  5 19 44 45 25 26 65 52 64 12 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 14 12 18 26  1 20  0 31 24 34 27  5 36  9 10  8 16 37 15 29 21 25  3  7  4 40 38 32 35 30 23 33  2 22 44 41 39 42 45 43 13  6 28 19 17], a_shuffle_aclus: [19 23 20 27 40  5 31  3 46 35 50 41 10 52 17 18 15 25 53 24 44 32 39  7 12  8 56 54 48 51 45 34 49  6 33 64 60 55 62 65 63 21 11 43 28 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0  4 23 41 11 12 38 35  2 19  1 16 39 27 22 24 21 13  5  8 40 17 14 15 37 32 34 33  3 42 29 28 25 30 36 31 18  7 43 44  6  9 10 45 26 20], a_shuffle_aclus: [ 3  8 34 60 19 20 54 51  6 28  5 25 55 41 33 35 32 21 10 15 56 26 23 24 53 48 50 49  7 62 44 43 39 45 52 46 27 12 63 64 11 17 18 65 40 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 21 22 13 23 11  6 29  3 30 10  2  0 16 31 33  8 24 28  1 34 14 12 25 45 26 17 27  5 19  9 18 44  7 43  4 38 20 39 35 32 40 37 41 36 15], a_shuffle_aclus: [62 32 33 21 34 19 11 44  7 45 18  6  3 25 46 49 15 35 43  5 50 23 20 39 65 40 26 41 10 28 17 27 64 12 63  8 54 31 55 51 48 56 53 60 52 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 24 33 10 35 21 11 23 39  4 14 37 19  7 22 17 28 30 40 20 12 25 45  0 26 27 32 42 43 41 29  9 31 18  6  8  1 13  2 16 36 38 15  3 44  5], a_shuffle_aclus: [50 35 49 18 51 32 19 34 55  8 23 53 28 12 33 26 43 45 56 31 20 39 65  3 40 41 48 62 63 60 44 17 46 27 11 15  5 21  6 25 52 54 24  7 64 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38  6 41 11 25 42 18 36  3  7  4 22  8 13 33 39 31 14 30 17 12 35 10 40 29 44  0 28 32 34 20 16 19 15 23  5 26  1 43 24  2 37 21 27 45  9], a_shuffle_aclus: [54 11 60 19 39 62 27 52  7 12  8 33 15 21 49 55 46 23 45 26 20 51 18 56 44 64  3 43 48 50 31 25 28 24 34 10 40  5 63 35  6 53 32 41 65 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [16  0 45  9 37 15 21 11 18 33 29 35 44 30 20  4 42 31  8  1 10 24  2  3 38 17  6 43 39 23  7 14 27 25 28 32 41 26 19 36 13  5 40 12 22 34], a_shuffle_aclus: [25  3 65 17 53 24 32 19 27 49 44 51 64 45 31  8 62 46 15  5 18 35  6  7 54 26 11 63 55 34 12 23 41 39 43 48 60 40 28 52 21 10 56 20 33 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 43 11 24 38 45  9 32  8 19 12 15  1  6 23 22 41  3  0 40  4 42 16 10  2 25 39 26 33 17 36 28 37 30 34 20 27 35  5 18 44 14 21 13  7 31], a_shuffle_aclus: [44 63 19 35 54 65 17 48 15 28 20 24  5 11 34 33 60  7  3 56  8 62 25 18  6 39 55 40 49 26 52 43 53 45 50 31 41 51 10 27 64 23 32 21 12 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 26 23 38 41  1 13 40 35  4 16 42 39 17 20 37 10 30 28 36 27  8  5 45  6  3 24 21 25  2 18  9 31 33 44 34  0 32 15 12 22 29 19  7 14 43], a_shuffle_aclus: [19 40 34 54 60  5 21 56 51  8 25 62 55 26 31 53 18 45 43 52 41 15 10 65 11  7 35 32 39  6 27 17 46 49 64 50  3 48 24 20 33 44 28 12 23 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [26 13 34 19  6 23 43 35 39 15 31 27 36 12 45 17 42 37  9  7 20 21  2 18 24 44 41  8 33 29 10 14 40  0  3 30  1 16  4 32 38 11  5 25 22 28], a_shuffle_aclus: [40 21 50 28 11 34 63 51 55 24 46 41 52 20 65 26 62 53 17 12 31 32  6 27 35 64 60 15 49 44 18 23 56  3  7 45  5 25  8 48 54 19 10 39 33 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3  2 45 39 16 41 44 37 13 35 27 11 33  0  1 34  6 22 14 17 31 21 20  8 29 30 32 28 18 26 19 25  4 43 15 42 38 10 36  7 24 23  5 40 12  9], a_shuffle_aclus: [ 7  6 65 55 25 60 64 53 21 51 41 19 49  3  5 50 11 33 23 26 46 32 31 15 44 45 48 43 27 40 28 39  8 63 24 62 54 18 52 12 35 34 10 56 20 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41  8 23  3  6  0 35 25 10 28 36 22 29 45  1 42 16 13 21 17 44 11 12 20 34 38  5 39 27 26  2 24 37 32 43 40 33 31 19  4 30 14 15  7 18  9], a_shuffle_aclus: [60 15 34  7 11  3 51 39 18 43 52 33 44 65  5 62 25 21 32 26 64 19 20 31 50 54 10 55 41 40  6 35 53 48 63 56 49 46 28  8 45 23 24 12 27 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28  5 35 37  1 30 27 14 23 18  6 22  8 19 45 21 42 20 36 11 41 17  7 26 31 10  2 43  9  3 39 25 40  4 32 29 38 15 16 44  0 33 13 12 34 24], a_shuffle_aclus: [43 10 51 53  5 45 41 23 34 27 11 33 15 28 65 32 62 31 52 19 60 26 12 40 46 18  6 63 17  7 55 39 56  8 48 44 54 24 25 64  3 49 21 20 50 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41 27 13 45 14 40 29 44 31  4 34  1  2  9 43  6  8 26  7 24 18 35 15 10 36 39  5  3 17 11 33 30  0 32 20 21 28 12 38 25 16 23 37 22 42 19], a_shuffle_aclus: [60 41 21 65 23 56 44 64 46  8 50  5  6 17 63 11 15 40 12 35 27 51 24 18 52 55 10  7 26 19 49 45  3 48 31 32 43 20 54 39 25 34 53 33 62 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 22  0 25 38 12 14 18  3 15 45 31 16  2 41 34  4  7  8 17 37 39 42 40 26 24 11 21 29 27 13 44 23 43 20 10 33  9 35 36  1 19  5  6 28 30], a_shuffle_aclus: [48 33  3 39 54 20 23 27  7 24 65 46 25  6 60 50  8 12 15 26 53 55 62 56 40 35 19 32 44 41 21 64 34 63 31 18 49 17 51 52  5 28 10 11 43 45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 32 45 23  1 35 24  6 28 36 29 27 19 16 30 18  7  0 37 33 10  5 14 38 22 26 25 34 17  4 12 44 31 15  8 21 39 40  3 43 42 41 11  9 13 20], a_shuffle_aclus: [ 6 48 65 34  5 51 35 11 43 52 44 41 28 25 45 27 12  3 53 49 18 10 23 54 33 40 39 50 26  8 20 64 46 24 15 32 55 56  7 63 62 60 19 17 21 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 14  2 22  8 34 25 38 24 37 43 16 40 12 42 28 19  3  1 32 21 44 17 11 39 29 15  7 20 45 10 41 13  9  6  4 31  5 27 26 35  0 23 30 36 33], a_shuffle_aclus: [27 23  6 33 15 50 39 54 35 53 63 25 56 20 62 43 28  7  5 48 32 64 26 19 55 44 24 12 31 65 18 60 21 17 11  8 46 10 41 40 51  3 34 45 52 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 20 34 14 40  8  9 12  6 29 22 13  7 25  2 18 24 23 43 21 10 30 37 27 41 28  1 15  0 45 32 39 16 17 44 38 31 19 36  3 11 42  5 26 35 33], a_shuffle_aclus: [ 8 31 50 23 56 15 17 20 11 44 33 21 12 39  6 27 35 34 63 32 18 45 53 41 60 43  5 24  3 65 48 55 25 26 64 54 46 28 52  7 19 62 10 40 51 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 37 18 39 33 28  9 14 11  4 44 10 24 35 43  5  0 30 26 41 15 20 45 32 16  8  2 13 12 31 29 34 42 36 40 23 27 19  6 25 38  7  3 21  1 22], a_shuffle_aclus: [26 53 27 55 49 43 17 23 19  8 64 18 35 51 63 10  3 45 40 60 24 31 65 48 25 15  6 21 20 46 44 50 62 52 56 34 41 28 11 39 54 12  7 32  5 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 11 30 22 19 13 14 27 35 37 42  9  2 26 25 43 45 31  6 10 29 36 38 18 24  4  0 34 20 17 21  3 40 39  8 12 23 44 41 16  7 33 15  1  5 28], a_shuffle_aclus: [48 19 45 33 28 21 23 41 51 53 62 17  6 40 39 63 65 46 11 18 44 52 54 27 35  8  3 50 31 26 32  7 56 55 15 20 34 64 60 25 12 49 24  5 10 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 34 25 16  7 41 40 26 37 17 35 28 27  3 10 23 31  0 20  9  4 12 39 14 43 19 13 22 29  1 24  2 18 36  6 15 45  8 21 38 32 30 44 33 11  5], a_shuffle_aclus: [62 50 39 25 12 60 56 40 53 26 51 43 41  7 18 34 46  3 31 17  8 20 55 23 63 28 21 33 44  5 35  6 27 52 11 24 65 15 32 54 48 45 64 49 19 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41  4  2 15 32 22 28 27 40 45 42 19 11  3 12 30  0 31 44 24 17 13 29 43 37 33 26 34  7 10 18  5 14 20 39 25 38  8  9 35  1 21 36 16  6 23], a_shuffle_aclus: [60  8  6 24 48 33 43 41 56 65 62 28 19  7 20 45  3 46 64 35 26 21 44 63 53 49 40 50 12 18 27 10 23 31 55 39 54 15 17 51  5 32 52 25 11 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7 33 23 19 36 31 45  9 17 39 26 15 11 38  0 18  4 30 32 28 40 21 29 41 14 44 13 16 12  1  6  8  3  5 37 27 24  2 42 35 22 20 25 43 34 10], a_shuffle_aclus: [12 49 34 28 52 46 65 17 26 55 40 24 19 54  3 27  8 45 48 43 56 32 44 60 23 64 21 25 20  5 11 15  7 10 53 41 35  6 62 51 33 31 39 63 50 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7 24 26  2  0 23 39 36 34 20 10 41 42  5 44 18 30 43 19 35 40  6 11  4 13 16 12  9  8 37 25 33  1 14 28 21 45 17 27 38  3 29 31 32 15 22], a_shuffle_aclus: [12 35 40  6  3 34 55 52 50 31 18 60 62 10 64 27 45 63 28 51 56 11 19  8 21 25 20 17 15 53 39 49  5 23 43 32 65 26 41 54  7 44 46 48 24 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33 26 27 15 12 19 32  0 45  5 20 13 17 29 16 38  3 11 28  4  8 31 41  7 40 10 22 23 43 35 34 44 25  9  6 39 24 42  1 30 37 14 36 18 21  2], a_shuffle_aclus: [49 40 41 24 20 28 48  3 65 10 31 21 26 44 25 54  7 19 43  8 15 46 60 12 56 18 33 34 63 51 50 64 39 17 11 55 35 62  5 45 53 23 52 27 32  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [26 16  1 28  0 21 20 40  3 10  9 23 35 17 11  2 41  6 34 18  4 13 27 37 30  5 32 15  8 36 31  7 22 44 19 39 38 12 42 29 14 33 24 43 25 45], a_shuffle_aclus: [40 25  5 43  3 32 31 56  7 18 17 34 51 26 19  6 60 11 50 27  8 21 41 53 45 10 48 24 15 52 46 12 33 64 28 55 54 20 62 44 23 49 35 63 39 65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 34 13 37  8 35 26 25  5  9 42 23 38 31 12  0  6 30 41 32 20  2 24 22 29 16 39 33 43  7 40 10 11 17 27 28 45  3  4 14 15 18 19  1 44 36], a_shuffle_aclus: [32 50 21 53 15 51 40 39 10 17 62 34 54 46 20  3 11 45 60 48 31  6 35 33 44 25 55 49 63 12 56 18 19 26 41 43 65  7  8 23 24 27 28  5 64 52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20 23 43  2 21 36 33  9 32  8 18 12 41 13 45 30 42 37 44 17  4 28 39 26  5  1 11  6 16 38 22  7 34 35 27 10  0 14 15  3 40 24 29 19 25 31], a_shuffle_aclus: [31 34 63  6 32 52 49 17 48 15 27 20 60 21 65 45 62 53 64 26  8 43 55 40 10  5 19 11 25 54 33 12 50 51 41 18  3 23 24  7 56 35 44 28 39 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13  0 40 33 23  8 36 14 15 37  6  7 21 41 27 30 32 26 38 35 39  4 25 42 22 18 11 16 44 19 17 45 29 12 28 24 43  9 10  1 34 31  2  5 20  3], a_shuffle_aclus: [21  3 56 49 34 15 52 23 24 53 11 12 32 60 41 45 48 40 54 51 55  8 39 62 33 27 19 25 64 28 26 65 44 20 43 35 63 17 18  5 50 46  6 10 31  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10  0 18 32 39 20 27 21 35  9 37 23 19 15 11 28  4  1 12 17  6 43 26 16  2 45 24  3 22 34 30 42 41 31 33 13  5 36 29 25  7  8 40 14 44 38], a_shuffle_aclus: [18  3 27 48 55 31 41 32 51 17 53 34 28 24 19 43  8  5 20 26 11 63 40 25  6 65 35  7 33 50 45 62 60 46 49 21 10 52 44 39 12 15 56 23 64 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1 14 28 22 43 31 10 13 39 25  8 21 29  4 20  2  3 11  7 37 12 30 42  5 45 44  0 41 15 27 34 35 38 18 19 23 40 16 36  6 33  9 32 26 17 24], a_shuffle_aclus: [ 5 23 43 33 63 46 18 21 55 39 15 32 44  8 31  6  7 19 12 53 20 45 62 10 65 64  3 60 24 41 50 51 54 27 28 34 56 25 52 11 49 17 48 40 26 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 16 45 12 31 37  7 24 22  4 40 10 34  3  9 25 28 33  1 32  2  5  0 15  6 29 18 44 11 39 13 17 21 20 35 26 14 27 19 43 36 38 23 30 41 42], a_shuffle_aclus: [15 25 65 20 46 53 12 35 33  8 56 18 50  7 17 39 43 49  5 48  6 10  3 24 11 44 27 64 19 55 21 26 32 31 51 40 23 41 28 63 52 54 34 45 60 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 10 27 18 42  9 29 12 21  2 22 16 35  6 15 43  5 17 24 38 23  7 39 37 25 20 13 28 33  0 34 19  8 44 31 32 26 40 45 14 41 11 36  3  1  4], a_shuffle_aclus: [45 18 41 27 62 17 44 20 32  6 33 25 51 11 24 63 10 26 35 54 34 12 55 53 39 31 21 43 49  3 50 28 15 64 46 48 40 56 65 23 60 19 52  7  5  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 36  2 14 16 12 18 42 38 31 10 40  1 44 41 34 32 43 20 24 28  9 21 45 26 30  0 23  7  5  6 27 19 39 11  3  8 35 15 22  4 17 25 13 33 29], a_shuffle_aclus: [53 52  6 23 25 20 27 62 54 46 18 56  5 64 60 50 48 63 31 35 43 17 32 65 40 45  3 34 12 10 11 41 28 55 19  7 15 51 24 33  8 26 39 21 49 44]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 31 34  4 36 39 17  6 40 21 43 24 38 41 16 45 25  7 29 33 19  1 20 27 42 28  0 37  8  5 13 18 35 14  2  9 32 26 10 22 11 15  3 12 30 23], a_shuffle_aclus: [64 46 50  8 52 55 26 11 56 32 63 35 54 60 25 65 39 12 44 49 28  5 31 41 62 43  3 53 15 10 21 27 51 23  6 17 48 40 18 33 19 24  7 20 45 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 23 41 30 22 11 26  4 14 28 42  9 32 38 44 35 37 19 36 45  7 25 10  1 13 20 31  6 24 34 40 29 33  2  8 43  0 15 16 17 18 12 39 21  5 27], a_shuffle_aclus: [ 7 34 60 45 33 19 40  8 23 43 62 17 48 54 64 51 53 28 52 65 12 39 18  5 21 31 46 11 35 50 56 44 49  6 15 63  3 24 25 26 27 20 55 32 10 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25  9 39 40 15 12 38 31 36  8  6 23 28 21 10  2  3 43 34 32 33 41 17 27 16  4 20 18 13 35 24 42 37 44 29 30 19 11  5 26 14  1 22  7 45  0], a_shuffle_aclus: [39 17 55 56 24 20 54 46 52 15 11 34 43 32 18  6  7 63 50 48 49 60 26 41 25  8 31 27 21 51 35 62 53 64 44 45 28 19 10 40 23  5 33 12 65  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25  9 41 24  5  4 14 32  7 26  6 20 11 43 35 36 33 15 44 31  1 12 10 23  2 45 28 34 27 16 21 18 38 29  3 40 30 39 22  8 17 42 37 13  0 19], a_shuffle_aclus: [39 17 60 35 10  8 23 48 12 40 11 31 19 63 51 52 49 24 64 46  5 20 18 34  6 65 43 50 41 25 32 27 54 44  7 56 45 55 33 15 26 62 53 21  3 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 22 21 14  9 29 28 15 11 44  6 12 43 10 39 17 26 25 45  5 30 36 37 38 41 33  0 40  2 19 24  3  1 34 13 16 42  4 35  8 31 32  7 20 27 23], a_shuffle_aclus: [27 33 32 23 17 44 43 24 19 64 11 20 63 18 55 26 40 39 65 10 45 52 53 54 60 49  3 56  6 28 35  7  5 50 21 25 62  8 51 15 46 48 12 31 41 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14  5 16  9 20 10 29 40 35 41 28  8  4 24  0  1 21 43 22  3 31 38 26 36 30 11  7 19 23 39 45 34 25 37 32 18 27 42 17 15 44  6  2 33 12 13], a_shuffle_aclus: [23 10 25 17 31 18 44 56 51 60 43 15  8 35  3  5 32 63 33  7 46 54 40 52 45 19 12 28 34 55 65 50 39 53 48 27 41 62 26 24 64 11  6 49 20 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 38 13  9 40 42 14 28  0 24 25 39  5  8 30 23 45 21 35 22 26 10 34 27  2 19 32 44 37 31  1 33 43 29 12  7  3 16  4 11 36 20 41 15 17  6], a_shuffle_aclus: [27 54 21 17 56 62 23 43  3 35 39 55 10 15 45 34 65 32 51 33 40 18 50 41  6 28 48 64 53 46  5 49 63 44 20 12  7 25  8 19 52 31 60 24 26 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33 16 30 37  3 45 29 27  8 11 41  1 12  0 21 44  2 34 43 26 10 22 19 42 38 40  6 24  7 39 18  4 35 15 20 13 28 14  5 23 32 25 31  9 17 36], a_shuffle_aclus: [49 25 45 53  7 65 44 41 15 19 60  5 20  3 32 64  6 50 63 40 18 33 28 62 54 56 11 35 12 55 27  8 51 24 31 21 43 23 10 34 48 39 46 17 26 52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 41 43 40 12 20 30  0 39 17 44 10 27  6 45 33 19 23 14 26 32 25 38  4  7 11 24  2 13 16 29  8 31 21 15 42  9  3 22 37 34  5 35 28  1 36], a_shuffle_aclus: [27 60 63 56 20 31 45  3 55 26 64 18 41 11 65 49 28 34 23 40 48 39 54  8 12 19 35  6 21 25 44 15 46 32 24 62 17  7 33 53 50 10 51 43  5 52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40 15 29 45  4 25 36  0 22 30 10  2 38  8 16 41 42  3  6 28 37 31 21 44 19  1 24 32  7 11 18 35 20  9 23 43  5 39 33 14 13 12 27 26 17 34], a_shuffle_aclus: [56 24 44 65  8 39 52  3 33 45 18  6 54 15 25 60 62  7 11 43 53 46 32 64 28  5 35 48 12 19 27 51 31 17 34 63 10 55 49 23 21 20 41 40 26 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 36 17 32  3 33 23 19 22 42 25  5 27  2 12 15 20  8  6 34 14 29 26 16 37  0 10  1 28  4 21 43 11 18 45 41 35 44  7 38 24  9 13 31 39 40], a_shuffle_aclus: [45 52 26 48  7 49 34 28 33 62 39 10 41  6 20 24 31 15 11 50 23 44 40 25 53  3 18  5 43  8 32 63 19 27 65 60 51 64 12 54 35 17 21 46 55 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 14 33 34 16 12  6 44 31  7  3 15 18 20 25 23 37  0 21 39 22  2 35 32  1 19 42 26 45 28 24 10 13  8 40 41  4 36 17 11 38 29  5 30  9 27], a_shuffle_aclus: [63 23 49 50 25 20 11 64 46 12  7 24 27 31 39 34 53  3 32 55 33  6 51 48  5 28 62 40 65 43 35 18 21 15 56 60  8 52 26 19 54 44 10 45 17 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 36 22  9  6 43 27 29 10 40 19  8  0 17 30 38  5 24  3 34 42 32 23 11 31 45 14 12 26 20 18 41 33 39 16 21  4 13  1 44 28 25  7  2 37 15], a_shuffle_aclus: [51 52 33 17 11 63 41 44 18 56 28 15  3 26 45 54 10 35  7 50 62 48 34 19 46 65 23 20 40 31 27 60 49 55 25 32  8 21  5 64 43 39 12  6 53 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19 14 18  8  9 16 11 44 31 32 21 17 38 13 25 42 12  6 20  4 29 41 24  5 28 43  3 36  7 23 26 27 40 34 39  0 22 30 15 33 45 37 35  2 10  1], a_shuffle_aclus: [28 23 27 15 17 25 19 64 46 48 32 26 54 21 39 62 20 11 31  8 44 60 35 10 43 63  7 52 12 34 40 41 56 50 55  3 33 45 24 49 65 53 51  6 18  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7 28 15 21 14 31 37  4 12  0 20  6 16 24 23 42 30  1 29 25 19 13 22 41 43 38 18 35 11 33 34 36 39 32 45 44 27 40  9 26  8 17  5 10  2  3], a_shuffle_aclus: [12 43 24 32 23 46 53  8 20  3 31 11 25 35 34 62 45  5 44 39 28 21 33 60 63 54 27 51 19 49 50 52 55 48 65 64 41 56 17 40 15 26 10 18  6  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15  5 44 42 43 23 35 26 34 30 39 45 17  8 24 36  4 20 37  0 38 28 29 33 40  3  7 10 16 11 41 14 25 12 19 31  9 18  6  1 32 21 22  2 27 13], a_shuffle_aclus: [24 10 64 62 63 34 51 40 50 45 55 65 26 15 35 52  8 31 53  3 54 43 44 49 56  7 12 18 25 19 60 23 39 20 28 46 17 27 11  5 48 32 33  6 41 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40 22 19 38 27 35 37 41 43 42 11 18 44  7 10  2 21 36 28 14 33  1 16 39 23  6 20 13 31 12 17 26  5 32 25  3  4  8 30 34 45 24 15  0  9 29], a_shuffle_aclus: [56 33 28 54 41 51 53 60 63 62 19 27 64 12 18  6 32 52 43 23 49  5 25 55 34 11 31 21 46 20 26 40 10 48 39  7  8 15 45 50 65 35 24  3 17 44]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19 11 27 42  1 20 43 38 16 33  6 22  7 28 36 13 14 10 26 44 37 15 31 24  5 21  0  4 29  3 17 45 32  8 23 12 40 25 41 18  9 35 39 34 30  2], a_shuffle_aclus: [28 19 41 62  5 31 63 54 25 49 11 33 12 43 52 21 23 18 40 64 53 24 46 35 10 32  3  8 44  7 26 65 48 15 34 20 56 39 60 27 17 51 55 50 45  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29  8  1  0 25  4 35 24 37 39 17 21 38  7 20 16  3 26 11 10 15 32 40 22 42 18 31 23 30  5 41 14  2 36 12 27 34  9 13 28 44 45 43 19 33  6], a_shuffle_aclus: [44 15  5  3 39  8 51 35 53 55 26 32 54 12 31 25  7 40 19 18 24 48 56 33 62 27 46 34 45 10 60 23  6 52 20 41 50 17 21 43 64 65 63 28 49 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33 11  5 23 34 37  9 30 26 36 39  8 21  7  3 17 42 38 43 31 12  1 14 19 15 22 13  6 27  0 25 20 28 44 24 29 45 10  2 18 35  4 40 32 41 16], a_shuffle_aclus: [49 19 10 34 50 53 17 45 40 52 55 15 32 12  7 26 62 54 63 46 20  5 23 28 24 33 21 11 41  3 39 31 43 64 35 44 65 18  6 27 51  8 56 48 60 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 13  1  7 20 29 35 10 32  5 41 31 25  2 19 43 28 33 12 42 15 24 11  4 39  3 36 21 37 17 27 26  0 16 22  8 18 30  9 14 38 44 34  6 23 40], a_shuffle_aclus: [65 21  5 12 31 44 51 18 48 10 60 46 39  6 28 63 43 49 20 62 24 35 19  8 55  7 52 32 53 26 41 40  3 25 33 15 27 45 17 23 54 64 50 11 34 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 10 44 19 14 35 38 18 25 11 20  4 22 32  6 27 34 16 42  1 21 12 45 41  0 37  8  5 17 36  3 15 39 24 26 29 23 33  7  2 28 30 40  9 31 43], a_shuffle_aclus: [21 18 64 28 23 51 54 27 39 19 31  8 33 48 11 41 50 25 62  5 32 20 65 60  3 53 15 10 26 52  7 24 55 35 40 44 34 49 12  6 43 45 56 17 46 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 10 29  5 26 28 21 22 33 38 13 41  2 43 23 19  0 17  4 20 31 34 15 32  3 30 40 25 42 14 27 37 35 24  1  9 36  6  7  8 12 16 39 11 18 44], a_shuffle_aclus: [65 18 44 10 40 43 32 33 49 54 21 60  6 63 34 28  3 26  8 31 46 50 24 48  7 45 56 39 62 23 41 53 51 35  5 17 52 11 12 15 20 25 55 19 27 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 18  4 40 26 14 34 33 32  9 19 10 12 35 17  8 28  7 22 27 37  3 13  1 23 29 42  0 39 24  6 15 36 41 20 25 45 11 30 43 16 44 31  2  5 38], a_shuffle_aclus: [32 27  8 56 40 23 50 49 48 17 28 18 20 51 26 15 43 12 33 41 53  7 21  5 34 44 62  3 55 35 11 24 52 60 31 39 65 19 45 63 25 64 46  6 10 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 11 43 14  5  0 18 17 13 16  2 26 36 37  7 38 40 31 39 23  6 42 15  1  8 10 22 32 19 44 20  3 27 45 35 41 29 25 28  4 12 33 21  9 30 24], a_shuffle_aclus: [50 19 63 23 10  3 27 26 21 25  6 40 52 53 12 54 56 46 55 34 11 62 24  5 15 18 33 48 28 64 31  7 41 65 51 60 44 39 43  8 20 49 32 17 45 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7 31 27 26 36 38 13 43 40 21 33 23 18 10 41 44 45 14 25 39  5  2  4 37 17  1 22 34  6 28 11 24 32 35  3 30 19  0 12  9 42 20 29  8 16 15], a_shuffle_aclus: [12 46 41 40 52 54 21 63 56 32 49 34 27 18 60 64 65 23 39 55 10  6  8 53 26  5 33 50 11 43 19 35 48 51  7 45 28  3 20 17 62 31 44 15 25 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 16  8  5 43 34  0 25 19 29 37 42 20  9 39 32 26 38  3 35 14  4 17 28 22 21 31 27 30 15 41 44 18  2 36  6 23 45  1 12 10 24 40 11  7 33], a_shuffle_aclus: [21 25 15 10 63 50  3 39 28 44 53 62 31 17 55 48 40 54  7 51 23  8 26 43 33 32 46 41 45 24 60 64 27  6 52 11 34 65  5 20 18 35 56 19 12 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 17  8  6 41 34 15 10 35 39  9 19 40 32 31  5 14 12 16 11 13 22 25 33  4 37 28 36 23 43 20 30 42  2 27  0  7 45  1 44 24 18 38 21  3 26], a_shuffle_aclus: [44 26 15 11 60 50 24 18 51 55 17 28 56 48 46 10 23 20 25 19 21 33 39 49  8 53 43 52 34 63 31 45 62  6 41  3 12 65  5 64 35 27 54 32  7 40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 37 44 20 14 31  1 16 43 23  9 30 25 15  3 33  0  8 38 34 26 45 12 27 29 19 18  4 39  7 21 22 40 32 35  2 36 11 41 17 24 28 13  5 42 10], a_shuffle_aclus: [11 53 64 31 23 46  5 25 63 34 17 45 39 24  7 49  3 15 54 50 40 65 20 41 44 28 27  8 55 12 32 33 56 48 51  6 52 19 60 26 35 43 21 10 62 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 28 32 41  8 27 10 25 35 14 23 42 13 20 16 29 21 36 22 12 24  9 26  6 15  5 18 43  0 39  4 37 40 44 33 38 45 17  3 19 31  1  2  7 34 30], a_shuffle_aclus: [19 43 48 60 15 41 18 39 51 23 34 62 21 31 25 44 32 52 33 20 35 17 40 11 24 10 27 63  3 55  8 53 56 64 49 54 65 26  7 28 46  5  6 12 50 45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38  6 23 43  2 36 24 35  1  7  5 21 13 11 41  4 19 27 39 29  9 32 34 12 16  8 10 17 42 44  3 18  0 15 20 26 25 22 28 40 30 45 37 14 33 31], a_shuffle_aclus: [54 11 34 63  6 52 35 51  5 12 10 32 21 19 60  8 28 41 55 44 17 48 50 20 25 15 18 26 62 64  7 27  3 24 31 40 39 33 43 56 45 65 53 23 49 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 20 45 37 13 11  1 16  5 28 18  4 36 26 23 42  3 14 15 21 30 35 24 10 32 27 39  2 25 31 38 44 43 19  7 17 40 29 41  0  8  9 12 22  6 33], a_shuffle_aclus: [50 31 65 53 21 19  5 25 10 43 27  8 52 40 34 62  7 23 24 32 45 51 35 18 48 41 55  6 39 46 54 64 63 28 12 26 56 44 60  3 15 17 20 33 11 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 11  2 14 24 12 33 38 16 13 20 36 18 40  6 34 31 45  7 15 44 10 43 28 42  9 23 37 17  1 29 25 35  5 22 19 26 27 32  3 21  8 41  4  0 39], a_shuffle_aclus: [45 19  6 23 35 20 49 54 25 21 31 52 27 56 11 50 46 65 12 24 64 18 63 43 62 17 34 53 26  5 44 39 51 10 33 28 40 41 48  7 32 15 60  8  3 55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38 43 20 13 22  7 29 19 34  3 25  0  4 16 28 42 15 17 35  5 27 30 41 24  6 37 39  9 45 12 36 18  2 10 26 11 40 14  8 32 21 33 31 23  1 44], a_shuffle_aclus: [54 63 31 21 33 12 44 28 50  7 39  3  8 25 43 62 24 26 51 10 41 45 60 35 11 53 55 17 65 20 52 27  6 18 40 19 56 23 15 48 32 49 46 34  5 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2  6 26  3  4 25 20 43 22 31 35 42  8 44 24  5 38 19 30 27 14 41  0 34 18 28 10 23 11 12 39 33 40 13 21 29  1 15 37  7 17 36 16  9 45 32], a_shuffle_aclus: [ 6 11 40  7  8 39 31 63 33 46 51 62 15 64 35 10 54 28 45 41 23 60  3 50 27 43 18 34 19 20 55 49 56 21 32 44  5 24 53 12 26 52 25 17 65 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 29 25  7 33 18 38 15 11  2 28  9 37 36 42 43  4 41 34 16 45  1 44 31 26 24 20 13 17 22 23 35 12  8 27 14 30 21 19  0 39 32 10  6 40  3], a_shuffle_aclus: [10 44 39 12 49 27 54 24 19  6 43 17 53 52 62 63  8 60 50 25 65  5 64 46 40 35 31 21 26 33 34 51 20 15 41 23 45 32 28  3 55 48 18 11 56  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 31  9 11 44 33 13  8 19 12 16 10 27  4 20 45  0  2 15  1 39 42 36 28  7 37 17 35 29 40 26 25 23 34 43 32 24 22  5 38 21 30 41 18  3  6], a_shuffle_aclus: [23 46 17 19 64 49 21 15 28 20 25 18 41  8 31 65  3  6 24  5 55 62 52 43 12 53 26 51 44 56 40 39 34 50 63 48 35 33 10 54 32 45 60 27  7 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 15 16 32 37 29 19 38  1 33  6  5 36 28  9 41  0 12 44 24 26  2 45  3 22 17  8 14 40 13 21 42  4 11 30  7 34 23 27 31 25 20 18 35 43 39], a_shuffle_aclus: [18 24 25 48 53 44 28 54  5 49 11 10 52 43 17 60  3 20 64 35 40  6 65  7 33 26 15 23 56 21 32 62  8 19 45 12 50 34 41 46 39 31 27 51 63 55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [31 37  8 15 33 25 43 12  9 14 23 32 24 28 44  7  4 13 27 42 26 30 10  6  3 41 21 16 40 29 19 38 36 22 45 18  1 35  5 17  0 11 20 39 34  2], a_shuffle_aclus: [46 53 15 24 49 39 63 20 17 23 34 48 35 43 64 12  8 21 41 62 40 45 18 11  7 60 32 25 56 44 28 54 52 33 65 27  5 51 10 26  3 19 31 55 50  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 43 20 26 17 25  0 13 42 27 36  3 29 40  5 24 11 19 18 12 41  4 21 14 10 34  6 35 38  2  1 45 32  7 15 30 16 37 31  8  9 22 39 33 23 28], a_shuffle_aclus: [64 63 31 40 26 39  3 21 62 41 52  7 44 56 10 35 19 28 27 20 60  8 32 23 18 50 11 51 54  6  5 65 48 12 24 45 25 53 46 15 17 33 55 49 34 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19 41 15 16 17 33 28 20  4  3 13  5 30  9 29  6 21 22 36 32  7 37 44 23 10 24 35 27 45 42 18  8 43 38  2 25 39 12 34 14  1 11 31 40 26  0], a_shuffle_aclus: [28 60 24 25 26 49 43 31  8  7 21 10 45 17 44 11 32 33 52 48 12 53 64 34 18 35 51 41 65 62 27 15 63 54  6 39 55 20 50 23  5 19 46 56 40  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 25  5 29 40 32  8 31 16  0 10 38 18 35 22  9 39 14  3 23  1  6 43  2  4 30 45 24 21 42 12 17 34  7 26 44 11 27 36 20 41 19 33 28 13 15], a_shuffle_aclus: [53 39 10 44 56 48 15 46 25  3 18 54 27 51 33 17 55 23  7 34  5 11 63  6  8 45 65 35 32 62 20 26 50 12 40 64 19 41 52 31 60 28 49 43 21 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 41 13 16 34 22 26 43 12 10 42  7  4 21 32  8 30 15 23 33 38 36  9 27 20  6  3 28 29 44  1 37 25  2 40 14 31 19 39 18 35  5 11 45 24  0], a_shuffle_aclus: [26 60 21 25 50 33 40 63 20 18 62 12  8 32 48 15 45 24 34 49 54 52 17 41 31 11  7 43 44 64  5 53 39  6 56 23 46 28 55 27 51 10 19 65 35  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 26 28 16  7  5 40 32 36 22 43  0  4 39 25 27  2 12 15 29 13  3  1 30 42 37 34 24 21 19  6 45  9 14 35 38 44 41 11 31 10  8 17 33 18 20], a_shuffle_aclus: [34 40 43 25 12 10 56 48 52 33 63  3  8 55 39 41  6 20 24 44 21  7  5 45 62 53 50 35 32 28 11 65 17 23 51 54 64 60 19 46 18 15 26 49 27 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 39 23 14 22 42  4 19 29 28 30 27 26  1  0 31 11 34 25  5 37 13 21 40 18 41 33 10 20 32 24 44 43  7 36 16 15  9 38  3 17 12 35 45  8  2], a_shuffle_aclus: [11 55 34 23 33 62  8 28 44 43 45 41 40  5  3 46 19 50 39 10 53 21 32 56 27 60 49 18 31 48 35 64 63 12 52 25 24 17 54  7 26 20 51 65 15  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 30  7 25 41 38  0 20 37  8 27 40 19 13  6 10  2 23 43  4 16 26 42 36 21 29 44 39 35 22 18 24 34 31  1 11 28 12 15  5 33 17 45  9  3 14], a_shuffle_aclus: [48 45 12 39 60 54  3 31 53 15 41 56 28 21 11 18  6 34 63  8 25 40 62 52 32 44 64 55 51 33 27 35 50 46  5 19 43 20 24 10 49 26 65 17  7 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 11 33 35  0 28  6 34 41 32  8 24 26 42 25 43 14  5 21 44 38 18 40  4 29 45  9 19 17 16 23 12 22  7 15  1 20 37 36  2 31 39 13  3 27 10], a_shuffle_aclus: [45 19 49 51  3 43 11 50 60 48 15 35 40 62 39 63 23 10 32 64 54 27 56  8 44 65 17 28 26 25 34 20 33 12 24  5 31 53 52  6 46 55 21  7 41 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7 22  3 39 37 27  2 20 35 32  6 23 24 29 34 36  8 44 31 43  9 21 18 40 42 28 10 17 41  0 14 13  5 26 15 16 30 25  1 19  4 33 12 11 45 38], a_shuffle_aclus: [12 33  7 55 53 41  6 31 51 48 11 34 35 44 50 52 15 64 46 63 17 32 27 56 62 43 18 26 60  3 23 21 10 40 24 25 45 39  5 28  8 49 20 19 65 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1 25  9  5 44 33 22 36 43 17 29 23  0 21 20 38  8  3 26 19 12 28 18 39 16 10 30 32 41  4 15  7 31  6 27 34 11 24  2 45 14 42 37 35 40 13], a_shuffle_aclus: [ 5 39 17 10 64 49 33 52 63 26 44 34  3 32 31 54 15  7 40 28 20 43 27 55 25 18 45 48 60  8 24 12 46 11 41 50 19 35  6 65 23 62 53 51 56 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 31 16  6 22 36 42  4 20  7 10 32 24  1  0 43 21  2 19 13 44 30 40  8 15  9 45 23 35 17  5 14 33 37 34 25 38 39 29 28 41 26 12 11  3 18], a_shuffle_aclus: [41 46 25 11 33 52 62  8 31 12 18 48 35  5  3 63 32  6 28 21 64 45 56 15 24 17 65 34 51 26 10 23 49 53 50 39 54 55 44 43 60 40 20 19  7 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 44 27 26 31  3 37 21 11 17  6 22 29 39 13  1  4 18 30 28 16 43 42 41 33 25  7 40 19 36 23 14 15 10 24 45  0  9 20  2  5 32 34 12 35 38], a_shuffle_aclus: [15 64 41 40 46  7 53 32 19 26 11 33 44 55 21  5  8 27 45 43 25 63 62 60 49 39 12 56 28 52 34 23 24 18 35 65  3 17 31  6 10 48 50 20 51 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14  7 39 16 37  1 15 19 27  8  6 18  2 22 45 20 31  0 17 41 44 24 30 40 28 11 32 13 25  3 12  4 26 36  5 34 23 10 29 35 33 38 21  9 42 43], a_shuffle_aclus: [23 12 55 25 53  5 24 28 41 15 11 27  6 33 65 31 46  3 26 60 64 35 45 56 43 19 48 21 39  7 20  8 40 52 10 50 34 18 44 51 49 54 32 17 62 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 43 41  4 33 13 37 10 18 35 21 42 15 39 16 29 34 44 26 14 32 40  0  5 28 27 45 31 12 23  3  1  6 36 22 20 11 24  8  2 25  7 30 38  9 19], a_shuffle_aclus: [26 63 60  8 49 21 53 18 27 51 32 62 24 55 25 44 50 64 40 23 48 56  3 10 43 41 65 46 20 34  7  5 11 52 33 31 19 35 15  6 39 12 45 54 17 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [31 37 14  5 34 39 41 38 42  0  9 32 45 40 12 27 21 44 18 30  4  7 23 17 22 35 26 33 10 16 29 43 19  8 15  6 28 25 20  1 13 36 11  3 24  2], a_shuffle_aclus: [46 53 23 10 50 55 60 54 62  3 17 48 65 56 20 41 32 64 27 45  8 12 34 26 33 51 40 49 18 25 44 63 28 15 24 11 43 39 31  5 21 52 19  7 35  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 32  5 27 42  2  1 26 16 37  3 44 35  8 38 21  6 25  7  0 29  9 28 43 30 17 15 22 23 34 36 10 40 14 13 19 11 31 33 41 18 12  4 24 20 39], a_shuffle_aclus: [65 48 10 41 62  6  5 40 25 53  7 64 51 15 54 32 11 39 12  3 44 17 43 63 45 26 24 33 34 50 52 18 56 23 21 28 19 46 49 60 27 20  8 35 31 55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 29  6 15 23 12 38 17 39  7 14  4  2 30 28 13 35 26 18 40 42 37 44 36 45 34 19 22 27 24 32 33  3  1 10  8  5 41 43  9 31 11 20  0 25 16], a_shuffle_aclus: [32 44 11 24 34 20 54 26 55 12 23  8  6 45 43 21 51 40 27 56 62 53 64 52 65 50 28 33 41 35 48 49  7  5 18 15 10 60 63 17 46 19 31  3 39 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35  4 44  0 23 36 14 28  1 10 45 16  6 17 27 33  9 19 12  7 31  2 30 29 26 34 21 43 40 13 37  3 41 24  8 22 25 38 18 11 39 42  5 32 20 15], a_shuffle_aclus: [51  8 64  3 34 52 23 43  5 18 65 25 11 26 41 49 17 28 20 12 46  6 45 44 40 50 32 63 56 21 53  7 60 35 15 33 39 54 27 19 55 62 10 48 31 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19 27  2  5 13 15 11 16 30 44 18 43  9 25 10 29  3 36 38 23  8 45 20  6 35 26 39 41 12 34 22  0 24 42 40 17 31  1  4 14 33 21  7 37 28 32], a_shuffle_aclus: [28 41  6 10 21 24 19 25 45 64 27 63 17 39 18 44  7 52 54 34 15 65 31 11 51 40 55 60 20 50 33  3 35 62 56 26 46  5  8 23 49 32 12 53 43 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 32 31 15 42 11 33  1  3 41 22 26 10 43 38 21 45  6 34 13 30  9  4 23 19 35 36  8 20 18  2 37 12  5  7 24 25 27 14 16 28 17  0 29 44 40], a_shuffle_aclus: [55 48 46 24 62 19 49  5  7 60 33 40 18 63 54 32 65 11 50 21 45 17  8 34 28 51 52 15 31 27  6 53 20 10 12 35 39 41 23 25 43 26  3 44 64 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 42 23 12 35  2 15 30 27 16 25 13 36  1 37  5 22 26  4 29  8 18 11 33 10 32  0 41 45  7 19 24 40 34 21 14 17 43  6  9 39 31 28 20 44 38], a_shuffle_aclus: [ 7 62 34 20 51  6 24 45 41 25 39 21 52  5 53 10 33 40  8 44 15 27 19 49 18 48  3 60 65 12 28 35 56 50 32 23 26 63 11 17 55 46 43 31 64 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2  8 22  6 13 44 34 42 12 32 43  3 23 33  7 41 29 18 45 27 14 21 37 10 30 31 16  9 35 40 20 11 25 38 24  0  4 39 17 15 26 28 19  1 36  5], a_shuffle_aclus: [ 6 15 33 11 21 64 50 62 20 48 63  7 34 49 12 60 44 27 65 41 23 32 53 18 45 46 25 17 51 56 31 19 39 54 35  3  8 55 26 24 40 43 28  5 52 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15 30 11 26 25  2 20 37 16 18  7  9 27 42  0 23  3  6 29 14 31 43 10 12  5 39  4 13 35 19 40 33  1 34 41 38 45 28 36 44 17  8 22 24 21 32], a_shuffle_aclus: [24 45 19 40 39  6 31 53 25 27 12 17 41 62  3 34  7 11 44 23 46 63 18 20 10 55  8 21 51 28 56 49  5 50 60 54 65 43 52 64 26 15 33 35 32 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39  4 33 14  9 34 21  8 25 19 13  5 38 32 16  3  6 15 35 11 20  2 12 40 17 18 10 31 23 29 28 37 45  1  0  7 41 36 24 30 26 27 22 43 42 44], a_shuffle_aclus: [55  8 49 23 17 50 32 15 39 28 21 10 54 48 25  7 11 24 51 19 31  6 20 56 26 27 18 46 34 44 43 53 65  5  3 12 60 52 35 45 40 41 33 63 62 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 37 27 16  0 43  2 38 11 40 17 35  1 18 36 14 30 19 13  6 10 44 21 12 20 22 26 32 39  4 25 31 33 45  9  3 23 24 42 41 15 34 28  7 29  5], a_shuffle_aclus: [15 53 41 25  3 63  6 54 19 56 26 51  5 27 52 23 45 28 21 11 18 64 32 20 31 33 40 48 55  8 39 46 49 65 17  7 34 35 62 60 24 50 43 12 44 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38 40  1 30 44 27 21 26 31 32  0 15 20 10 22  9  2 19 29 36  6 18 43 14  5 34 24 28 16 35  7 39 23 33 12 25 37 42 11 45 17  4 13 41  8  3], a_shuffle_aclus: [54 56  5 45 64 41 32 40 46 48  3 24 31 18 33 17  6 28 44 52 11 27 63 23 10 50 35 43 25 51 12 55 34 49 20 39 53 62 19 65 26  8 21 60 15  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40  9 44  6 15 13 25 35 26 34 10 29 30 12 38  5  2 31  8  0 21  1 28 22 37  4 27 18 45 14 43 20 36 19 39 33  7 24 41 11 23 32 42 17  3 16], a_shuffle_aclus: [56 17 64 11 24 21 39 51 40 50 18 44 45 20 54 10  6 46 15  3 32  5 43 33 53  8 41 27 65 23 63 31 52 28 55 49 12 35 60 19 34 48 62 26  7 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 23 17 44 39  7 14  5 15 36 45 42 30 31 27 21 33 28 25 19 12 18 13 11  9 34 20 38  2  1 24 37 26  0 29 35  6 16  3 10 40 22  4  8 32 41], a_shuffle_aclus: [63 34 26 64 55 12 23 10 24 52 65 62 45 46 41 32 49 43 39 28 20 27 21 19 17 50 31 54  6  5 35 53 40  3 44 51 11 25  7 18 56 33  8 15 48 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1  2  8 11 14  5 21  6 41  7 15  9 34 23 37 33 31 24 10 16 44 26 40 39  0 42 38 22 36 35 45 17 25  4 27 18 12 20  3 29 28 30 13 19 32 43], a_shuffle_aclus: [ 5  6 15 19 23 10 32 11 60 12 24 17 50 34 53 49 46 35 18 25 64 40 56 55  3 62 54 33 52 51 65 26 39  8 41 27 20 31  7 44 43 45 21 28 48 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19  2 20 43 32 36 28  5 21 26 41 14  6 11 39 25 12  8 35 24 16 13 31 45 42  9 10 27  7  4 22 30 33  1 37 44 15 34  0 18 17 23  3 38 29 40], a_shuffle_aclus: [28  6 31 63 48 52 43 10 32 40 60 23 11 19 55 39 20 15 51 35 25 21 46 65 62 17 18 41 12  8 33 45 49  5 53 64 24 50  3 27 26 34  7 54 44 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33 15 18 25 26 19 34 45 16 32 41 27 36 31 29  6 24  9 28 10 21 14 40 39  1 38 44  3 11 20 12  8  0 43 30  5  4 37 13 17 22 23 35  2  7 42], a_shuffle_aclus: [49 24 27 39 40 28 50 65 25 48 60 41 52 46 44 11 35 17 43 18 32 23 56 55  5 54 64  7 19 31 20 15  3 63 45 10  8 53 21 26 33 34 51  6 12 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 17  5 35 13  7 24 32 41 23 43  4  1  2 39 44 19  3 26 22 10  6 11 21 45 27  8 42 34 29 38 33 40 37 16 12 20 15 31 28 30  0 25 36  9 14], a_shuffle_aclus: [27 26 10 51 21 12 35 48 60 34 63  8  5  6 55 64 28  7 40 33 18 11 19 32 65 41 15 62 50 44 54 49 56 53 25 20 31 24 46 43 45  3 39 52 17 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32  9  2 30 19 11 15 13 10 23 33  0 42  8 40 44 35 43 39 25  6 20 12 37 22  3  7 16 28 31 17 34 41  4 14 24 27  1 38 21 18 29 45 36 26  5], a_shuffle_aclus: [48 17  6 45 28 19 24 21 18 34 49  3 62 15 56 64 51 63 55 39 11 31 20 53 33  7 12 25 43 46 26 50 60  8 23 35 41  5 54 32 27 44 65 52 40 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 45 39 32 26 21 34 25 22 29 18 42 11 28  5 36 13 44 43 27 14 33 31 16 41 20 23  6 30 10  2 17  4 38  8 19  1 40 24  9 15  3  0 37 35  7], a_shuffle_aclus: [20 65 55 48 40 32 50 39 33 44 27 62 19 43 10 52 21 64 63 41 23 49 46 25 60 31 34 11 45 18  6 26  8 54 15 28  5 56 35 17 24  7  3 53 51 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 29 37 25 21 35 17  7 20 24  4 13 42 27 10 34 28  1  5 44 31 43  9 39  0  6 26 16 41 18  2 30 22 15 40  3 33 38 23 36 45 11 32  8 12 19], a_shuffle_aclus: [23 44 53 39 32 51 26 12 31 35  8 21 62 41 18 50 43  5 10 64 46 63 17 55  3 11 40 25 60 27  6 45 33 24 56  7 49 54 34 52 65 19 48 15 20 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 35 26  0  1 29 19 39 10 38 22  2 20 18 37  8 41 30 42 33 11 17 24 43 27  7  3  6  4 13 45 28 40  5 21 14  9 16 31 15 44 25 32 34 23 12], a_shuffle_aclus: [52 51 40  3  5 44 28 55 18 54 33  6 31 27 53 15 60 45 62 49 19 26 35 63 41 12  7 11  8 21 65 43 56 10 32 23 17 25 46 24 64 39 48 50 34 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 31 34  3 30  1 24 40  5  0 25  4 36 19 17 44 29  6 14 23 22 39 20 18 12 41 27 35 26  9  2 10 15 45 33 21  8 37 42  7 16 28 32 11 38 43], a_shuffle_aclus: [21 46 50  7 45  5 35 56 10  3 39  8 52 28 26 64 44 11 23 34 33 55 31 27 20 60 41 51 40 17  6 18 24 65 49 32 15 53 62 12 25 43 48 19 54 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41 45 25 40 15 20 21 36 18 31 19 27  8  7  2 30 43  9 11 35 32  5 16 33 13 26 23 38  6 12 22 10  3  0 24 28 34 44 14  1 17  4 37 39 42 29], a_shuffle_aclus: [60 65 39 56 24 31 32 52 27 46 28 41 15 12  6 45 63 17 19 51 48 10 25 49 21 40 34 54 11 20 33 18  7  3 35 43 50 64 23  5 26  8 53 55 62 44]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 40 31 29 11 45  2  9 35 26 24 23 21 42 14  4 18 43 25 16 34 17  6  3  7 12 22  0 30 36 37 39 10 33 32 20 44 13  8  5 38 41  1 28 19 15], a_shuffle_aclus: [41 56 46 44 19 65  6 17 51 40 35 34 32 62 23  8 27 63 39 25 50 26 11  7 12 20 33  3 45 52 53 55 18 49 48 31 64 21 15 10 54 60  5 43 28 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 45 42 44  0 30 20 28 19 38 21 22 27  2 18 13 15 14 29 36  6 39 10 35  7 32  9  1 31  5 16  3 11 40 26 34 43 33  8 25 24 17 12 37  4 41], a_shuffle_aclus: [34 65 62 64  3 45 31 43 28 54 32 33 41  6 27 21 24 23 44 52 11 55 18 51 12 48 17  5 46 10 25  7 19 56 40 50 63 49 15 39 35 26 20 53  8 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 43 22 30 14 42 27 35 23  9 38 24  1 29 28  7  2 45 10 36 21 41 33 26  3  8 31  5 19 20 13  0 37  4 16 17 39 32 12 18 25 15  6 34 40 44], a_shuffle_aclus: [19 63 33 45 23 62 41 51 34 17 54 35  5 44 43 12  6 65 18 52 32 60 49 40  7 15 46 10 28 31 21  3 53  8 25 26 55 48 20 27 39 24 11 50 56 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 34 27 20  5 19 31 11 43 12 42  1  9 38 32 23 25 30 35 22 14  2 15 33 45 21 39 26 37 41  3  6  4 40 44  0  8  7 17 13 29 18 10 16 28 24], a_shuffle_aclus: [52 50 41 31 10 28 46 19 63 20 62  5 17 54 48 34 39 45 51 33 23  6 24 49 65 32 55 40 53 60  7 11  8 56 64  3 15 12 26 21 44 27 18 25 43 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30  4 12 38 35  3 43 22  6 10 37  0 21  5 41 40 15 39 18 26 42 24  8 25 36  2 29 11  1 16 28 17 32 44 31 45  9 20 13 19 14  7 33 34 23 27], a_shuffle_aclus: [45  8 20 54 51  7 63 33 11 18 53  3 32 10 60 56 24 55 27 40 62 35 15 39 52  6 44 19  5 25 43 26 48 64 46 65 17 31 21 28 23 12 49 50 34 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 17 24 35 41 36 19 31 25  2 27 11 29  7  6 13 10 23  5  9  8 37 44 33 30 40 22  3  4 28 42 38 18 26 21 34 43 45 15  0 32 12  1 16 20 14], a_shuffle_aclus: [55 26 35 51 60 52 28 46 39  6 41 19 44 12 11 21 18 34 10 17 15 53 64 49 45 56 33  7  8 43 62 54 27 40 32 50 63 65 24  3 48 20  5 25 31 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29  4 30 36 13 27 44  7  0 20 21  1 31  9 17  3 33 42 23 43 22 11 32  2 28 26 12 25 39  8 45 14 34 15 37 41 40  6 19 10 16 18 38 35 24  5], a_shuffle_aclus: [44  8 45 52 21 41 64 12  3 31 32  5 46 17 26  7 49 62 34 63 33 19 48  6 43 40 20 39 55 15 65 23 50 24 53 60 56 11 28 18 25 27 54 51 35 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 28  5 22 43  3 44 37 31 24 10 23 15 33  2 34 17 45  0 27 42 32  6  4  7 26 19 36  8  1 11 20 14 25 39 21  9 40 12 18 35 38 30 29 41 16], a_shuffle_aclus: [21 43 10 33 63  7 64 53 46 35 18 34 24 49  6 50 26 65  3 41 62 48 11  8 12 40 28 52 15  5 19 31 23 39 55 32 17 56 20 27 51 54 45 44 60 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 23  5  1 18 32 22 39 13 17 44 45  6  3 33 43 21 24 11  0  4  9 28 25 12 41 38 30 42 19 14 27  8 36 16 40 37 15 26 29 35 34 20 31 10  7], a_shuffle_aclus: [ 6 34 10  5 27 48 33 55 21 26 64 65 11  7 49 63 32 35 19  3  8 17 43 39 20 60 54 45 62 28 23 41 15 52 25 56 53 24 40 44 51 50 31 46 18 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14  8  3 37  2 19 28 29 40 44 25 10  9 36 16 39 26 41 21 22 32  5 20  7 11 31 24 30 18 23  1 27 38 35  0 12 13 45 33 42  6 15  4 34 43 17], a_shuffle_aclus: [23 15  7 53  6 28 43 44 56 64 39 18 17 52 25 55 40 60 32 33 48 10 31 12 19 46 35 45 27 34  5 41 54 51  3 20 21 65 49 62 11 24  8 50 63 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 31 19 28 40 41  6 26 15 12  2 21  4 23 30 42  7 16 24 39 37 27 29  1 22  3  0 45 13 33 11 35 18 44 38 25 17 43  8 36 34 32 14  9 20  5], a_shuffle_aclus: [18 46 28 43 56 60 11 40 24 20  6 32  8 34 45 62 12 25 35 55 53 41 44  5 33  7  3 65 21 49 19 51 27 64 54 39 26 63 15 52 50 48 23 17 31 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40 10 21 23 39 24  3  0  6 28 45 30 19 42 41 15 26 11  2 44 38 33 34 31  4  5 29 18  8 13  7 43  9 17 36 14 37 12 25 32 16 20 22  1 35 27], a_shuffle_aclus: [56 18 32 34 55 35  7  3 11 43 65 45 28 62 60 24 40 19  6 64 54 49 50 46  8 10 44 27 15 21 12 63 17 26 52 23 53 20 39 48 25 31 33  5 51 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 43 17 16 29 24  8 28 27 23 33  1  2 20 12 38 30 31 39 44 14 41 42  7  4 18 21 45  5 11 37  9  0 40 35  3 36 13 25 22 32 34 19 26 15  6], a_shuffle_aclus: [18 63 26 25 44 35 15 43 41 34 49  5  6 31 20 54 45 46 55 64 23 60 62 12  8 27 32 65 10 19 53 17  3 56 51  7 52 21 39 33 48 50 28 40 24 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 19 33  7 15 24  8 29  5 32 31  4 45 25 10 18 17  6 11 37 39 43  0 12 30 23 42 26 20 22 21 27 36 16  1  2 28 41  9 34 40 44 38 35 13 14], a_shuffle_aclus: [ 7 28 49 12 24 35 15 44 10 48 46  8 65 39 18 27 26 11 19 53 55 63  3 20 45 34 62 40 31 33 32 41 52 25  5  6 43 60 17 50 56 64 54 51 21 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24  1 12 40 21 22 16  6 37  9 14 31  4 36 38 43 15 13 33  7 26 28 11  2 29 35 27  3  5 45 30 25 19  0 32 17 20 10  8 44 34 18 41 42 23 39], a_shuffle_aclus: [35  5 20 56 32 33 25 11 53 17 23 46  8 52 54 63 24 21 49 12 40 43 19  6 44 51 41  7 10 65 45 39 28  3 48 26 31 18 15 64 50 27 60 62 34 55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15 22 32 17 21 27 11 25 18 37 35 30 16  2 41 23 20 34 33 42  3 28 12  1  4 24 45 19  0 39 13 38 10  8  7 31  6 26 43  9  5 44 29 14 40 36], a_shuffle_aclus: [24 33 48 26 32 41 19 39 27 53 51 45 25  6 60 34 31 50 49 62  7 43 20  5  8 35 65 28  3 55 21 54 18 15 12 46 11 40 63 17 10 64 44 23 56 52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 14 25 35 10 24 13 37  7 42 30 29 44  2 21 36 34 12 38  0  5 45 11 16 15 17 28 39 19  1  8 33 18 22 31  3 20  6 43 41 40 23  9 27 26 32], a_shuffle_aclus: [ 8 23 39 51 18 35 21 53 12 62 45 44 64  6 32 52 50 20 54  3 10 65 19 25 24 26 43 55 28  5 15 49 27 33 46  7 31 11 63 60 56 34 17 41 40 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 20 13 41 32 22 44 15  6 14 37  5 36 45 35 39 23 38  4  2 25 33 16 42  8  1 26 27 30 19  0 18 12 10 11 43  9 34  3 29 31 17 40 28 21  7], a_shuffle_aclus: [35 31 21 60 48 33 64 24 11 23 53 10 52 65 51 55 34 54  8  6 39 49 25 62 15  5 40 41 45 28  3 27 20 18 19 63 17 50  7 44 46 26 56 43 32 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38  0 42 12 15 14 17 35 43 29 23  7 18 11 36 31  1 30 28 22  9  2 27 16 26 44 10 19 24  3  6 40 25 33  8 13 32 34 21 39 45  4 41  5 37 20], a_shuffle_aclus: [54  3 62 20 24 23 26 51 63 44 34 12 27 19 52 46  5 45 43 33 17  6 41 25 40 64 18 28 35  7 11 56 39 49 15 21 48 50 32 55 65  8 60 10 53 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42  2 24 27 38  6 14 33  8  4  1 22 18 32 23 28 30 35 26 40 17  5 15 29  7 39 36  3 44 10 16 37 20 34 45 25 41 43  0 13 19 21 11 12  9 31], a_shuffle_aclus: [62  6 35 41 54 11 23 49 15  8  5 33 27 48 34 43 45 51 40 56 26 10 24 44 12 55 52  7 64 18 25 53 31 50 65 39 60 63  3 21 28 32 19 20 17 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13  5  2 40 25 23 12 22 44 20 15 17 18 27 38 21 33 28 32  3 36  6 43 35  8  1 41 42 30 37  7 14  0 19 24 26 10 45 11 29 16 34  4 39  9 31], a_shuffle_aclus: [21 10  6 56 39 34 20 33 64 31 24 26 27 41 54 32 49 43 48  7 52 11 63 51 15  5 60 62 45 53 12 23  3 28 35 40 18 65 19 44 25 50  8 55 17 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 41 36 31 42 13 44 30  0 35 11 17 37  5 20 40 23  6  3 10 22 24  7 12 19  1 43 39 38 29 34 32 26 16 27 28 25 21  2 18  4 15 14  9  8 33], a_shuffle_aclus: [65 60 52 46 62 21 64 45  3 51 19 26 53 10 31 56 34 11  7 18 33 35 12 20 28  5 63 55 54 44 50 48 40 25 41 43 39 32  6 27  8 24 23 17 15 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 22 14 26 33 23  3 36  8 40 41  5 18 34  7  9  6 42  1 28 17  0 32 12 38 45 24 39 37 20 25 27 15 19 11 31 35 10  2 44 16  4 30 13 29 21], a_shuffle_aclus: [63 33 23 40 49 34  7 52 15 56 60 10 27 50 12 17 11 62  5 43 26  3 48 20 54 65 35 55 53 31 39 41 24 28 19 46 51 18  6 64 25  8 45 21 44 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 37 22 27  1 38 21 26 35 24  2 31 15 11  0 23 14 32  7  9 28 20 41 29  6 10  5 44  8 39 30 45 40 34 19 43 42 12 13 33 17 18  3 16 25  4], a_shuffle_aclus: [52 53 33 41  5 54 32 40 51 35  6 46 24 19  3 34 23 48 12 17 43 31 60 44 11 18 10 64 15 55 45 65 56 50 28 63 62 20 21 49 26 27  7 25 39  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 28 33 36 23 31 12 34 32 44 18 38  2  0 11 22 40 14  9 35 37 16 17 10 42 20  4  6 25 26 45 43 27 21 19  3  8  1 24  5 29  7 30 39 15 41], a_shuffle_aclus: [21 43 49 52 34 46 20 50 48 64 27 54  6  3 19 33 56 23 17 51 53 25 26 18 62 31  8 11 39 40 65 63 41 32 28  7 15  5 35 10 44 12 45 55 24 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 30 29 33 41 16 20 24 17  8 15 34 25 22  6 44 11 18 37 38  5  7 10  2 36  4 19 23 27 42 39 43 14 28  9  3 40 35 13 45 21 26 12 32 31  1], a_shuffle_aclus: [ 3 45 44 49 60 25 31 35 26 15 24 50 39 33 11 64 19 27 53 54 10 12 18  6 52  8 28 34 41 62 55 63 23 43 17  7 56 51 21 65 32 40 20 48 46  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 19 27 15  9 29 37 28 26 17 45 41  0 35 21 16 36 22  3 42  5 33 24 12 10  1  4 18  2 11  8 13 44  7 25 32 14 30 38 31 20 39 40 34 43  6], a_shuffle_aclus: [34 28 41 24 17 44 53 43 40 26 65 60  3 51 32 25 52 33  7 62 10 49 35 20 18  5  8 27  6 19 15 21 64 12 39 48 23 45 54 46 31 55 56 50 63 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 26 23 34  5 40 18 36 17 15 11 42 37  3 32 28 20 38  9 30 43 31 27  0 41 12 29  4 44  7 25 16 24 21 19  6 14 22 39 10  1 13 33  8  2 45], a_shuffle_aclus: [51 40 34 50 10 56 27 52 26 24 19 62 53  7 48 43 31 54 17 45 63 46 41  3 60 20 44  8 64 12 39 25 35 32 28 11 23 33 55 18  5 21 49 15  6 65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 21 16 40  5 31  3  9 13 15 20 12 45  6 32 37 18 30 23 33 44 24 41 14  7 39 28 34 29 38 17 27  1 42  0 11 10 22 43 19 36 25  2  4 26 35], a_shuffle_aclus: [15 32 25 56 10 46  7 17 21 24 31 20 65 11 48 53 27 45 34 49 64 35 60 23 12 55 43 50 44 54 26 41  5 62  3 19 18 33 63 28 52 39  6  8 40 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 17  8 33  0 29 20  4 11 19 45 32 15 43 35 21 26 39 41 40 31 37 10 16 34 30 38  2  6 36 27 22  1 44  9  5 12  7 25 18 24  3 14 23 13 42], a_shuffle_aclus: [43 26 15 49  3 44 31  8 19 28 65 48 24 63 51 32 40 55 60 56 46 53 18 25 50 45 54  6 11 52 41 33  5 64 17 10 20 12 39 27 35  7 23 34 21 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23  6 33  0 14 35 16 24 20 29  1 32 26 18 15 12 28 30 27 31 11 17  5 39 45 34 25 41  3 43 42 13 44 38 21 37 36  8 10  9 19  4  7 22 40  2], a_shuffle_aclus: [34 11 49  3 23 51 25 35 31 44  5 48 40 27 24 20 43 45 41 46 19 26 10 55 65 50 39 60  7 63 62 21 64 54 32 53 52 15 18 17 28  8 12 33 56  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [16 42  3 40 36 33 11 44 43 19 26 30  9 35 21 23  2 15 14  1 37 29 31 18  5 20 34 27 13 45 39 32 24  7  0  8 10  4 22  6 25 17 12 41 38 28], a_shuffle_aclus: [25 62  7 56 52 49 19 64 63 28 40 45 17 51 32 34  6 24 23  5 53 44 46 27 10 31 50 41 21 65 55 48 35 12  3 15 18  8 33 11 39 26 20 60 54 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 32 10 12 42 15  0 22 30 36  9  3 24 14 16 21 31 41 19 45 18 33  8  1 29 35 20 27  2  4 39 34 44 40 28 43 37  5  7 23  6 11 38 26 17 13], a_shuffle_aclus: [39 48 18 20 62 24  3 33 45 52 17  7 35 23 25 32 46 60 28 65 27 49 15  5 44 51 31 41  6  8 55 50 64 56 43 63 53 10 12 34 11 19 54 40 26 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 15 35 26  9 36 20  0 12 19 33 23 18 21 24 39 14 27 29 41  2 22 44  7 31 40  6 45 10 28 37 32 25  8 16 11 38 30 34 42  1  3 43 13  4 17], a_shuffle_aclus: [10 24 51 40 17 52 31  3 20 28 49 34 27 32 35 55 23 41 44 60  6 33 64 12 46 56 11 65 18 43 53 48 39 15 25 19 54 45 50 62  5  7 63 21  8 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 26  3 12 30 17 11 31 40 13 22 10 34 45 18  0 28  1  6 20 37 23 39  8 32 25 19  4 44 16 42 15  2 27 43 29 38 41 36 24 14 33 21  7  5 35], a_shuffle_aclus: [17 40  7 20 45 26 19 46 56 21 33 18 50 65 27  3 43  5 11 31 53 34 55 15 48 39 28  8 64 25 62 24  6 41 63 44 54 60 52 35 23 49 32 12 10 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 37 25 21 38  9 26  5 42 19 31  7 16 24  2 30 44 36 12 11 34 45 10  3 43  4 27 14 33  8 15 32 17 41 13  6 22 29 23 40 18 20 39  0  1 35], a_shuffle_aclus: [43 53 39 32 54 17 40 10 62 28 46 12 25 35  6 45 64 52 20 19 50 65 18  7 63  8 41 23 49 15 24 48 26 60 21 11 33 44 34 56 27 31 55  3  5 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1 22 34 10 23 31 14 35 36 45 17 28 33 42  8 39 11 13 21 19 25 12  4 44 40 43  9 29 27  5 37  3  2 30 24 15 38 32 41  7  6  0 18 16 26 20], a_shuffle_aclus: [ 5 33 50 18 34 46 23 51 52 65 26 43 49 62 15 55 19 21 32 28 39 20  8 64 56 63 17 44 41 10 53  7  6 45 35 24 54 48 60 12 11  3 27 25 40 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 17 38 14 21 22 27 19 11 40  2  1  7  4 23 41 13 33 36 25  6 34 44 12 28  5  9 20  0 15 24 39 45 37  8 42 16 10 30 26  3 18 35 29 32 31], a_shuffle_aclus: [63 26 54 23 32 33 41 28 19 56  6  5 12  8 34 60 21 49 52 39 11 50 64 20 43 10 17 31  3 24 35 55 65 53 15 62 25 18 45 40  7 27 51 44 48 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 28  5 12 36  1  9 41 18 32 43  7 22 42 10 38 14 13 44 45 35 15 17 24 21 39 29 20  8 25 34 26 23  6 33 11  0  3 40 19 31  4 37  2 30 16], a_shuffle_aclus: [41 43 10 20 52  5 17 60 27 48 63 12 33 62 18 54 23 21 64 65 51 24 26 35 32 55 44 31 15 39 50 40 34 11 49 19  3  7 56 28 46  8 53  6 45 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 17  7 30 12 45 10 23 28 25 34 32 11 24  4  8  2 41 43  6 14 29 13 21 16  0 39 37  5 40  9 18 38 22  3 20 36 19 42 33 26  1 44 35 15 31], a_shuffle_aclus: [41 26 12 45 20 65 18 34 43 39 50 48 19 35  8 15  6 60 63 11 23 44 21 32 25  3 55 53 10 56 17 27 54 33  7 31 52 28 62 49 40  5 64 51 24 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 32 15 31 25 16  7 27 18 22 20 26 44 29  4  2  1 38  6 13 41  5 10 21 39 17 45 24 36 34 11  8 23 43  0  9 33 28 19 40 14 12  3 42 35 30], a_shuffle_aclus: [53 48 24 46 39 25 12 41 27 33 31 40 64 44  8  6  5 54 11 21 60 10 18 32 55 26 65 35 52 50 19 15 34 63  3 17 49 43 28 56 23 20  7 62 51 45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 37  2 29 33 36  9 21 45 31 11 30 35 39 16  1 28 12 23 10 13 15 38  3 41 22 20  7 43 40 24  6  5 32 42 27  8 19 34 44  0 25 26  4 14 17], a_shuffle_aclus: [27 53  6 44 49 52 17 32 65 46 19 45 51 55 25  5 43 20 34 18 21 24 54  7 60 33 31 12 63 56 35 11 10 48 62 41 15 28 50 64  3 39 40  8 23 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7  6 44 42 37 39 17 20 18  4  0  9 45 28 15 13 19 40  3 24 12 14 31 29 16 26  8 41 38 21 10 30 32 11 36 33 35 25 43  1 23 27 22  5 34  2], a_shuffle_aclus: [12 11 64 62 53 55 26 31 27  8  3 17 65 43 24 21 28 56  7 35 20 23 46 44 25 40 15 60 54 32 18 45 48 19 52 49 51 39 63  5 34 41 33 10 50  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 30  3  1 14  6  2 22  9 45 28 41 27 32 36 16 18 11 12 29 31 34 26  5 25  7 33 20 15 23 13 42 17 10  0 44 21 19 40 24  8 35 39  4 37 38], a_shuffle_aclus: [63 45  7  5 23 11  6 33 17 65 43 60 41 48 52 25 27 19 20 44 46 50 40 10 39 12 49 31 24 34 21 62 26 18  3 64 32 28 56 35 15 51 55  8 53 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 22 25 18 32  6  0 36 20 45 29 39 11 31 24  2 33 23 15 10 44  5 30  1 40 34 37 19 35 28 17 41 16 21  8 27 14  7 13 38 26 42 43 12  3  4], a_shuffle_aclus: [17 33 39 27 48 11  3 52 31 65 44 55 19 46 35  6 49 34 24 18 64 10 45  5 56 50 53 28 51 43 26 60 25 32 15 41 23 12 21 54 40 62 63 20  7  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7 12 29 18 32  4 13 14 10 31 41 43 20  6  3 33 22 28 38 15 34  1 25 26  8 39 21 30 27 11 42 16 23 44 36 37 35  2 45 24 17  5  0 19  9 40], a_shuffle_aclus: [12 20 44 27 48  8 21 23 18 46 60 63 31 11  7 49 33 43 54 24 50  5 39 40 15 55 32 45 41 19 62 25 34 64 52 53 51  6 65 35 26 10  3 28 17 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 30 34 19 15 29  4 12 14 45 39  3 16  9 25 43 32 13  8  5 35  7 23 21 11 33 42 24 31 44  2 38  6  0 17 18 20 27 28 22 10  1 37 41 26 40], a_shuffle_aclus: [52 45 50 28 24 44  8 20 23 65 55  7 25 17 39 63 48 21 15 10 51 12 34 32 19 49 62 35 46 64  6 54 11  3 26 27 31 41 43 33 18  5 53 60 40 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 25 42 19  4 26 31 38 13 28 22 12 30  1 10  7  5 45 21 27  0 14  3 40 16 43 15 39 20 44  9 32  6  2 41 23 24 37 33 11 36 17 29 35  8 18], a_shuffle_aclus: [50 39 62 28  8 40 46 54 21 43 33 20 45  5 18 12 10 65 32 41  3 23  7 56 25 63 24 55 31 64 17 48 11  6 60 34 35 53 49 19 52 26 44 51 15 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 43  5 26 14 35 12 23 36 28  7 17 33  1 19 38 25  6 42 45  0 41 39 32 27  3  4 29 18 16 10  8 21 34 22 31 44 40 11 30 37 20 13 24  2 15], a_shuffle_aclus: [17 63 10 40 23 51 20 34 52 43 12 26 49  5 28 54 39 11 62 65  3 60 55 48 41  7  8 44 27 25 18 15 32 50 33 46 64 56 19 45 53 31 21 35  6 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 37 40 19 14  2  8 29  4  5 20 42 27 10 16  9 13 41 36 18 17 15 24 43  0 22 34  7 45 39 23  6 21 33 38 32 28  3 44 12 30 31 26 11  1 35], a_shuffle_aclus: [39 53 56 28 23  6 15 44  8 10 31 62 41 18 25 17 21 60 52 27 26 24 35 63  3 33 50 12 65 55 34 11 32 49 54 48 43  7 64 20 45 46 40 19  5 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 27 43 16 18 22 10 35 29 41 28 13 30 19 31 40 23  8 20 12  3  1 26 38  0 36  6 21  4 37 44 32 14  2  9  7 25 45 33 24 15 34  5 11 39 17], a_shuffle_aclus: [62 41 63 25 27 33 18 51 44 60 43 21 45 28 46 56 34 15 31 20  7  5 40 54  3 52 11 32  8 53 64 48 23  6 17 12 39 65 49 35 24 50 10 19 55 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [26 39  1 18  2  9 23 13 41 34 16 38 32 10 11 19 44 15 42  0 17 21 24 14 12  8 40  6 28 22 25  7 20 30 33 29  4 43 36  5 35 27  3 37 45 31], a_shuffle_aclus: [40 55  5 27  6 17 34 21 60 50 25 54 48 18 19 28 64 24 62  3 26 32 35 23 20 15 56 11 43 33 39 12 31 45 49 44  8 63 52 10 51 41  7 53 65 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 44 26 42 19  8  5 23 20 25  7  2 16 13 22 24 32 41  1 35 45 17  3  0 11 36 30 34 27 18 43 31 33 15 40 38 29 14  4  9 10 21  6 12 37 28], a_shuffle_aclus: [55 64 40 62 28 15 10 34 31 39 12  6 25 21 33 35 48 60  5 51 65 26  7  3 19 52 45 50 41 27 63 46 49 24 56 54 44 23  8 17 18 32 11 20 53 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8  0 28  2 32 12 42 10  3 23 20 38 29 44 18 36 31 26 40 27 37  1  5 24 21 34 41 13 33 30 25 14 45 39  6 35 22  7 17 11 43  4  9 16 15 19], a_shuffle_aclus: [15  3 43  6 48 20 62 18  7 34 31 54 44 64 27 52 46 40 56 41 53  5 10 35 32 50 60 21 49 45 39 23 65 55 11 51 33 12 26 19 63  8 17 25 24 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 20 23 40 12 45  9 37 38 35  3 22 29  4  7 25  6 15 41 19 13 26 42  2 10  0 18 27 36 34 21 33 39  8 14 11  1 17 24 44 28 31 16 32 30 43], a_shuffle_aclus: [10 31 34 56 20 65 17 53 54 51  7 33 44  8 12 39 11 24 60 28 21 40 62  6 18  3 27 41 52 50 32 49 55 15 23 19  5 26 35 64 43 46 25 48 45 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 43  0 26 35 34 41 32  1 45  3  2 33 24 11 38 37 28 19 42 27 13 15  9 14 17 40 23  6 29 16 12 21 31 39  5 10 30 44  8 36 22 20 18 25  7], a_shuffle_aclus: [ 8 63  3 40 51 50 60 48  5 65  7  6 49 35 19 54 53 43 28 62 41 21 24 17 23 26 56 34 11 44 25 20 32 46 55 10 18 45 64 15 52 33 31 27 39 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 14 24  7 36  3 21 15  5 43 34 16 13 42  6  0 26 17 32 25 23  4  9 45 18 35 33 22 30 44 29 40 12 20 38 28  8 39 19  1 10 31 41  2 11 37], a_shuffle_aclus: [41 23 35 12 52  7 32 24 10 63 50 25 21 62 11  3 40 26 48 39 34  8 17 65 27 51 49 33 45 64 44 56 20 31 54 43 15 55 28  5 18 46 60  6 19 53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 22 24  4 42 13  1 40 20 37  0 12  6 23 11 32 45  3  9 27 15 34 14 26 31 28 39 44 36 25  2  8 17 43 38 29 41 10 21  5  7 19 18 33 30 16], a_shuffle_aclus: [51 33 35  8 62 21  5 56 31 53  3 20 11 34 19 48 65  7 17 41 24 50 23 40 46 43 55 64 52 39  6 15 26 63 54 44 60 18 32 10 12 28 27 49 45 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 37 39 24 18  0 28  1 21 25 20 22 35 32 13 16 12 17  5 29  4 33 10  9  6 42 30 14 34  8 15  2 41  7 23 36 43 19 31 44 45  3 26 40 38 11], a_shuffle_aclus: [41 53 55 35 27  3 43  5 32 39 31 33 51 48 21 25 20 26 10 44  8 49 18 17 11 62 45 23 50 15 24  6 60 12 34 52 63 28 46 64 65  7 40 56 54 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19 35 16  2 17 41 27 28 40 33  5 34  6 22  4 45 29 24 13 42 12 43  1 20 44 30  7 11 32  9 36 31  3 37 38 18 15 21 14 39 23  8 26 10  0 25], a_shuffle_aclus: [28 51 25  6 26 60 41 43 56 49 10 50 11 33  8 65 44 35 21 62 20 63  5 31 64 45 12 19 48 17 52 46  7 53 54 27 24 32 23 55 34 15 40 18  3 39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 13 27 21 40 25 34 33 31 30 24 43  5 11 32 15 42 45 19  1 29 20  6  8 22 41  9 26  3 44  7 37 14 23 36 35 28 38 12 18 39 16  2 17  0 10], a_shuffle_aclus: [ 8 21 41 32 56 39 50 49 46 45 35 63 10 19 48 24 62 65 28  5 44 31 11 15 33 60 17 40  7 64 12 53 23 34 52 51 43 54 20 27 55 25  6 26  3 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1  5 43 25 40  6 45 18 32 35 37 26 21 44  9 41 17 19 15 42  3 27 23 11 13 39 33 24 29 10 38 36  8 14  0 12 22  4  2 31 20 30 28 16  7 34], a_shuffle_aclus: [ 5 10 63 39 56 11 65 27 48 51 53 40 32 64 17 60 26 28 24 62  7 41 34 19 21 55 49 35 44 18 54 52 15 23  3 20 33  8  6 46 31 45 43 25 12 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38 36 12 22 43 31 14 15  2 10 11 26 17 39  0 42 35  1 23 27 44 41 25 19 20  9 18 28  3 16 34  7 24  4 30  6 40 29 21 37 32 13 45 33  8  5], a_shuffle_aclus: [54 52 20 33 63 46 23 24  6 18 19 40 26 55  3 62 51  5 34 41 64 60 39 28 31 17 27 43  7 25 50 12 35  8 45 11 56 44 32 53 48 21 65 49 15 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8  7  1 23  9 26 30 10 45 41 31 21 28 18 33 37 14 15 19 24  2 36 20 22  6 42 16 17 11 38 43 12 39 25 35 44  4 13 27  0  5 34 40  3 32 29], a_shuffle_aclus: [15 12  5 34 17 40 45 18 65 60 46 32 43 27 49 53 23 24 28 35  6 52 31 33 11 62 25 26 19 54 63 20 55 39 51 64  8 21 41  3 10 50 56  7 48 44]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 34  0 18 12 25 39 27 20 45 37 32 44 19 14  4  2 28 29 33  1  8  6 26 13 21 40 15 11 41  9 22 10 23  7 38 42 16  3 24 30 36 31 35 43  5], a_shuffle_aclus: [26 50  3 27 20 39 55 41 31 65 53 48 64 28 23  8  6 43 44 49  5 15 11 40 21 32 56 24 19 60 17 33 18 34 12 54 62 25  7 35 45 52 46 51 63 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 24  3 42 23 41  1  0 20 25 45 12 44 33 32 16 28 31 19  6 11 40 26 39 43  9 22 37 38 27  4  8 21 18 30 10 36 17  7  5 29  2 15 14 34 13], a_shuffle_aclus: [51 35  7 62 34 60  5  3 31 39 65 20 64 49 48 25 43 46 28 11 19 56 40 55 63 17 33 53 54 41  8 15 32 27 45 18 52 26 12 10 44  6 24 23 50 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8  6 37 18 29 19  7 13  1 27 17 12 41 40 38 23 42 43 26 36 44 11 21  4 10 33  2 32 31 30 25 35  0  3 28 45 20 14 24  9 22  5 39 15 16 34], a_shuffle_aclus: [15 11 53 27 44 28 12 21  5 41 26 20 60 56 54 34 62 63 40 52 64 19 32  8 18 49  6 48 46 45 39 51  3  7 43 65 31 23 35 17 33 10 55 24 25 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 13  3 20 15 12 29  5 41 44 30 38  7 16  0 28 42 45 22 21 24 43 35 40 19 14 36 10 34 25 18 32  2 26 27 39 11 31  6 23 37  9 17  1 33  8], a_shuffle_aclus: [ 8 21  7 31 24 20 44 10 60 64 45 54 12 25  3 43 62 65 33 32 35 63 51 56 28 23 52 18 50 39 27 48  6 40 41 55 19 46 11 34 53 17 26  5 49 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 31 16 33 30 15  0 22 40 25 28 35 43 26  5  1  6 29 45  7 36 41 20 10 11 21  9 27  2  8 19 44  3 37 13 32 18 34 39 24 38  4 23 12 14 17], a_shuffle_aclus: [62 46 25 49 45 24  3 33 56 39 43 51 63 40 10  5 11 44 65 12 52 60 31 18 19 32 17 41  6 15 28 64  7 53 21 48 27 50 55 35 54  8 34 20 23 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 22 12 36 30 23 37 21 40 27 25  5  4 14 26 45  8  1 24 20 33  3 29 13 35 17 32 44 38 34  7 10 31 41 28 42  6 19  0  2 16 11 18 15 39 43], a_shuffle_aclus: [17 33 20 52 45 34 53 32 56 41 39 10  8 23 40 65 15  5 35 31 49  7 44 21 51 26 48 64 54 50 12 18 46 60 43 62 11 28  3  6 25 19 27 24 55 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 38  7 21 14 10 43 15 20 45  8 33  2 36 25  3 13 39 32 27 12 44 11 19 28 31 42 37 22 40 30 24  0 16 26  6 18  1  9 41 35 17  4 23 34  5], a_shuffle_aclus: [44 54 12 32 23 18 63 24 31 65 15 49  6 52 39  7 21 55 48 41 20 64 19 28 43 46 62 53 33 56 45 35  3 25 40 11 27  5 17 60 51 26  8 34 50 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19 28 39 24 44  1  6 36  4  9  7 12  2 45 29 17 21 25  3 40 43 11 34 38  5 37 26 32 14  0 35 15 13 23 41 18 27 22 20 31 33 16 10 42 30  8], a_shuffle_aclus: [28 43 55 35 64  5 11 52  8 17 12 20  6 65 44 26 32 39  7 56 63 19 50 54 10 53 40 48 23  3 51 24 21 34 60 27 41 33 31 46 49 25 18 62 45 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0  3 42 29 43 17 19 12 45 13 41 40 24  4  9  5 15 39 23 37 14 30  1 27 22 34  8  7  6 35 26 31 25 21 33  2 11 10 20 36 28 44 32 18 38 16], a_shuffle_aclus: [ 3  7 62 44 63 26 28 20 65 21 60 56 35  8 17 10 24 55 34 53 23 45  5 41 33 50 15 12 11 51 40 46 39 32 49  6 19 18 31 52 43 64 48 27 54 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12  4 32 30 21 37 34  7  6 19 42  1  9 43 22  8 20 16 31 44 24 15 26  5  0 35 29 39  3 18 38 23 25 17 11 27 40 14 10 41 36 28 33  2 45 13], a_shuffle_aclus: [20  8 48 45 32 53 50 12 11 28 62  5 17 63 33 15 31 25 46 64 35 24 40 10  3 51 44 55  7 27 54 34 39 26 19 41 56 23 18 60 52 43 49  6 65 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [22 13 29  2 20 30 11 39 17  6 28 16 43 14 31  0  4  1 12 15 21 37 32 40 36 34 10 19 23 44 42 24  5 38 26  3 45 41  8 35 27 33  7  9 25 18], a_shuffle_aclus: [33 21 44  6 31 45 19 55 26 11 43 25 63 23 46  3  8  5 20 24 32 53 48 56 52 50 18 28 34 64 62 35 10 54 40  7 65 60 15 51 41 49 12 17 39 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 15 38  7  1 40  3 13 10 31  8  4 20 44 34 17 39 32 29 36 21 30 26 16 22 12 33 24 43 18 41  6  9 42 11 14 45 27  5 35 23 25 37 19  2 28], a_shuffle_aclus: [ 3 24 54 12  5 56  7 21 18 46 15  8 31 64 50 26 55 48 44 52 32 45 40 25 33 20 49 35 63 27 60 11 17 62 19 23 65 41 10 51 34 39 53 28  6 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 18 16 44  3 27 36 37 26 45 22 17 40  7  5 15 35 21 30 41 38 14 42 43 33 28 31 29 11 25  2 32  1  8 12 20  4  0 13  9  6 19 24 23 10 34], a_shuffle_aclus: [55 27 25 64  7 41 52 53 40 65 33 26 56 12 10 24 51 32 45 60 54 23 62 63 49 43 46 44 19 39  6 48  5 15 20 31  8  3 21 17 11 28 35 34 18 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 21  9 20 30 18  5  2 16 33 27 23 44 36 11  8 29 41  7 32 42 28  0 17 38 40 14 25 31  1 19 35 37 45  3  6 39 10 15 24 12 22 13 34 26  4], a_shuffle_aclus: [63 32 17 31 45 27 10  6 25 49 41 34 64 52 19 15 44 60 12 48 62 43  3 26 54 56 23 39 46  5 28 51 53 65  7 11 55 18 24 35 20 33 21 50 40  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 36 33  1 17 15 39  7 38 26 22 29  4 21 41  5 18 14 34  8 42 27 13 40  9 16 24 43 25 23 10 30  0 19 35  6 45 44 37 32 28 11  3  2 20 31], a_shuffle_aclus: [20 52 49  5 26 24 55 12 54 40 33 44  8 32 60 10 27 23 50 15 62 41 21 56 17 25 35 63 39 34 18 45  3 28 51 11 65 64 53 48 43 19  7  6 31 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41 28  4 16 44 11  9 22  7 33 25 43 29  8 38 42 36 27 10 32 20  0 45 14  3  1  2 39 15 19 12  6 37 24 13 30 31 26 23 34 21 17 18  5 40 35], a_shuffle_aclus: [60 43  8 25 64 19 17 33 12 49 39 63 44 15 54 62 52 41 18 48 31  3 65 23  7  5  6 55 24 28 20 11 53 35 21 45 46 40 34 50 32 26 27 10 56 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 36 13  1 33  7 12 38  0 37 34 17 42 21 45  9 18 39 26  4 19 40 43 35 23 10  8 16  5 11  2 22 14 41 44 29 20 31 30 28 27  6 25 32 24 15], a_shuffle_aclus: [ 7 52 21  5 49 12 20 54  3 53 50 26 62 32 65 17 27 55 40  8 28 56 63 51 34 18 15 25 10 19  6 33 23 60 64 44 31 46 45 43 41 11 39 48 35 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 30  4 38 15 45 32  7 33 25 28  0 17 29 11 41 14 21  6 31 39 10 18 22 16  5  9 42 23  2 12 43 27  1 13 19  3 26 20 40 34  8 36 35 44 24], a_shuffle_aclus: [53 45  8 54 24 65 48 12 49 39 43  3 26 44 19 60 23 32 11 46 55 18 27 33 25 10 17 62 34  6 20 63 41  5 21 28  7 40 31 56 50 15 52 51 64 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 26 23 45  2 11 43 16 36 33 32  6  4 21 30 38 20 29 39  8 17  1 15 22 10 42 40 18 34  7 44 27  0 37 41  5 24 35 28 25  9 19  3 12 13 31], a_shuffle_aclus: [23 40 34 65  6 19 63 25 52 49 48 11  8 32 45 54 31 44 55 15 26  5 24 33 18 62 56 27 50 12 64 41  3 53 60 10 35 51 43 39 17 28  7 20 21 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 18 35 45 38 27 24  1 13  5 41  4 21  2 31  9 34  0 43 16 20 19 23 26 11 17 33 22 29  8 40 39 28 30 36 10  7  3 25 12  6 44 14 15 42 32], a_shuffle_aclus: [53 27 51 65 54 41 35  5 21 10 60  8 32  6 46 17 50  3 63 25 31 28 34 40 19 26 49 33 44 15 56 55 43 45 52 18 12  7 39 20 11 64 23 24 62 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 27  5  4 16 11 17 18  1  7 31 19 24 45  3 25 20 39 32 15 33 41 23  8 14  2 40 38 10 35 30 34 36  9 44 13 12 22 28 29 21 37  6 26 42  0], a_shuffle_aclus: [63 41 10  8 25 19 26 27  5 12 46 28 35 65  7 39 31 55 48 24 49 60 34 15 23  6 56 54 18 51 45 50 52 17 64 21 20 33 43 44 32 53 11 40 62  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33 27 12 23 36 16 29  8 39 20 25 28 43  1 10 42 24 34 40 38  7 11  4  0  2 19 14  9 22 44 35 45 21  6 31 41 18 37 30 15 32  3 26  5 13 17], a_shuffle_aclus: [49 41 20 34 52 25 44 15 55 31 39 43 63  5 18 62 35 50 56 54 12 19  8  3  6 28 23 17 33 64 51 65 32 11 46 60 27 53 45 24 48  7 40 10 21 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45  9  7 34  6 39 40 36  2 38 26 43 15 30 35 37 29 31  5 32 14 33 24 18 12 41 21 25 13  8 19 42 44 27  3 23 11 20 17  0 10 28  1  4 16 22], a_shuffle_aclus: [65 17 12 50 11 55 56 52  6 54 40 63 24 45 51 53 44 46 10 48 23 49 35 27 20 60 32 39 21 15 28 62 64 41  7 34 19 31 26  3 18 43  5  8 25 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 43 28 41 13 40 15 10 37 34 30 36 31  6 25 35 29 42 20 22 26  3  1 17 45 39  4  9 32 24  5 19 12 16  7  2 44 38 18  8 27 21 14 11 23 33], a_shuffle_aclus: [ 3 63 43 60 21 56 24 18 53 50 45 52 46 11 39 51 44 62 31 33 40  7  5 26 65 55  8 17 48 35 10 28 20 25 12  6 64 54 27 15 41 32 23 19 34 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 17 43  0 44  8 25 12 15 10 24  5 19 11 41 36 33 20 37 38 35 14 45  2 28 26 40 31 22  4  6 21  1 39 23  7 18 13  9 27 29  3 30 16 42 34], a_shuffle_aclus: [48 26 63  3 64 15 39 20 24 18 35 10 28 19 60 52 49 31 53 54 51 23 65  6 43 40 56 46 33  8 11 32  5 55 34 12 27 21 17 41 44  7 45 25 62 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [31 22 44 11 39 15  9 36 18 43 33 29 10 35 45 23 12 17  7 30 32 24 16 27 21  5  0 38  6  3 28  4 41 26 25  1 19  8 42 37  2 13 34 20 14 40], a_shuffle_aclus: [46 33 64 19 55 24 17 52 27 63 49 44 18 51 65 34 20 26 12 45 48 35 25 41 32 10  3 54 11  7 43  8 60 40 39  5 28 15 62 53  6 21 50 31 23 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30  0  1 40 14 15 39 23  8 17 45 35 29  2 10 11 21 33 42 19 24 12 22  9 38 25 20 44 31 32 16 37  4 41 13 18 26 34 27  3  7 28 43 36  6  5], a_shuffle_aclus: [45  3  5 56 23 24 55 34 15 26 65 51 44  6 18 19 32 49 62 28 35 20 33 17 54 39 31 64 46 48 25 53  8 60 21 27 40 50 41  7 12 43 63 52 11 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 17 23 32 37 30  2  0 43 45  3 20  9 44 11  4 24 13 39 19  8 18 40 33 14 41 15 26 36 10 31  5 35 12  1 42 28 29 38 34  7 21 27 22 16 25], a_shuffle_aclus: [11 26 34 48 53 45  6  3 63 65  7 31 17 64 19  8 35 21 55 28 15 27 56 49 23 60 24 40 52 18 46 10 51 20  5 62 43 44 54 50 12 32 41 33 25 39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 25  1 43 15 37 21  8 40 41 28 45 29 34 11  6 12 10  9 22 16 27 26 19 23 44 20  7 36 42 18  3 14 32  0 13 39 30  5 31  2  4 38 33 24 35], a_shuffle_aclus: [26 39  5 63 24 53 32 15 56 60 43 65 44 50 19 11 20 18 17 33 25 41 40 28 34 64 31 12 52 62 27  7 23 48  3 21 55 45 10 46  6  8 54 49 35 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 23 44  1  2 18  8 14  4 31 29 24 10  9 17 32 36  5 19 45 12 25 16 20 15 40 27 13 26  7 43  3 22 28 39  6 34 11 42 21  0 38 30 37 41 33], a_shuffle_aclus: [51 34 64  5  6 27 15 23  8 46 44 35 18 17 26 48 52 10 28 65 20 39 25 31 24 56 41 21 40 12 63  7 33 43 55 11 50 19 62 32  3 54 45 53 60 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 16 33  6 36 21  0 13 38  9 24  2 10 35 39 26  3 27 42 31 18 22 20  7 34 44  5 11 29 14 43 37 23 12 15  8 40 17 32  4 28 41  1 25 45 19], a_shuffle_aclus: [45 25 49 11 52 32  3 21 54 17 35  6 18 51 55 40  7 41 62 46 27 33 31 12 50 64 10 19 44 23 63 53 34 20 24 15 56 26 48  8 43 60  5 39 65 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 44  0  5 23 16 11 26 37 10  4  9 17 33 39  3 31 21 38 22 24 13 18  6 41 20 40  7 27 25 28  2 12 36 15 29 35 19 42  1 32 14 43 30 45  8], a_shuffle_aclus: [50 64  3 10 34 25 19 40 53 18  8 17 26 49 55  7 46 32 54 33 35 21 27 11 60 31 56 12 41 39 43  6 20 52 24 44 51 28 62  5 48 23 63 45 65 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 32 10 15  5  1 23 22  9  2  4 16 26  7 14 38 29 18 40 24  6 25 30 31 11 17 41 20 42  0 19  8 35 39 21  3 33 13 45 36 27 43 37 28 34 44], a_shuffle_aclus: [20 48 18 24 10  5 34 33 17  6  8 25 40 12 23 54 44 27 56 35 11 39 45 46 19 26 60 31 62  3 28 15 51 55 32  7 49 21 65 52 41 63 53 43 50 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 27  8 25 15  6 32  1  3 36 43  7 44 14 24 29  2 41 31 13 37 17 38 22 19 30 21 11 26  0 20 39 35 10 45 33 12  9 28 40 23 42 16 34  4 18], a_shuffle_aclus: [10 41 15 39 24 11 48  5  7 52 63 12 64 23 35 44  6 60 46 21 53 26 54 33 28 45 32 19 40  3 31 55 51 18 65 49 20 17 43 56 34 62 25 50  8 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19 22 45 38 40 16  0 15 32  3  9  4 23 14 37 41 35 43  1  7 42 25 29 26 36 10 20 17 27 33 30 44 31 34 12 24 18  5 21  2 39 28  8 11  6 13], a_shuffle_aclus: [28 33 65 54 56 25  3 24 48  7 17  8 34 23 53 60 51 63  5 12 62 39 44 40 52 18 31 26 41 49 45 64 46 50 20 35 27 10 32  6 55 43 15 19 11 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 34 25  7  1 28 16 41 35 30  4 11 10 38 33 13 12 40 31  8 45 15 42 44 32 22 37  2  9 36 20  6 24  3 39 17 18  5 19 21 14 27 43 29 26  0], a_shuffle_aclus: [34 50 39 12  5 43 25 60 51 45  8 19 18 54 49 21 20 56 46 15 65 24 62 64 48 33 53  6 17 52 31 11 35  7 55 26 27 10 28 32 23 41 63 44 40  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 16 44 42 36 37 34 32 40 27 19 43 13  3  4  8 28 20  2  6 38 12 29 21 33  9  1 41  0 30 23 11 31 25 39 24 18 22 10  5 14 35  7 15 26 17], a_shuffle_aclus: [65 25 64 62 52 53 50 48 56 41 28 63 21  7  8 15 43 31  6 11 54 20 44 32 49 17  5 60  3 45 34 19 46 39 55 35 27 33 18 10 23 51 12 24 40 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19  5 42 23 22 37 45  9 40 25 28 11 21 35 31 32 34  4 36  7 12 39 13 38  8  6 14 30 20 18 29 26 10 44  1  0 27 24 33  2 17 15  3 43 41 16], a_shuffle_aclus: [28 10 62 34 33 53 65 17 56 39 43 19 32 51 46 48 50  8 52 12 20 55 21 54 15 11 23 45 31 27 44 40 18 64  5  3 41 35 49  6 26 24  7 63 60 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 41 33 25 37 22 35  4 45 13 39 42  1 36 30 34  0 26 16 23 15 31 20 40 18 44 21 29 17 19  9 43 10 11  7 28 14 27  3 12  5  6 32  8 38  2], a_shuffle_aclus: [35 60 49 39 53 33 51  8 65 21 55 62  5 52 45 50  3 40 25 34 24 46 31 56 27 64 32 44 26 28 17 63 18 19 12 43 23 41  7 20 10 11 48 15 54  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 38 13  7 23 45 31  4 24  0 19 10 33 12 16  6 34  3 29  8 32 44 36 43  5 35 39 22 41 27 14 42 11 30 15  9 28 20 37 21 25 18 17 40 26  1], a_shuffle_aclus: [ 6 54 21 12 34 65 46  8 35  3 28 18 49 20 25 11 50  7 44 15 48 64 52 63 10 51 55 33 60 41 23 62 19 45 24 17 43 31 53 32 39 27 26 56 40  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40 31 32 42  6 12 26 14 10 41 11 30 37  7  0 18 20 39 33 34  9 45 15 36 24 17 35 23  2 38 21  1 25 19 27  5 44 16 28 29 22 43 13  4  3  8], a_shuffle_aclus: [56 46 48 62 11 20 40 23 18 60 19 45 53 12  3 27 31 55 49 50 17 65 24 52 35 26 51 34  6 54 32  5 39 28 41 10 64 25 43 44 33 63 21  8  7 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 17  2 36 24  5 32 13 10 16 31 15 11 43 27 45 28  7 22 42 25 19 20 14 39  3  6 35 37 38 26 29 18  8 30  1 44 41 33 40  4 23 34 12  0  9], a_shuffle_aclus: [32 26  6 52 35 10 48 21 18 25 46 24 19 63 41 65 43 12 33 62 39 28 31 23 55  7 11 51 53 54 40 44 27 15 45  5 64 60 49 56  8 34 50 20  3 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 14 44 12  9 23 41  2 35 34 40  3  5 20  4  1 33 29 26 32 31 27 11 25 37 10 43 22 17 42  6 19 21 15  0 28  7 16 45 30 38 24  8 13 39 36], a_shuffle_aclus: [27 23 64 20 17 34 60  6 51 50 56  7 10 31  8  5 49 44 40 48 46 41 19 39 53 18 63 33 26 62 11 28 32 24  3 43 12 25 65 45 54 35 15 21 55 52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 34  8 23 17  2 21 37 18 31 13 41 36  9 22 27  6 43  5 25 26 45 30 29 38  7 20 39 28 19  1  0 35 10 24  3 15 12 33 14 44 40 11  4 32 16], a_shuffle_aclus: [62 50 15 34 26  6 32 53 27 46 21 60 52 17 33 41 11 63 10 39 40 65 45 44 54 12 31 55 43 28  5  3 51 18 35  7 24 20 49 23 64 56 19  8 48 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21  2 41  7  6  9 12 37 14  4 32 22 28 20 29 43 45 11  0 16  5 27 10 15 30 13 40 38  1 35  3 23 31 39 26 42 44 17 25 24 36  8 19 18 33 34], a_shuffle_aclus: [32  6 60 12 11 17 20 53 23  8 48 33 43 31 44 63 65 19  3 25 10 41 18 24 45 21 56 54  5 51  7 34 46 55 40 62 64 26 39 35 52 15 28 27 49 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 45 30 36 26 17 22 43 12 19 28 44 35 39 31 14  0 34 27 18  2 25 42  7  4  5 11 38 10  8 33  1 29 20  6 41 40 24 13 23 37 15  9 21 32 16], a_shuffle_aclus: [ 7 65 45 52 40 26 33 63 20 28 43 64 51 55 46 23  3 50 41 27  6 39 62 12  8 10 19 54 18 15 49  5 44 31 11 60 56 35 21 34 53 24 17 32 48 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 42 17 15  8  9 35 27 31 24 21  3 41 26 11 28 37 32 40  1 12 43 10 18 38 23 16 14 29 30 19 13 36  7  6 25 45 39 22 20 34 33  4 44  2  5], a_shuffle_aclus: [ 3 62 26 24 15 17 51 41 46 35 32  7 60 40 19 43 53 48 56  5 20 63 18 27 54 34 25 23 44 45 28 21 52 12 11 39 65 55 33 31 50 49  8 64  6 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [16 29 41 38 27 40 15 39 44 33 35 12  8 37 23 34 26 42  4  0 14 36 18 30  6 20 21  2  9 43 32 25 10 24  1 13 11 19  7 28 17 45  5 22  3 31], a_shuffle_aclus: [25 44 60 54 41 56 24 55 64 49 51 20 15 53 34 50 40 62  8  3 23 52 27 45 11 31 32  6 17 63 48 39 18 35  5 21 19 28 12 43 26 65 10 33  7 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 38 18  9  6 39 28  7  4 16 40 20 22  5 34  2 37 27 19  8 43  3 23 29 30 25 32 36 24 31 42 13 12 35 26 33  0 41 45  1 14 44 11 10 17 15], a_shuffle_aclus: [32 54 27 17 11 55 43 12  8 25 56 31 33 10 50  6 53 41 28 15 63  7 34 44 45 39 48 52 35 46 62 21 20 51 40 49  3 60 65  5 23 64 19 18 26 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 34 19 26 38 12 30 11  3 31 29 15 40  0 16  9 37 41  8 36  4 23 14  7 45 33 20 42  5 24 13 22 35 39 17  1 28 18 21 44 25 27  2 10  6 43], a_shuffle_aclus: [48 50 28 40 54 20 45 19  7 46 44 24 56  3 25 17 53 60 15 52  8 34 23 12 65 49 31 62 10 35 21 33 51 55 26  5 43 27 32 64 39 41  6 18 11 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 12 24 11 20 38 40  0 27 16 35 13 17 32 25  4 31 29 21 26 43  9 10  5  3 14 22 37 15 45 41  8  7 23 28 44 34 33 18  2 36  1 19  6 30 42], a_shuffle_aclus: [55 20 35 19 31 54 56  3 41 25 51 21 26 48 39  8 46 44 32 40 63 17 18 10  7 23 33 53 24 65 60 15 12 34 43 64 50 49 27  6 52  5 28 11 45 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 42 31  7  9 18  8  6 36  0 24 29 17  5  1 15 35 10 19  3 14 20 45 21  2 23 32  4 44 22 13 33 43 38 25 11 30 26 28 34 41 40 39 16 12 37], a_shuffle_aclus: [41 62 46 12 17 27 15 11 52  3 35 44 26 10  5 24 51 18 28  7 23 31 65 32  6 34 48  8 64 33 21 49 63 54 39 19 45 40 43 50 60 56 55 25 20 53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1 34  4 17 14 45 19 13  0 41 38 22 23 26 42 21 35 18 31  7 20 11 40  5 36  2 27 25 12 28 39 24 32  9 10 33 29  3 43 16 44 15  8  6 37 30], a_shuffle_aclus: [ 5 50  8 26 23 65 28 21  3 60 54 33 34 40 62 32 51 27 46 12 31 19 56 10 52  6 41 39 20 43 55 35 48 17 18 49 44  7 63 25 64 24 15 11 53 45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 43 41 12 11 18 22  7  4 40 25  6 33 37 28 39 21 23  2 17 34  0 29 45 16 13  8 38 42 10 15  9  3 14 19 24 35 31 20 27  1 36 26 32 30 44], a_shuffle_aclus: [10 63 60 20 19 27 33 12  8 56 39 11 49 53 43 55 32 34  6 26 50  3 44 65 25 21 15 54 62 18 24 17  7 23 28 35 51 46 31 41  5 52 40 48 45 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 18 15 35 45  3 22 24 42 19 26 41 10 13  6 12 40 38 21  1 27 31  4 39 16 29 11 43  7  2 37 30  0 28 34 14  9 44 32  5 17 33 23 20  8 25], a_shuffle_aclus: [52 27 24 51 65  7 33 35 62 28 40 60 18 21 11 20 56 54 32  5 41 46  8 55 25 44 19 63 12  6 53 45  3 43 50 23 17 64 48 10 26 49 34 31 15 39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 22 12 43 40 21 30 31 44 23 18 28 26 39 37  1 17 33 41  8 10 27 20  7  0 29 34 13  6  3  5 14  2 25 11 36 45 15 16 42 19 32 24  9  4 38], a_shuffle_aclus: [51 33 20 63 56 32 45 46 64 34 27 43 40 55 53  5 26 49 60 15 18 41 31 12  3 44 50 21 11  7 10 23  6 39 19 52 65 24 25 62 28 48 35 17  8 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1  5 20 41 14  7 36 40 19 10 26 38 30  3 12 23 18  2  6 17 21 27 32 13 45 33 16 39 11 37  0 31 28 15 29  8 35 44 22  9 34 43 42 25  4 24], a_shuffle_aclus: [ 5 10 31 60 23 12 52 56 28 18 40 54 45  7 20 34 27  6 11 26 32 41 48 21 65 49 25 55 19 53  3 46 43 24 44 15 51 64 33 17 50 63 62 39  8 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 34 35 13 25 41 21  6 36 18  5 11  9 38 42 31 29 32 23  2 15 45  1  0 14 40 39 43 27 10  3 24 17 19 16 33 26 28 22 30  8 37 20 44 12  7], a_shuffle_aclus: [ 8 50 51 21 39 60 32 11 52 27 10 19 17 54 62 46 44 48 34  6 24 65  5  3 23 56 55 63 41 18  7 35 26 28 25 49 40 43 33 45 15 53 31 64 20 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19  0 43 12 11 15 41 27 36 24 37 25 23 38 18  5 13 31 33 44  4 35 16 39 14  9  7 21 45 32  1  8 29 20 42 17  3  6 28 22 26 30  2 10 40 34], a_shuffle_aclus: [28  3 63 20 19 24 60 41 52 35 53 39 34 54 27 10 21 46 49 64  8 51 25 55 23 17 12 32 65 48  5 15 44 31 62 26  7 11 43 33 40 45  6 18 56 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44  9 38 23 17  7 30 29  5 11 10 32 36 43 39  0 21  4 33 22 41 12 42 27 35  6 40  3 25 31 13 15  1 24  8 45 20 26 14 19 16 28 37  2 18 34], a_shuffle_aclus: [64 17 54 34 26 12 45 44 10 19 18 48 52 63 55  3 32  8 49 33 60 20 62 41 51 11 56  7 39 46 21 24  5 35 15 65 31 40 23 28 25 43 53  6 27 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 10  9 22 17  1 35 29 26  3 33 14 20 37  6 42 40 24 11 21 31 25  2  5 39  8 12 38 36 27  4 43 41  7 15 16 28 44 30 23 13 19  0 18 32 45], a_shuffle_aclus: [50 18 17 33 26  5 51 44 40  7 49 23 31 53 11 62 56 35 19 32 46 39  6 10 55 15 20 54 52 41  8 63 60 12 24 25 43 64 45 34 21 28  3 27 48 65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 12 25 13 37 36 24 28 41  0  2 38 11 40  6 19 10 20 31 15 18 45 22  4 35 29  5 17 34 21 23  7 14  9 27 44 42 30  8 43 32  3  1 26 33 16], a_shuffle_aclus: [55 20 39 21 53 52 35 43 60  3  6 54 19 56 11 28 18 31 46 24 27 65 33  8 51 44 10 26 50 32 34 12 23 17 41 64 62 45 15 63 48  7  5 40 49 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 11 27 45 19 22 30 37 31 35 20 23 16 33  1 10 39  7  6  4 26  2 29 42 44  8 34 12  3 18 28 14 32 38  5 21 25 13 17 41 36 40  9 24 15 43], a_shuffle_aclus: [ 3 19 41 65 28 33 45 53 46 51 31 34 25 49  5 18 55 12 11  8 40  6 44 62 64 15 50 20  7 27 43 23 48 54 10 32 39 21 26 60 52 56 17 35 24 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 34 26 10  2  1 30 24  9 41  6 14 22 20 38 31 45 21 11 23  0  7 35 28  5 43 44 40 29 36 19 42 16 39  4 18 12  3 15 33 32 13 17 25 27 37], a_shuffle_aclus: [15 50 40 18  6  5 45 35 17 60 11 23 33 31 54 46 65 32 19 34  3 12 51 43 10 63 64 56 44 52 28 62 25 55  8 27 20  7 24 49 48 21 26 39 41 53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 32 39 29  1 36 41 26  7 31  0 44  6 10  4 45 14 28 42 33 27 30 38 23  5 13 35  9 37 12 34  2  8 40 16 22 17 20 24 11 21 25 43 15 18 19], a_shuffle_aclus: [ 7 48 55 44  5 52 60 40 12 46  3 64 11 18  8 65 23 43 62 49 41 45 54 34 10 21 51 17 53 20 50  6 15 56 25 33 26 31 35 19 32 39 63 24 27 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42  2 16 24  5 31 25 35 27 20  3 36 17  7 26 45 32 40 43  0 11 39 30 33 21 37  6 29  9 38 10 15 19 23 22 18 14  1 28 13 44 34  8  4 12 41], a_shuffle_aclus: [62  6 25 35 10 46 39 51 41 31  7 52 26 12 40 65 48 56 63  3 19 55 45 49 32 53 11 44 17 54 18 24 28 34 33 27 23  5 43 21 64 50 15  8 20 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20 24 34  4 27  2 42 37 45 23 26 28 44 25 31 30 29 10 21  8 19 38 15 36 39 40 14 16 18  3  6 13 32  1 41 35 11 33  5  0 43  7 12  9 17 22], a_shuffle_aclus: [31 35 50  8 41  6 62 53 65 34 40 43 64 39 46 45 44 18 32 15 28 54 24 52 55 56 23 25 27  7 11 21 48  5 60 51 19 49 10  3 63 12 20 17 26 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 34 32 25 39 15 11 17  1 19 35 21 28  5 26 24  4 23  6 41 40 31 20  3 30 38 18 22 10 29 44 27 12 43  2  7  9 36 33 37  8 14 45 42 13 16], a_shuffle_aclus: [ 3 50 48 39 55 24 19 26  5 28 51 32 43 10 40 35  8 34 11 60 56 46 31  7 45 54 27 33 18 44 64 41 20 63  6 12 17 52 49 53 15 23 65 62 21 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 31  3 44 42 28 21  2 40 16 22 34 14 45  7 39 36  6 33 25 10 38  5  0 20  1 15 17  8 24 27 23 43  4 32 12 26 19 29 41 30 18 35 11 13 37], a_shuffle_aclus: [17 46  7 64 62 43 32  6 56 25 33 50 23 65 12 55 52 11 49 39 18 54 10  3 31  5 24 26 15 35 41 34 63  8 48 20 40 28 44 60 45 27 51 19 21 53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15  7 31 43 29 13 37 33 23  8 10 20  5 38  2 26 44 40 17 32  1 41 39 28 21 22 30 35 45 25 11 12 27  3 18 24  9 19 36 42  6 34 16 14  4  0], a_shuffle_aclus: [24 12 46 63 44 21 53 49 34 15 18 31 10 54  6 40 64 56 26 48  5 60 55 43 32 33 45 51 65 39 19 20 41  7 27 35 17 28 52 62 11 50 25 23  8  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 35 43  5 12 30 21 25 37 34 17 13 42 20  1 14 18 38  2 23 19 31 27 39 40 28 15 45  9  4 44  6 26 24 16  3 33 10 22 36 41  7 32  0 29 11], a_shuffle_aclus: [15 51 63 10 20 45 32 39 53 50 26 21 62 31  5 23 27 54  6 34 28 46 41 55 56 43 24 65 17  8 64 11 40 35 25  7 49 18 33 52 60 12 48  3 44 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 43  9  5 26 29  8  4 35 38 45 15 27 18 16 21 31  7  1 28 11 23 36 12 34  0 44 14 10 32 30 22  3 17 19 37 40 39 42 41 13  2 20 33  6 24], a_shuffle_aclus: [39 63 17 10 40 44 15  8 51 54 65 24 41 27 25 32 46 12  5 43 19 34 52 20 50  3 64 23 18 48 45 33  7 26 28 53 56 55 62 60 21  6 31 49 11 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 21 10 18 15 42  0 13 24 25 39 44 41  3  2 11 28  5 16 12 32 36 40 14  7 23  9 33 27 43 26 20 22 45 19 29 30 31 35  6  4 17 38 37  1 34], a_shuffle_aclus: [15 32 18 27 24 62  3 21 35 39 55 64 60  7  6 19 43 10 25 20 48 52 56 23 12 34 17 49 41 63 40 31 33 65 28 44 45 46 51 11  8 26 54 53  5 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 17 14 23 24 44 43 34 45 12 29 11  1 20 16  4 13 35  6 37  0 40 41  2  7 30 36 21 31 19 25 22 26 27 42 10 38 15  8  5  3 33 18  9 39 32], a_shuffle_aclus: [43 26 23 34 35 64 63 50 65 20 44 19  5 31 25  8 21 51 11 53  3 56 60  6 12 45 52 32 46 28 39 33 40 41 62 18 54 24 15 10  7 49 27 17 55 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40 38  0 44 34 23 45 13 18 21 19  3 27  9 22 17 30 20 35 33 31 14 29 24 37 39 16 15  7 42  5 11 10 26  4 32  6 41 28 12  2  8 36 25 43  1], a_shuffle_aclus: [56 54  3 64 50 34 65 21 27 32 28  7 41 17 33 26 45 31 51 49 46 23 44 35 53 55 25 24 12 62 10 19 18 40  8 48 11 60 43 20  6 15 52 39 63  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32  2 13 25 43 18 30 20  4 44  9  8  0 27  1  5 38 21 31 36 16 34 12 33 40 26 17 19  7 15 41 24 29 14 37 22 10 35 39 23 45 11  3 28 42  6], a_shuffle_aclus: [48  6 21 39 63 27 45 31  8 64 17 15  3 41  5 10 54 32 46 52 25 50 20 49 56 40 26 28 12 24 60 35 44 23 53 33 18 51 55 34 65 19  7 43 62 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 35 39  7 15  4 12 40 27 42 25 14 26 37 44  3 21 20 11 34 31 24  5 38 16 30 43  9 32 23  6 45  1  0 33 29 28 19 13 18  2 17 41  8 22 10], a_shuffle_aclus: [52 51 55 12 24  8 20 56 41 62 39 23 40 53 64  7 32 31 19 50 46 35 10 54 25 45 63 17 48 34 11 65  5  3 49 44 43 28 21 27  6 26 60 15 33 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 44 27 13 31 30  3 24 43 12  9  2 39 19  8 40 38 15 10 14 41 28 20  6 35  5  4 16 23 36 18 32 22 37 26 21 42 29 11 17  1 33  7 25 45 34], a_shuffle_aclus: [ 3 64 41 21 46 45  7 35 63 20 17  6 55 28 15 56 54 24 18 23 60 43 31 11 51 10  8 25 34 52 27 48 33 53 40 32 62 44 19 26  5 49 12 39 65 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 22 25 11 36  2 17 45  8 28 23 42  3 26 35 21 31 18 16 30 33 43 20 19 44 24 40 32 13 14 38 27 12 39  5 41  1  0  4  9 15 34 37 29 10  7], a_shuffle_aclus: [11 33 39 19 52  6 26 65 15 43 34 62  7 40 51 32 46 27 25 45 49 63 31 28 64 35 56 48 21 23 54 41 20 55 10 60  5  3  8 17 24 50 53 44 18 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25  7 18 33 16  6  3 21 34  4 38 30  8 40 32 28 37 23 26 39 41 11 22 29  5 17 42  2 14  1  0 24 19 13 27 45 35 31 44 20 10 15 36  9 12 43], a_shuffle_aclus: [39 12 27 49 25 11  7 32 50  8 54 45 15 56 48 43 53 34 40 55 60 19 33 44 10 26 62  6 23  5  3 35 28 21 41 65 51 46 64 31 18 24 52 17 20 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 26 31  6 40 15 28 41 44 22 19 17  3 35 18 37 34 27 14 43 38 25 16 12 45  9 29 42 33  1  0  7  2 24 20  4  8 39 10 13 11  5 30 21 32 36], a_shuffle_aclus: [34 40 46 11 56 24 43 60 64 33 28 26  7 51 27 53 50 41 23 63 54 39 25 20 65 17 44 62 49  5  3 12  6 35 31  8 15 55 18 21 19 10 45 32 48 52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38 29 31  0 34 43 17  6 40  1 28  8  9 33 13 21 12  4 30 15 35 11 32  3 26 36  2 44 37 20 22 24 23 39  5 10 45  7 16 14 41 27 42 18 19 25], a_shuffle_aclus: [54 44 46  3 50 63 26 11 56  5 43 15 17 49 21 32 20  8 45 24 51 19 48  7 40 52  6 64 53 31 33 35 34 55 10 18 65 12 25 23 60 41 62 27 28 39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6  1  4  2 29 40  9 23 26 24 16 32 13 37 30 42 12 45 10  7 18 39 33 43 38 35 44  5 28  8 11 21  3 36 14 25 34 22 41 15 19 17 31 27 20  0], a_shuffle_aclus: [11  5  8  6 44 56 17 34 40 35 25 48 21 53 45 62 20 65 18 12 27 55 49 63 54 51 64 10 43 15 19 32  7 52 23 39 50 33 60 24 28 26 46 41 31  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11  7 24 13 10  6 44 32 27 18  9 42 35 37 45  1 29 38 40 28 33  3 30 19 36 22 34 21 41 17 26 14 20 16 15  5 25 12  8  2 31 39  0  4 23 43], a_shuffle_aclus: [19 12 35 21 18 11 64 48 41 27 17 62 51 53 65  5 44 54 56 43 49  7 45 28 52 33 50 32 60 26 40 23 31 25 24 10 39 20 15  6 46 55  3  8 34 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 29 11 31 26  6 25 37 32 18  4  2 13 36 27 30 34 44 39  7 33  1 41  9 19 43 12 28 15 14 22 20 24  5 16  3 40 45 38 21 42  0 10 17  8 35], a_shuffle_aclus: [34 44 19 46 40 11 39 53 48 27  8  6 21 52 41 45 50 64 55 12 49  5 60 17 28 63 20 43 24 23 33 31 35 10 25  7 56 65 54 32 62  3 18 26 15 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35  5 13 19 44 30  2 32 28 24 42 36 20  3 25 26  6 27  8 12 16 22  1 45 15 38 21 40 37 39 10 31  7 11 17 33 14 41 23 34  4 43 18  9  0 29], a_shuffle_aclus: [51 10 21 28 64 45  6 48 43 35 62 52 31  7 39 40 11 41 15 20 25 33  5 65 24 54 32 56 53 55 18 46 12 19 26 49 23 60 34 50  8 63 27 17  3 44]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21  1 11 40 29 35 45  8  3 37 38 22 23 10 19  0 42  9 18  2  6 12 16 39 44 36 25 14  7 28 26 15 27 31 13 30 43  5 17  4 33 34 20 41 24 32], a_shuffle_aclus: [32  5 19 56 44 51 65 15  7 53 54 33 34 18 28  3 62 17 27  6 11 20 25 55 64 52 39 23 12 43 40 24 41 46 21 45 63 10 26  8 49 50 31 60 35 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 16 34 11 12 40 30 21 20  6  3 13 27 43 10 45 35 37 39  8 22 33 28  0 26 19 17  5 25  7 15 42 14 36 18 32  2  9 41 24  1 23 38  4 31 44], a_shuffle_aclus: [44 25 50 19 20 56 45 32 31 11  7 21 41 63 18 65 51 53 55 15 33 49 43  3 40 28 26 10 39 12 24 62 23 52 27 48  6 17 60 35  5 34 54  8 46 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 30 15 23 33 39 43  1 38 36 21 18 14  2 34 24 28 27 31  7 13 26 40 41 20 22  3  0  5 44  6 12 45 17 42 35 11  4 37  9 25  8 16 10 19 32], a_shuffle_aclus: [44 45 24 34 49 55 63  5 54 52 32 27 23  6 50 35 43 41 46 12 21 40 56 60 31 33  7  3 10 64 11 20 65 26 62 51 19  8 53 17 39 15 25 18 28 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12  8  4 26  2 32 31 34 44 23 24 39 11 28 33 29  0 43 30  1  3 25 21 22 17 14 45 18 42 37 40 36 38  9 35 41 10  6 19 15 27 13  7 20  5 16], a_shuffle_aclus: [20 15  8 40  6 48 46 50 64 34 35 55 19 43 49 44  3 63 45  5  7 39 32 33 26 23 65 27 62 53 56 52 54 17 51 60 18 11 28 24 41 21 12 31 10 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 36 12 26  5 40 44 32 37 19 20  2 25 34 14 41 18 29 33  7 22 35 45 13 31  3 42 28 16 27 23  0 43  1  9  6 30 39  8  4 11 17 15 10 24 38], a_shuffle_aclus: [32 52 20 40 10 56 64 48 53 28 31  6 39 50 23 60 27 44 49 12 33 51 65 21 46  7 62 43 25 41 34  3 63  5 17 11 45 55 15  8 19 26 24 18 35 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7 40 15 39 34 13 30 16 18  5  6 26 19 24 27 44 12 10  8 43 14  0 17 28 36 23 42 31 25  1 11 41 33  3 45 35 38 20 22  9 29 32 21  4  2 37], a_shuffle_aclus: [12 56 24 55 50 21 45 25 27 10 11 40 28 35 41 64 20 18 15 63 23  3 26 43 52 34 62 46 39  5 19 60 49  7 65 51 54 31 33 17 44 48 32  8  6 53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 22 42 20 32 23 11 28 19 21 35 33 13 31 27 43 38 16 15  5  8 44 29 18 12 45 17  3  1 37 40 25 14 39  0 41 30  6 36 26  4  9 10  7 34  2], a_shuffle_aclus: [35 33 62 31 48 34 19 43 28 32 51 49 21 46 41 63 54 25 24 10 15 64 44 27 20 65 26  7  5 53 56 39 23 55  3 60 45 11 52 40  8 17 18 12 50  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 16 13 42 40  6  8  0 28  7 26 41 19  1 23 12 30 24 37 22 34 25 18 29 15 38 14 43 39 36 32 10 27 45 33 11 44  3  2 21 17 31 35  4 20  9], a_shuffle_aclus: [10 25 21 62 56 11 15  3 43 12 40 60 28  5 34 20 45 35 53 33 50 39 27 44 24 54 23 63 55 52 48 18 41 65 49 19 64  7  6 32 26 46 51  8 31 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 30  6  9 10 25 17 24 22 20 36 12 43  0 45 39  1  4 37  8  2  7 31 21 32 15 29 38  5 19 33 26 44 18 40 23 41 27 14  3 11 28 13 34 16 42], a_shuffle_aclus: [51 45 11 17 18 39 26 35 33 31 52 20 63  3 65 55  5  8 53 15  6 12 46 32 48 24 44 54 10 28 49 40 64 27 56 34 60 41 23  7 19 43 21 50 25 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 16 40 10 35 17  2 14 15 33 25 41 11  9 27 18 36 34 20 44 19 37 26  4 29 32 12  6 24  0 23 43  3 22 31 28  7  8  1  5 45 21 42 30 13 38], a_shuffle_aclus: [55 25 56 18 51 26  6 23 24 49 39 60 19 17 41 27 52 50 31 64 28 53 40  8 44 48 20 11 35  3 34 63  7 33 46 43 12 15  5 10 65 32 62 45 21 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 18 36  1 12  0 13 37 43 17 32  3 30 45 34 40 22 10 33 21 20  5 28 25  2 35  7 16 11 29  6 31  4  9 14 24 27 23 15 26 42  8 44 38 41 19], a_shuffle_aclus: [55 27 52  5 20  3 21 53 63 26 48  7 45 65 50 56 33 18 49 32 31 10 43 39  6 51 12 25 19 44 11 46  8 17 23 35 41 34 24 40 62 15 64 54 60 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 35  5 24 32 41 42 20 28  9 15 37 33 44 16 29 14 26 22  6 12  7 10 25 11 38  1 19 21  0 18 13 43 30 45 34  2  3 36  8 23 40 27  4 17 31], a_shuffle_aclus: [55 51 10 35 48 60 62 31 43 17 24 53 49 64 25 44 23 40 33 11 20 12 18 39 19 54  5 28 32  3 27 21 63 45 65 50  6  7 52 15 34 56 41  8 26 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 21 10  9 14 36 11 39  5 32 23 24 28 43 20 18 29 17 15 44  1 38  4  3 22 12  6 25 19 27  7 34 45 35 13  2  8 42 33 37 31 41 16  0 26 40], a_shuffle_aclus: [45 32 18 17 23 52 19 55 10 48 34 35 43 63 31 27 44 26 24 64  5 54  8  7 33 20 11 39 28 41 12 50 65 51 21  6 15 62 49 53 46 60 25  3 40 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7  1 39  4 17 41 23 45 36 10 22  3  5 38 35 26 29 28 18 30  6  0 21  2 37 33 11 16 13 24 20 44  9 40 25 14 12 43 42 34  8 19 15 31 32 27], a_shuffle_aclus: [12  5 55  8 26 60 34 65 52 18 33  7 10 54 51 40 44 43 27 45 11  3 32  6 53 49 19 25 21 35 31 64 17 56 39 23 20 63 62 50 15 28 24 46 48 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 22 23 26 20 43 40 14 17 33 16  8  0 18 44 10 21 30 24 42 19 31 28  7 12  2 36  4 32 38 37  1 15 11 13 25 39 45  9 34  3 41 35 29  6  5], a_shuffle_aclus: [41 33 34 40 31 63 56 23 26 49 25 15  3 27 64 18 32 45 35 62 28 46 43 12 20  6 52  8 48 54 53  5 24 19 21 39 55 65 17 50  7 60 51 44 11 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [31  4 15 33 16 36 25 19 45  2 41 11  6 13 22 17 44 42 34 24 30 23 21 20 28  3  9 39 10 14 38  7 18 37  1 26 29 32  5 40 43  8 12  0 27 35], a_shuffle_aclus: [46  8 24 49 25 52 39 28 65  6 60 19 11 21 33 26 64 62 50 35 45 34 32 31 43  7 17 55 18 23 54 12 27 53  5 40 44 48 10 56 63 15 20  3 41 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 45 26 39 37 15 25 42 22  3 31 11 17 30  0  4 21 16 35 33  8 38 29 43 44 34  7 41  9 32 10 12 24 36 20  2 18  6 14 27 23 28 13  1 40 19], a_shuffle_aclus: [10 65 40 55 53 24 39 62 33  7 46 19 26 45  3  8 32 25 51 49 15 54 44 63 64 50 12 60 17 48 18 20 35 52 31  6 27 11 23 41 34 43 21  5 56 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 20  4 30 38 32 31 44 19  5 26 41 34 45 39 36 28 40 16 14 24 43 13  2  9 33  3 37  8 42 11 21 29 25  7  0 22 17 12 18 15  6 35 23 10  1], a_shuffle_aclus: [41 31  8 45 54 48 46 64 28 10 40 60 50 65 55 52 43 56 25 23 35 63 21  6 17 49  7 53 15 62 19 32 44 39 12  3 33 26 20 27 24 11 51 34 18  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 23  0 26 37 19 39  2 41 38  9 22 36 31 15 17 34 32 42 25 20  6 33 10 45 16 43 18 24 12 11  4  3 44 21 13  8  1 30 35  7 14 27 28  5 40], a_shuffle_aclus: [44 34  3 40 53 28 55  6 60 54 17 33 52 46 24 26 50 48 62 39 31 11 49 18 65 25 63 27 35 20 19  8  7 64 32 21 15  5 45 51 12 23 41 43 10 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 38 15 22  5 19 10 17 45  1 20 26 12 32 16 28 36 37 31 35 23  8 25 40  3 14 41 11 13  2 27 42 33 29  7 30 44  6 39 18 34 24 21  4  0  9], a_shuffle_aclus: [63 54 24 33 10 28 18 26 65  5 31 40 20 48 25 43 52 53 46 51 34 15 39 56  7 23 60 19 21  6 41 62 49 44 12 45 64 11 55 27 50 35 32  8  3 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 35 13 30  9  8 20 19 42 14 41 24 10 22  6 31  0 36 18 26 16 27  3  5  2 32 37 15  7 12 45 34 38 17 11 43 23 21 39 33  4 25 29  1 40 44], a_shuffle_aclus: [43 51 21 45 17 15 31 28 62 23 60 35 18 33 11 46  3 52 27 40 25 41  7 10  6 48 53 24 12 20 65 50 54 26 19 63 34 32 55 49  8 39 44  5 56 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39  3 21 38 18 41 25 44  4 22 45  9 10 37 26 42 20 33 32 19 16 13  8 31 24 40 30 28 43 29 15 14 23  6 11  1  7 17  0  5  2 36 27 35 34 12], a_shuffle_aclus: [55  7 32 54 27 60 39 64  8 33 65 17 18 53 40 62 31 49 48 28 25 21 15 46 35 56 45 43 63 44 24 23 34 11 19  5 12 26  3 10  6 52 41 51 50 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 41 23  9 12 13 45 33 31 14 17 34 24 32 39  0 25  4  2 35  3 38 30 44 40 18  7 15 36 29  8 21 11 43 22  1 26 28 16  6 20  5 19 37 10 27], a_shuffle_aclus: [62 60 34 17 20 21 65 49 46 23 26 50 35 48 55  3 39  8  6 51  7 54 45 64 56 27 12 24 52 44 15 32 19 63 33  5 40 43 25 11 31 10 28 53 18 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 28  9 29 21 14 10 17 40  0 24 25 38 23  7 44 12  1 13 22  5  4 18 30 33  6  3 16  8 15 43 26 41 37 31 34 42 45 19 36 35  2 20 32 27 39], a_shuffle_aclus: [19 43 17 44 32 23 18 26 56  3 35 39 54 34 12 64 20  5 21 33 10  8 27 45 49 11  7 25 15 24 63 40 60 53 46 50 62 65 28 52 51  6 31 48 41 55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 29 33 37 28 18 31  1 25 45 40  6 38 22 21 16 24  5 17 26 36 15  9 10  4 27 32  7 41 19 13 35 39 11  8 12  0 44  2  3 42 34 30 14 43 20], a_shuffle_aclus: [34 44 49 53 43 27 46  5 39 65 56 11 54 33 32 25 35 10 26 40 52 24 17 18  8 41 48 12 60 28 21 51 55 19 15 20  3 64  6  7 62 50 45 23 63 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29  8 25 20 24 18 31  4 23  2 34 28 12  3 39 13 11 45 30 36 10 44 19  1  7 41 40 21  9 33  6 37 15 26 38  5  0 17 32 16 27 35 43 42 14 22], a_shuffle_aclus: [44 15 39 31 35 27 46  8 34  6 50 43 20  7 55 21 19 65 45 52 18 64 28  5 12 60 56 32 17 49 11 53 24 40 54 10  3 26 48 25 41 51 63 62 23 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [26 38 12 41 19 27  4 28 15 25 20 44  6 22  2 43 37 23  5 18 33 21  8  3 36  0 30 17 34 10 11 32 31 42 13 29 14 39 16  1 24  9 40 35 45  7], a_shuffle_aclus: [40 54 20 60 28 41  8 43 24 39 31 64 11 33  6 63 53 34 10 27 49 32 15  7 52  3 45 26 50 18 19 48 46 62 21 44 23 55 25  5 35 17 56 51 65 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 30  9  6 42 31 15 13 24 27 22 21 20  4 18  5 23 45 35  2 44  3 19 34  8 43  1 26  0 36 29 25 16 10 37 33 39 40 11 14 17 41  7 28 32 38], a_shuffle_aclus: [20 45 17 11 62 46 24 21 35 41 33 32 31  8 27 10 34 65 51  6 64  7 28 50 15 63  5 40  3 52 44 39 25 18 53 49 55 56 19 23 26 60 12 43 48 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40 37 13  0  1  2  3  5 41 28 31 32  8 17 23 34 33 22 20 19 35 14 15 36 29 38 45 39 30  9 24 27 26 10 25 21 12 42 44 43 11  4  7  6 18 16], a_shuffle_aclus: [56 53 21  3  5  6  7 10 60 43 46 48 15 26 34 50 49 33 31 28 51 23 24 52 44 54 65 55 45 17 35 41 40 18 39 32 20 62 64 63 19  8 12 11 27 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4  7 43 45 10  8 33  9 41 31 13 21 14  0 18 27 32 17 12 44 16 28 37  6  5  1 34 39 11 29 42 36 40 23 25 26 24 19  3 38 30 22  2 15 35 20], a_shuffle_aclus: [ 8 12 63 65 18 15 49 17 60 46 21 32 23  3 27 41 48 26 20 64 25 43 53 11 10  5 50 55 19 44 62 52 56 34 39 40 35 28  7 54 45 33  6 24 51 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15 11 34 36 16 28 25  9 44  6 40 22  5 35 17 10 42  3  8 19  4 26 30 27 21 13  0 43 38 18 23 24  2  7 41  1 32 31 39 29 14 33 20 45 37 12], a_shuffle_aclus: [24 19 50 52 25 43 39 17 64 11 56 33 10 51 26 18 62  7 15 28  8 40 45 41 32 21  3 63 54 27 34 35  6 12 60  5 48 46 55 44 23 49 31 65 53 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 15  9 37  3 32 25 38 33  5 27 24 40  0 20 11  6 26  4 30  8 44  2 21 28 14 39  7 10 12 35 22 29 43 36 41 45 16 13 23 34  1 18 42 31 19], a_shuffle_aclus: [26 24 17 53  7 48 39 54 49 10 41 35 56  3 31 19 11 40  8 45 15 64  6 32 43 23 55 12 18 20 51 33 44 63 52 60 65 25 21 34 50  5 27 62 46 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 11 23 29 25 44 19 37  6  3 15 35 34  8 27 30 31  4 41 22 17 14 21 18 26 28 43  2 32 10 33 40 42  9  5 16  7 12 20 38 24  1  0 36 45 39], a_shuffle_aclus: [21 19 34 44 39 64 28 53 11  7 24 51 50 15 41 45 46  8 60 33 26 23 32 27 40 43 63  6 48 18 49 56 62 17 10 25 12 20 31 54 35  5  3 52 65 55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13  6 45  8 22 17 25 14 18 44  9 33 16 41  0 32 21  1 31 34 35 38 12 37 29  5 11 30  2 23 24 40  7 15 26 10 36 28 20  4 19 42 27 43  3 39], a_shuffle_aclus: [21 11 65 15 33 26 39 23 27 64 17 49 25 60  3 48 32  5 46 50 51 54 20 53 44 10 19 45  6 34 35 56 12 24 40 18 52 43 31  8 28 62 41 63  7 55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 31  6 20 38 39 44 10  1  0 30 37 21 42  5 45  3 25 11 29  8  9 23 33 22  4 35 14 27 18 28 40 36 26  7 13 17 15 43  2 12 19 34 16 41 32], a_shuffle_aclus: [35 46 11 31 54 55 64 18  5  3 45 53 32 62 10 65  7 39 19 44 15 17 34 49 33  8 51 23 41 27 43 56 52 40 12 21 26 24 63  6 20 28 50 25 60 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 40 36 32  4 44 13 45  3  6 28 37 17 38 24  0 39 35 42 27 15  9 30 18 33 26  1  2 43 14 31  5 25 41 10 29  8 19 11 21 34 23 20  7 16 22], a_shuffle_aclus: [20 56 52 48  8 64 21 65  7 11 43 53 26 54 35  3 55 51 62 41 24 17 45 27 49 40  5  6 63 23 46 10 39 60 18 44 15 28 19 32 50 34 31 12 25 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30  4 45 37 18 27 22 14 23 34  6 15 21 32 44 28 33 16 24  3 26 25  9 12 38 13 36 11  8  5  0 35 43 17 40 42 29  2  7 39 19  1 20 41 10 31], a_shuffle_aclus: [45  8 65 53 27 41 33 23 34 50 11 24 32 48 64 43 49 25 35  7 40 39 17 20 54 21 52 19 15 10  3 51 63 26 56 62 44  6 12 55 28  5 31 60 18 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29  2 22 14  4 25 34 38 17 36 11 37 12 20 24  8 21 32 39 18 40 26  1 23 27 19 43 31 30 10 13 41 35  6 16  0  7  5  9 42 33 28 44  3 15 45], a_shuffle_aclus: [44  6 33 23  8 39 50 54 26 52 19 53 20 31 35 15 32 48 55 27 56 40  5 34 41 28 63 46 45 18 21 60 51 11 25  3 12 10 17 62 49 43 64  7 24 65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 43 45 10  6 23 29  9 22 15  7  5 30 41 33 31 11 40  4  2 38 20 26 36 42 14 34 16 25  0 44 27  1 12 17 28 39 35  3 13 32 19 21 18  8 37], a_shuffle_aclus: [35 63 65 18 11 34 44 17 33 24 12 10 45 60 49 46 19 56  8  6 54 31 40 52 62 23 50 25 39  3 64 41  5 20 26 43 55 51  7 21 48 28 32 27 15 53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1 31 43  0 35 17 34 41  3 13 42 29 24 27 40 28  4 23  6 21 16 45 18 38 26  5 30 12 14 22  8  7 19 10 37 39  9 32 25 11 44 20  2 33 15 36], a_shuffle_aclus: [ 5 46 63  3 51 26 50 60  7 21 62 44 35 41 56 43  8 34 11 32 25 65 27 54 40 10 45 20 23 33 15 12 28 18 53 55 17 48 39 19 64 31  6 49 24 52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 24 42 44 31 23 38 10 20 18 34 16  6 37 17 33 28 41 36 14 11  8 22 21 12  4 29  1 32 35 26 43  2 40  5 27  9 15 13  7 30 19 39 25 45  3], a_shuffle_aclus: [ 3 35 62 64 46 34 54 18 31 27 50 25 11 53 26 49 43 60 52 23 19 15 33 32 20  8 44  5 48 51 40 63  6 56 10 41 17 24 21 12 45 28 55 39 65  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 41 22 12 26 28 38 27 24 11 42 16 15  5 43 21 13 37 20  4 25 40 44 17  0 19  7 32 35 29 14  8  3  6 33  9 39 36 23 34 45 30 18 31 10  1], a_shuffle_aclus: [ 6 60 33 20 40 43 54 41 35 19 62 25 24 10 63 32 21 53 31  8 39 56 64 26  3 28 12 48 51 44 23 15  7 11 49 17 55 52 34 50 65 45 27 46 18  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 25 28 33 14 41  9 27 20 38 36 12 10 16 11 44 17 15 43  4  6 37  0  5  7 19 40 23 13 30 26 31 24 32  2  8 22 35 21 45 39 18  1  3 34 29], a_shuffle_aclus: [62 39 43 49 23 60 17 41 31 54 52 20 18 25 19 64 26 24 63  8 11 53  3 10 12 28 56 34 21 45 40 46 35 48  6 15 33 51 32 65 55 27  5  7 50 44]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 30 10 19 21  8 20 40 26 12  5 44  7 33 15 25 22 27 29 43  4 45 34 23 37  6 11 32 13 41  1 39 42 24 36  9 18 28  0  3 16 17 38 31 14 35], a_shuffle_aclus: [ 6 45 18 28 32 15 31 56 40 20 10 64 12 49 24 39 33 41 44 63  8 65 50 34 53 11 19 48 21 60  5 55 62 35 52 17 27 43  3  7 25 26 54 46 23 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18  5 45  0 27 36 19 33 20  8 21 12 11 24 32 34 26  6 41  7  2 40 28 38  3 44 15 29 25 43 37 16 13 42 39 35 10 30  1  4 14 22  9 23 31 17], a_shuffle_aclus: [27 10 65  3 41 52 28 49 31 15 32 20 19 35 48 50 40 11 60 12  6 56 43 54  7 64 24 44 39 63 53 25 21 62 55 51 18 45  5  8 23 33 17 34 46 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 18 10 36 43  2 19 33 38  7 28 32 39  6 16 23 14 29 34 13 22 11 21 15 24 30 12  5  1  9 20 37  8 45 17  4 25 26 31 41 44 42  0  3 40 35], a_shuffle_aclus: [41 27 18 52 63  6 28 49 54 12 43 48 55 11 25 34 23 44 50 21 33 19 32 24 35 45 20 10  5 17 31 53 15 65 26  8 39 40 46 60 64 62  3  7 56 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 41 20  3 40 15 29 26 44 24 27 30 21 28 12 17 10 25  0  7 18  9 38 36 35 23  1 42 34 43 45 33  8  6 39 37 31  5  4 19  2 14 11 32 16 22], a_shuffle_aclus: [21 60 31  7 56 24 44 40 64 35 41 45 32 43 20 26 18 39  3 12 27 17 54 52 51 34  5 62 50 63 65 49 15 11 55 53 46 10  8 28  6 23 19 48 25 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 17 13 28  0  2 44 14  6  9 22 43 45 23 10 36 41 12 33 37 31 18 29  3  5 26 24 40 21  1 25 34  8 32 15 27 30  7 39 16  4 38 19 35 20 42], a_shuffle_aclus: [19 26 21 43  3  6 64 23 11 17 33 63 65 34 18 52 60 20 49 53 46 27 44  7 10 40 35 56 32  5 39 50 15 48 24 41 45 12 55 25  8 54 28 51 31 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 24 22  7 35 41 18 23 26 28 45 27 15  4 14 39  6 16  3 10 33  8 30 38 37 44 31 43 29 36  9 40 21 32 34  5 17 13 42 19 12 11 20 25  0  1], a_shuffle_aclus: [ 6 35 33 12 51 60 27 34 40 43 65 41 24  8 23 55 11 25  7 18 49 15 45 54 53 64 46 63 44 52 17 56 32 48 50 10 26 21 62 28 20 19 31 39  3  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15 38 45 19 29 26 21 44 25  6 32  3  7  5 40  1 39 37  4 22 18 27 30 11 28 41 35 13 20 34 43 12 14  9 16 23 42 31  2 24  0 33 10  8 36 17], a_shuffle_aclus: [24 54 65 28 44 40 32 64 39 11 48  7 12 10 56  5 55 53  8 33 27 41 45 19 43 60 51 21 31 50 63 20 23 17 25 34 62 46  6 35  3 49 18 15 52 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29  1 44 14 21  8 17 18 34  6 45  7 35 19 38  2 25 27 24 20 37 13 16 30 41 10 26  4 39  0 11 42 12  3 32 31 36 23  5 28  9 22 40 15 33 43], a_shuffle_aclus: [44  5 64 23 32 15 26 27 50 11 65 12 51 28 54  6 39 41 35 31 53 21 25 45 60 18 40  8 55  3 19 62 20  7 48 46 52 34 10 43 17 33 56 24 49 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 28 34  5 33 36 30  0 14 19 17 11  3 10 25 37 40 16  9 43 39 26 27  4 42 15 44  1 21 12 35 18 22  8 29 41 45 23 20 38 31 32  2 24  7  6], a_shuffle_aclus: [21 43 50 10 49 52 45  3 23 28 26 19  7 18 39 53 56 25 17 63 55 40 41  8 62 24 64  5 32 20 51 27 33 15 44 60 65 34 31 54 46 48  6 35 12 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 10 18 28 26 44  7 39  2 13 38 15 29  4  8 43 23 17  1  6 31  5  3 24  0 22 12 11 33 16  9 27 34 41 40 45 36 25 35 32 20 30 37 21 19 14], a_shuffle_aclus: [62 18 27 43 40 64 12 55  6 21 54 24 44  8 15 63 34 26  5 11 46 10  7 35  3 33 20 19 49 25 17 41 50 60 56 65 52 39 51 48 31 45 53 32 28 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 30 45 39  5 10 19 35 16 18 31 24 14 11  2 17 26 13 38 25 42 43 29 44 20  0  9 41 22 15 28  1  8  7 27  6 32 33  4 34 12  3 23 40 37 21], a_shuffle_aclus: [52 45 65 55 10 18 28 51 25 27 46 35 23 19  6 26 40 21 54 39 62 63 44 64 31  3 17 60 33 24 43  5 15 12 41 11 48 49  8 50 20  7 34 56 53 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 19 45 44  8 12 10 13  1 21 25 38 39 15 17 37 24  6 31  7 30 26 42 40 29 33 23 22 16 36  4 32  2 11 34  0 20  3 14  5 28 27 35 41  9 18], a_shuffle_aclus: [63 28 65 64 15 20 18 21  5 32 39 54 55 24 26 53 35 11 46 12 45 40 62 56 44 49 34 33 25 52  8 48  6 19 50  3 31  7 23 10 43 41 51 60 17 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 34  4 10 27 19 40 33 12 37 44 17 28  1 43  7  6 29 21 31 11 13 23 18 45  2 22  5  8 20 36 25 14 24 32 42  0  9  3 30 41 38 35 15 26 16], a_shuffle_aclus: [55 50  8 18 41 28 56 49 20 53 64 26 43  5 63 12 11 44 32 46 19 21 34 27 65  6 33 10 15 31 52 39 23 35 48 62  3 17  7 45 60 54 51 24 40 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 25 30 35 23 39 22  2 40 31 28  8 37 45 34 29  3 19 21 10 38 43 26  0 17 13  6 41 44 16  1 33  7 18  5  9 24 15 20 11  4 32 12 36 42 27], a_shuffle_aclus: [23 39 45 51 34 55 33  6 56 46 43 15 53 65 50 44  7 28 32 18 54 63 40  3 26 21 11 60 64 25  5 49 12 27 10 17 35 24 31 19  8 48 20 52 62 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 45 23 43  8 19  7 33 39  4  6 18 38  5 13 17 22 44 36 31  1 32 26 24 34 35  9 37  3 10 30 25 16 20  2 40 27 42 21 15 12 29 41 14 28  0], a_shuffle_aclus: [19 65 34 63 15 28 12 49 55  8 11 27 54 10 21 26 33 64 52 46  5 48 40 35 50 51 17 53  7 18 45 39 25 31  6 56 41 62 32 24 20 44 60 23 43  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25  1 15  2 45 30 32 14  9 27 19 41 26 44  3 36 13 16 10 20 28  4  0 34 37 17 31 42 43  7 12 29 39 40 35 22 38 24 18 33 11  6 21 23  5  8], a_shuffle_aclus: [39  5 24  6 65 45 48 23 17 41 28 60 40 64  7 52 21 25 18 31 43  8  3 50 53 26 46 62 63 12 20 44 55 56 51 33 54 35 27 49 19 11 32 34 10 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 10  2 44 23  0 29 43 33  6  7 19 31 26 41 14 37 28 15  1 13 34 39 32 38  8  4 11 40 25 21 45 16  3 35 17  9 27  5 22 18 42 36 20 30 12], a_shuffle_aclus: [35 18  6 64 34  3 44 63 49 11 12 28 46 40 60 23 53 43 24  5 21 50 55 48 54 15  8 19 56 39 32 65 25  7 51 26 17 41 10 33 27 62 52 31 45 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42  9 40  6 16  4 31 11  1 38 10 32 45 12  8 43 19 37 13 33 17 18 20 39 28 26 35 21 41  7 27  5  3 15 30 29 44  0 22 14  2 34 36 24 25 23], a_shuffle_aclus: [62 17 56 11 25  8 46 19  5 54 18 48 65 20 15 63 28 53 21 49 26 27 31 55 43 40 51 32 60 12 41 10  7 24 45 44 64  3 33 23  6 50 52 35 39 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1 36 22 29  9 31 20 14 21 33  2 17 19 23 37 24  7 16 25 30  5 13 38  6 32 18 45 41 12 44 40 35 10  8 27 34 43 11  3 28  4 15 39 42  0 26], a_shuffle_aclus: [ 5 52 33 44 17 46 31 23 32 49  6 26 28 34 53 35 12 25 39 45 10 21 54 11 48 27 65 60 20 64 56 51 18 15 41 50 63 19  7 43  8 24 55 62  3 40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 33  7 37 26 13 30  0  3 31 32 10 43 40 24 16 25 17 39 45  5 15 22 14  9 28 18 44 19 41 23 27 11 21  8 38  6 42 29 20 34  2  4 36 12  1], a_shuffle_aclus: [51 49 12 53 40 21 45  3  7 46 48 18 63 56 35 25 39 26 55 65 10 24 33 23 17 43 27 64 28 60 34 41 19 32 15 54 11 62 44 31 50  6  8 52 20  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [16  8 23 41 11 32 28  0  1 42 29 33 19 17 38  4 39 37 26 44  6 30 25 27 45 20 13 12  9  7  3 31 21 40 10 18  5 14 15 43  2 34 35 36 24 22], a_shuffle_aclus: [25 15 34 60 19 48 43  3  5 62 44 49 28 26 54  8 55 53 40 64 11 45 39 41 65 31 21 20 17 12  7 46 32 56 18 27 10 23 24 63  6 50 51 52 35 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [16 43 11 38 18 35 26 19 41  3 17  8 34 10 33 24 13 30 25 12 29 31  7 39 20  6  1 14 42  4 37  0 23 44  9 27  5 15 28 22 36  2 32 45 21 40], a_shuffle_aclus: [25 63 19 54 27 51 40 28 60  7 26 15 50 18 49 35 21 45 39 20 44 46 12 55 31 11  5 23 62  8 53  3 34 64 17 41 10 24 43 33 52  6 48 65 32 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 45 21 15 24 30 43  3  4  5  6  2 44 27 33 39 38 36  1 13 22  9 42 16 23 10 31  0 26 37 11 17 19 35 12 18 34 32 14 20 25 40 29  8 41  7], a_shuffle_aclus: [43 65 32 24 35 45 63  7  8 10 11  6 64 41 49 55 54 52  5 21 33 17 62 25 34 18 46  3 40 53 19 26 28 51 20 27 50 48 23 31 39 56 44 15 60 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1  7 30 11  3 39 32 42  9 31  4 18 27 38 22 25 12 23 29 21  2 24 28 34 33  6 36 20 43 15 37 17 19 44 13 14 40  5 26 16 35  0 41 45 10  8], a_shuffle_aclus: [ 5 12 45 19  7 55 48 62 17 46  8 27 41 54 33 39 20 34 44 32  6 35 43 50 49 11 52 31 63 24 53 26 28 64 21 23 56 10 40 25 51  3 60 65 18 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 32 23  9 18  1 45  4 36  5 25 30 33 39 38 42 22 10 31 12 24 21 14  8  7 15 27  0 35 11 20  3 13  2 17 37 40 34 16  6 26 44 41 19 43 28], a_shuffle_aclus: [44 48 34 17 27  5 65  8 52 10 39 45 49 55 54 62 33 18 46 20 35 32 23 15 12 24 41  3 51 19 31  7 21  6 26 53 56 50 25 11 40 64 60 28 63 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 41 18 45 42 24 16 25 12 26 21 14 22 35 30  3 40  4 39  5  8 33 27 15 11 44 31 37 38 10 20 32 19 13 28  1 23 17  0 29 34  6 36 43  2  7], a_shuffle_aclus: [17 60 27 65 62 35 25 39 20 40 32 23 33 51 45  7 56  8 55 10 15 49 41 24 19 64 46 53 54 18 31 48 28 21 43  5 34 26  3 44 50 11 52 63  6 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [16 15 28  1  6 30 19 18 42 13 31 21 29 12 26 41 23 24 38 36 44 40 39  3 14 34 10 43 27  2 37  0 25 11 22  9 20  7 45  5 33 17 32  8  4 35], a_shuffle_aclus: [25 24 43  5 11 45 28 27 62 21 46 32 44 20 40 60 34 35 54 52 64 56 55  7 23 50 18 63 41  6 53  3 39 19 33 17 31 12 65 10 49 26 48 15  8 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18  5 44  4 43 31 30 45 42  3  8 38 36 21 40 29 24 34 37 33  1  6 32 19  7 25 11 15  0 23 13  9 27 12 14 16 28 35  2 39 26 20 17 10 22 41], a_shuffle_aclus: [27 10 64  8 63 46 45 65 62  7 15 54 52 32 56 44 35 50 53 49  5 11 48 28 12 39 19 24  3 34 21 17 41 20 23 25 43 51  6 55 40 31 26 18 33 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 36  6 37 27 25 33 45 14 26 15  7 41  4  1 30 12 22 24 16 19 34 18 38 23 40  3 17  5 31 10 13 35 44 20 39 43  2 11 29  8  0  9 21 32 42], a_shuffle_aclus: [43 52 11 53 41 39 49 65 23 40 24 12 60  8  5 45 20 33 35 25 28 50 27 54 34 56  7 26 10 46 18 21 51 64 31 55 63  6 19 44 15  3 17 32 48 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43  4 16 22 24 44 14 32 10 13 30  1 45 37  3 11  6 28  2 17 15 31 38  7 29 27 23 19  8 25 42 20  0 41 34  5 33 40 36 26 35 39  9 18 21 12], a_shuffle_aclus: [63  8 25 33 35 64 23 48 18 21 45  5 65 53  7 19 11 43  6 26 24 46 54 12 44 41 34 28 15 39 62 31  3 60 50 10 49 56 52 40 51 55 17 27 32 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 41  8 19 30 37  3 23 33 26 44 12 32 25 42 36 29  0 21  7 14 27  2 38 43 13 20  1  9 15 40 39 11  5 45 18 22 17 28 10  4  6 31 35 16 24], a_shuffle_aclus: [50 60 15 28 45 53  7 34 49 40 64 20 48 39 62 52 44  3 32 12 23 41  6 54 63 21 31  5 17 24 56 55 19 10 65 27 33 26 43 18  8 11 46 51 25 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38  7 11 34  2 17 37 18 13  9 35 10 42 29 30 25 28 22  6 32  1 26 21 20 36 33 41 40 39  4 16  8 44  0 23  3 45 12 31 19 43  5 14 24 15 27], a_shuffle_aclus: [54 12 19 50  6 26 53 27 21 17 51 18 62 44 45 39 43 33 11 48  5 40 32 31 52 49 60 56 55  8 25 15 64  3 34  7 65 20 46 28 63 10 23 35 24 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 40 43 37 19 44 18 15 20 23 39 25 34 16 29 31 42 35 11  3 45 14 21 26  7 22  2  5  0 36  9 13  8 17 38  4 10 32 41 33  1 12 30 24 27 28], a_shuffle_aclus: [11 56 63 53 28 64 27 24 31 34 55 39 50 25 44 46 62 51 19  7 65 23 32 40 12 33  6 10  3 52 17 21 15 26 54  8 18 48 60 49  5 20 45 35 41 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 27  0 14 43 33 20 12 13 17 22  1 38 31 15 19 25 41 21 42  7 37  2 39 40 29 16  6 35  3 30  8 34  4 45 11 18 32 24 44 28 23  9 10 26 36], a_shuffle_aclus: [10 41  3 23 63 49 31 20 21 26 33  5 54 46 24 28 39 60 32 62 12 53  6 55 56 44 25 11 51  7 45 15 50  8 65 19 27 48 35 64 43 34 17 18 40 52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38 28 27 12 43 32 25 16  9 45 10 19 15  2 41 35  7  6 30 24 20  8 39 11 36 13  4 40 37  5 31 18 33 42 21  3 26  1 14 34 17 44 22 29 23  0], a_shuffle_aclus: [54 43 41 20 63 48 39 25 17 65 18 28 24  6 60 51 12 11 45 35 31 15 55 19 52 21  8 56 53 10 46 27 49 62 32  7 40  5 23 50 26 64 33 44 34  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 36 22 38 43 42 10 33 31 37  2  6 30 15 24 39 16  7 21  8 25 34 32 44 40 17  5  9 14 27  1 29 28 20 41  4  0 12 23 26 18 35 19 13 45  3], a_shuffle_aclus: [19 52 33 54 63 62 18 49 46 53  6 11 45 24 35 55 25 12 32 15 39 50 48 64 56 26 10 17 23 41  5 44 43 31 60  8  3 20 34 40 27 51 28 21 65  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40 25 22 13 21 12 41 30  0 39 42 45 11 27  2 36 29 24 18 23  7  5 19 43 14 28 38 31 35  1 15 32  8 33 16 37  3 17 26  9 10  6 34  4 44 20], a_shuffle_aclus: [56 39 33 21 32 20 60 45  3 55 62 65 19 41  6 52 44 35 27 34 12 10 28 63 23 43 54 46 51  5 24 48 15 49 25 53  7 26 40 17 18 11 50  8 64 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15  2 45 10 38 39  8 24 33  1 34 42 17 36 12 23 21  9 19 16  0 27 40  7 32 11  3 26 20 31  6 30  4 35 43 13 22 41 28 37 18 25  5 29 44 14], a_shuffle_aclus: [24  6 65 18 54 55 15 35 49  5 50 62 26 52 20 34 32 17 28 25  3 41 56 12 48 19  7 40 31 46 11 45  8 51 63 21 33 60 43 53 27 39 10 44 64 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 14 36  7 20 41  3  2 15 39 35 16 42 33 34 29 19 44 23 38  0 13 28  5 43  6 32 11 12 31 18 21 22 17 27  1  4 30 26  9 40 10 37  8 45 24], a_shuffle_aclus: [39 23 52 12 31 60  7  6 24 55 51 25 62 49 50 44 28 64 34 54  3 21 43 10 63 11 48 19 20 46 27 32 33 26 41  5  8 45 40 17 56 18 53 15 65 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41  5 35  0 28 11 38 32 13  1  3 23 20  8 14 10 15 27 12  7 30  2 31 43 25 18 40 44  4 17 19 21 26 22 36 33 45 42 37 24 29  9 34 16  6 39], a_shuffle_aclus: [60 10 51  3 43 19 54 48 21  5  7 34 31 15 23 18 24 41 20 12 45  6 46 63 39 27 56 64  8 26 28 32 40 33 52 49 65 62 53 35 44 17 50 25 11 55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33  5 20 41 19 32  6 11 36 21 27  2  9  3 26 12 37  0 22 38 45  4 31 40 35 23 10 42 17 25 30 15 28 44  1 13 14 29 34 24 43 18 16  8 39  7], a_shuffle_aclus: [49 10 31 60 28 48 11 19 52 32 41  6 17  7 40 20 53  3 33 54 65  8 46 56 51 34 18 62 26 39 45 24 43 64  5 21 23 44 50 35 63 27 25 15 55 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15 12 25 44 22 27  2  9 17 33  6 24 38 10 16  3 43 23 30 19  4  7 14 36 45  8  5 40 35 31 32 37  0 28 41 21 13 20 11 26  1 34 39 18 29 42], a_shuffle_aclus: [24 20 39 64 33 41  6 17 26 49 11 35 54 18 25  7 63 34 45 28  8 12 23 52 65 15 10 56 51 46 48 53  3 43 60 32 21 31 19 40  5 50 55 27 44 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 22 13 23 40 16 32 21  0 26  3 41 29 44 36 15 35 39  6  5 20 17 19  7  4  9 27 31 38 37 30  2 18 10 43  8 28  1 42 33 14 24 45 12 25 11], a_shuffle_aclus: [50 33 21 34 56 25 48 32  3 40  7 60 44 64 52 24 51 55 11 10 31 26 28 12  8 17 41 46 54 53 45  6 27 18 63 15 43  5 62 49 23 35 65 20 39 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 31 38 40 27 33  1 18 23 16  2  4 44 28 26 19 30 21  8 35 10 39 43 36 45 17 37 41 24 34 11  0 14 25  9  7 29 15  5  6  3 12 42 32 20 22], a_shuffle_aclus: [21 46 54 56 41 49  5 27 34 25  6  8 64 43 40 28 45 32 15 51 18 55 63 52 65 26 53 60 35 50 19  3 23 39 17 12 44 24 10 11  7 20 62 48 31 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 17  2 43 32  7  9 36 26  6 29 44 35  8 11  4 23 25 27 24 18 22 45 10 37 41 20 42 31 19  3 38 16 40 39  0 28 30 15 13 33 21  1 12  5 14], a_shuffle_aclus: [50 26  6 63 48 12 17 52 40 11 44 64 51 15 19  8 34 39 41 35 27 33 65 18 53 60 31 62 46 28  7 54 25 56 55  3 43 45 24 21 49 32  5 20 10 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35  1 44 45  7 18 33 42 12 13 14 32 11 27  3  0 34 30 28 41  8 22 38 19 29 25 36 26 40 10 20 16 43 37  6 24  5  2 31 23  9 15 39 21  4 17], a_shuffle_aclus: [51  5 64 65 12 27 49 62 20 21 23 48 19 41  7  3 50 45 43 60 15 33 54 28 44 39 52 40 56 18 31 25 63 53 11 35 10  6 46 34 17 24 55 32  8 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 33 14  7 40 25 35  8 26  9  1 36 13 29 43 27 44 22 28 12 11 21 45 10 34  5  4 31 23  6 15 37 18 20 42 30 38 32 39 24 16 41  2 17 19  3], a_shuffle_aclus: [ 3 49 23 12 56 39 51 15 40 17  5 52 21 44 63 41 64 33 43 20 19 32 65 18 50 10  8 46 34 11 24 53 27 31 62 45 54 48 55 35 25 60  6 26 28  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 39 14 29 16 33 31  1 20 24 42  4 38 40 19 10 35 27  3 34 25  5 45 18 41  0  2 22 23 30 15 36 32 13  8 37 28 11 26  7 21 43  9 44 12 17], a_shuffle_aclus: [11 55 23 44 25 49 46  5 31 35 62  8 54 56 28 18 51 41  7 50 39 10 65 27 60  3  6 33 34 45 24 52 48 21 15 53 43 19 40 12 32 63 17 64 20 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7 32 44 20  2 40 26 24  6 19 11  0 23  3 16 37 18 25 22 38 34 10 12 41 35 30 45 33 39 14  5  4 15  9 21 43 31 28  8 36 13 17 42  1 29 27], a_shuffle_aclus: [12 48 64 31  6 56 40 35 11 28 19  3 34  7 25 53 27 39 33 54 50 18 20 60 51 45 65 49 55 23 10  8 24 17 32 63 46 43 15 52 21 26 62  5 44 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 14 41 40 18 45 28 33 36 32  9 29 37  2 43  7 31 12 22 19  6 10 23  4 38  8 30 24 35 13  1 42 20 25  0 27 17 15 26 16 34 11 44 39 21  3], a_shuffle_aclus: [10 23 60 56 27 65 43 49 52 48 17 44 53  6 63 12 46 20 33 28 11 18 34  8 54 15 45 35 51 21  5 62 31 39  3 41 26 24 40 25 50 19 64 55 32  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 26 21 37  0  3 28  9 44 30 19 42 10 39 12  8 31 17 32 24 14 35  2 45 40 23 25  6 38  5 27 18  1 34 22 15 13  7 43 11 20 16 36 41 33  4], a_shuffle_aclus: [44 40 32 53  3  7 43 17 64 45 28 62 18 55 20 15 46 26 48 35 23 51  6 65 56 34 39 11 54 10 41 27  5 50 33 24 21 12 63 19 31 25 52 60 49  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 25  4 22 45 44 32 26 10 33 13  1 15 41 36 29  3 17 21 24  6 14 31 16 39  7 20 38 43 11 42  9  2 19  0 18 37 27 35 30 40 34 12 28  8 23], a_shuffle_aclus: [10 39  8 33 65 64 48 40 18 49 21  5 24 60 52 44  7 26 32 35 11 23 46 25 55 12 31 54 63 19 62 17  6 28  3 27 53 41 51 45 56 50 20 43 15 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 10 11 20 17  7  3 40 29 39 33 36 37 26 27 45  2 30 44 14  1 23 35  5 18  0 42 34 22  9 28  8 12 16 25 41 15 31 19 43  4  6 13 21 32 38], a_shuffle_aclus: [35 18 19 31 26 12  7 56 44 55 49 52 53 40 41 65  6 45 64 23  5 34 51 10 27  3 62 50 33 17 43 15 20 25 39 60 24 46 28 63  8 11 21 32 48 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 31  5  9  3 14 36 24 35 32 28 11 42 29  8 25 19  0  4 12 38 27 44 26 22 37 16  7 41 43 23 30  2 40 45 18  6 10 20 34  1 17 15 21 33 13], a_shuffle_aclus: [55 46 10 17  7 23 52 35 51 48 43 19 62 44 15 39 28  3  8 20 54 41 64 40 33 53 25 12 60 63 34 45  6 56 65 27 11 18 31 50  5 26 24 32 49 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38  3  2 30 42 43  4 41 11 22 24 45 36  0  7 34 39 15 29 20 31  6 28 23 16  9 21  5 44 40 18  1 10  8 25 13 26 14 32 33 12 19 37 27 35 17], a_shuffle_aclus: [54  7  6 45 62 63  8 60 19 33 35 65 52  3 12 50 55 24 44 31 46 11 43 34 25 17 32 10 64 56 27  5 18 15 39 21 40 23 48 49 20 28 53 41 51 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 44  8  4 15 38 33 30 18  7 25 39 37 21 23  5 26  1 14 41  0  3 40 19 12 31 13 22 45 28 16 32 10 24 42 17 20 36 35 43 34  2 11  9 29 27], a_shuffle_aclus: [11 64 15  8 24 54 49 45 27 12 39 55 53 32 34 10 40  5 23 60  3  7 56 28 20 46 21 33 65 43 25 48 18 35 62 26 31 52 51 63 50  6 19 17 44 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 25 20  6 15 39 38  3 21 19 40 32 24 18 13  7 12 29 42 17 22 26 45 36  8  1 41  2 27 33 34 43 28  0 44 37 30 11 10  4 23  5 31 14 35 16], a_shuffle_aclus: [17 39 31 11 24 55 54  7 32 28 56 48 35 27 21 12 20 44 62 26 33 40 65 52 15  5 60  6 41 49 50 63 43  3 64 53 45 19 18  8 34 10 46 23 51 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 23  5 18 19 17 42 33 10  1 30 14 31 26 39 32 40 21  3 24 16 35  7 11  8  4 43  0 20 36 37 22 41 13 29  9 45 27 25 28 38 44  2 15 34 12], a_shuffle_aclus: [11 34 10 27 28 26 62 49 18  5 45 23 46 40 55 48 56 32  7 35 25 51 12 19 15  8 63  3 31 52 53 33 60 21 44 17 65 41 39 43 54 64  6 24 50 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 28 27 30 41 12  3 16 38 10 23 19 22 33  8  6  0  2 14 37 25 31 13  7 43 40 26  4  9 17  5  1 44 45 24 34 35 11 15 18 42 39 21 29 20 32], a_shuffle_aclus: [52 43 41 45 60 20  7 25 54 18 34 28 33 49 15 11  3  6 23 53 39 46 21 12 63 56 40  8 17 26 10  5 64 65 35 50 51 19 24 27 62 55 32 44 31 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 30 35  5  0 36 45 27 16 17 19 43 33 14 31 10 26 29 38 15 44 32  1 39 25 24  6 23 40  7 18 28  4  8 20 11 22  9 13 41 34 37  2 21 12 42], a_shuffle_aclus: [ 7 45 51 10  3 52 65 41 25 26 28 63 49 23 46 18 40 44 54 24 64 48  5 55 39 35 11 34 56 12 27 43  8 15 31 19 33 17 21 60 50 53  6 32 20 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 34 12 21 22  2 16 37  7  0 29 13  9 45  4 10 26 20 30 36 38 32 31 43 44 11 24  6  5 19 41  1 27 23  3 33 42 28 40 39 15  8 35 25 18 17], a_shuffle_aclus: [23 50 20 32 33  6 25 53 12  3 44 21 17 65  8 18 40 31 45 52 54 48 46 63 64 19 35 11 10 28 60  5 41 34  7 49 62 43 56 55 24 15 51 39 27 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15 25 32 30 41 34 22 29 26 37 12 38  5 11 44 19 24 35  6 21 33 31 36  4 23 39 13 10 43  1 14  2 17  9 28 40 20 27 16 18 42  7  3  8  0 45], a_shuffle_aclus: [24 39 48 45 60 50 33 44 40 53 20 54 10 19 64 28 35 51 11 32 49 46 52  8 34 55 21 18 63  5 23  6 26 17 43 56 31 41 25 27 62 12  7 15  3 65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 40 36 35  4 38 22  8 42 16 13  1  3 44  9  6 39 27 34 15 32 25 41 24 28 33 21 20 45  2 43 12  0 18 23 30 19 37 31 26 11  7 29 17 14  5], a_shuffle_aclus: [18 56 52 51  8 54 33 15 62 25 21  5  7 64 17 11 55 41 50 24 48 39 60 35 43 49 32 31 65  6 63 20  3 27 34 45 28 53 46 40 19 12 44 26 23 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 43 19 26 38 14  3  0 29 23 25  9 37  1 30  2 20 39 44 12 34 24 17  6 13 28 27 15 18  7 36 10 16 11 21 45  8 22 33  5 41 32  4 42 40 31], a_shuffle_aclus: [51 63 28 40 54 23  7  3 44 34 39 17 53  5 45  6 31 55 64 20 50 35 26 11 21 43 41 24 27 12 52 18 25 19 32 65 15 33 49 10 60 48  8 62 56 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 42 40 45 43 32 39 37 44 38  7 19 34 21 18 33 24 26 20  2 30 13  9  6 16  0 27  3  5 31  1 17 36 11 14 12 41 10 22 28 23 15  4  8 35 29], a_shuffle_aclus: [39 62 56 65 63 48 55 53 64 54 12 28 50 32 27 49 35 40 31  6 45 21 17 11 25  3 41  7 10 46  5 26 52 19 23 20 60 18 33 43 34 24  8 15 51 44]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 35 26 27  7 12 36 17 44 10 29  6 18 30  8  3 43 31 24  2 40  5 32 37 33  0 25 21 22 23  9 11 15 13  1 41 28 19 38 39  4 34 16 20 42 14], a_shuffle_aclus: [65 51 40 41 12 20 52 26 64 18 44 11 27 45 15  7 63 46 35  6 56 10 48 53 49  3 39 32 33 34 17 19 24 21  5 60 43 28 54 55  8 50 25 31 62 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [22 10  4  0 28 39  6 30 14 15  1 33 29 34 27 35 40 16 12 36 37 42 44  8 31 23 11  3 21 26 17 38 19 32 24 18 45 25  7 20 13 43  5  2 41  9], a_shuffle_aclus: [33 18  8  3 43 55 11 45 23 24  5 49 44 50 41 51 56 25 20 52 53 62 64 15 46 34 19  7 32 40 26 54 28 48 35 27 65 39 12 31 21 63 10  6 60 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23  3 38 28  6  9 35  8  4 24  2 25 21 20 18 27 42 22 10 12 26 40  7 37 32 16 19 43  0 14 33  1 36 31 39 15 44 11 45 30 34  5 17 13 29 41], a_shuffle_aclus: [34  7 54 43 11 17 51 15  8 35  6 39 32 31 27 41 62 33 18 20 40 56 12 53 48 25 28 63  3 23 49  5 52 46 55 24 64 19 65 45 50 10 26 21 44 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 44 18  5 16 36 31 24 14 20 27 19 37 29  6 43  3 38 28 32  7 13 41 35  8 21 22  0 10  2 26 12 23 34 11  9 33  4  1 39 25 15 17 40 30 45], a_shuffle_aclus: [62 64 27 10 25 52 46 35 23 31 41 28 53 44 11 63  7 54 43 48 12 21 60 51 15 32 33  3 18  6 40 20 34 50 19 17 49  8  5 55 39 24 26 56 45 65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 26 18  9 37 11 41 38 33 45 39 42 44 32 14  0 13 40  8 34 17 35 30 36 27 22 31 19 28 43  7 15 10 24  2 29 23 20  4 21  6 12  5 16  1  3], a_shuffle_aclus: [39 40 27 17 53 19 60 54 49 65 55 62 64 48 23  3 21 56 15 50 26 51 45 52 41 33 46 28 43 63 12 24 18 35  6 44 34 31  8 32 11 20 10 25  5  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 13 20 44  3  7 40 33  6 12  4 45 16 15 39 36 22 24 38  9 35 29 11  1 17 30 32 14 25 23  8 41 21 43  0 34 27  5 19 10 28 26  2 18 37 31], a_shuffle_aclus: [62 21 31 64  7 12 56 49 11 20  8 65 25 24 55 52 33 35 54 17 51 44 19  5 26 45 48 23 39 34 15 60 32 63  3 50 41 10 28 18 43 40  6 27 53 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15 38 28 18 25 34 32  7 17 29 16 37 27 35  9  1 13  3  6 21 11 12 10 43 36 41 45 42  5 14 22  2  4 24 23 33 44 39 19  8 40 30 20 31  0 26], a_shuffle_aclus: [24 54 43 27 39 50 48 12 26 44 25 53 41 51 17  5 21  7 11 32 19 20 18 63 52 60 65 62 10 23 33  6  8 35 34 49 64 55 28 15 56 45 31 46  3 40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 10 19 30  3 43 23  0  4 41 24 16 27  9 33 37 11 32 26 22 12 15 40  7 18 34  2  8 28 25 35 45  5 17 44  1 39 21 13  6 31 29 20 14 38 36], a_shuffle_aclus: [62 18 28 45  7 63 34  3  8 60 35 25 41 17 49 53 19 48 40 33 20 24 56 12 27 50  6 15 43 39 51 65 10 26 64  5 55 32 21 11 46 44 31 23 54 52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 33 12  6  4 35  3 32  8 26 41  0 30 13 16 21  5  9 15 29 24 45 38 27 44 23 36 20 42  1 11 18 43 37 25 19 34 40 22 17  7 28 39  2 10 31], a_shuffle_aclus: [23 49 20 11  8 51  7 48 15 40 60  3 45 21 25 32 10 17 24 44 35 65 54 41 64 34 52 31 62  5 19 27 63 53 39 28 50 56 33 26 12 43 55  6 18 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 23 18  5  0 25 14 20 15 39 28 45 34 10 41 29 26  8 19  1  4 40 27  7 24 17 42 36  9 16  2 44 43 37 33 35 32 21 13 31  6 22  3 12 38 30], a_shuffle_aclus: [19 34 27 10  3 39 23 31 24 55 43 65 50 18 60 44 40 15 28  5  8 56 41 12 35 26 62 52 17 25  6 64 63 53 49 51 48 32 21 46 11 33  7 20 54 45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 10 35  1 41 18 14 36 38 39 33 22 19 44 25 42 16 15  7 30  5 40 28 26 20  6 31 12 17 21 37 24  9  8  2 23 13  0 11 27 29  4  3 34 43 32], a_shuffle_aclus: [65 18 51  5 60 27 23 52 54 55 49 33 28 64 39 62 25 24 12 45 10 56 43 40 31 11 46 20 26 32 53 35 17 15  6 34 21  3 19 41 44  8  7 50 63 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 14 27 30 13  4  7  8 18 17 34 15 28 45 42 40 39 33 31 41 25  6 19 43 44 24 20 12 16  1 26 29 11  2 38  3  5 10 21  9 22 36 37  0 35 32], a_shuffle_aclus: [34 23 41 45 21  8 12 15 27 26 50 24 43 65 62 56 55 49 46 60 39 11 28 63 64 35 31 20 25  5 40 44 19  6 54  7 10 18 32 17 33 52 53  3 51 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 28 24 16 22 13 19 26  2  7 11  0 39  6 41  8 43 30  4 37 34 31  5 38  1 35 21 40 18 33 20 32 27 45 17 44 42 14 36 25 10 12 29 15 23  9], a_shuffle_aclus: [ 7 43 35 25 33 21 28 40  6 12 19  3 55 11 60 15 63 45  8 53 50 46 10 54  5 51 32 56 27 49 31 48 41 65 26 64 62 23 52 39 18 20 44 24 34 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 37 15 16  1 22  4  3 40 32 29  6 10 12 38 14  9 26  7 19 30  8 27  0 39 13 28 36 21 42  2 45 41 34 33 17  5 31 24 20 23 35 43 18 11 44], a_shuffle_aclus: [39 53 24 25  5 33  8  7 56 48 44 11 18 20 54 23 17 40 12 28 45 15 41  3 55 21 43 52 32 62  6 65 60 50 49 26 10 46 35 31 34 51 63 27 19 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 15 14  6 40  3 29 25  5 19 17 34 43 32 13 27 18 31 24 21 37 11  7 28  4  1 10 41 36  8 45 12  0 35 39 23 26 38 30 44 20  9  2 22 16 33], a_shuffle_aclus: [62 24 23 11 56  7 44 39 10 28 26 50 63 48 21 41 27 46 35 32 53 19 12 43  8  5 18 60 52 15 65 20  3 51 55 34 40 54 45 64 31 17  6 33 25 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 42 15  1 10 35 41 28 13 31 16 45  5  8 22 20 36 12  7 19 43 23  4 37 17 29 44 39 11 33 27 18  0 34 21 14  9 40 25 30  6 38 24 26  3  2], a_shuffle_aclus: [48 62 24  5 18 51 60 43 21 46 25 65 10 15 33 31 52 20 12 28 63 34  8 53 26 44 64 55 19 49 41 27  3 50 32 23 17 56 39 45 11 54 35 40  7  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 14  7 42 12  8 32 16 31 45  3 13 34 28 10 29 18 20  0 33 15  6 26 35 39  1 11 41 38  2 30 23 21 43 24 19  4 25 40 22  5 37  9 44 27 36], a_shuffle_aclus: [26 23 12 62 20 15 48 25 46 65  7 21 50 43 18 44 27 31  3 49 24 11 40 51 55  5 19 60 54  6 45 34 32 63 35 28  8 39 56 33 10 53 17 64 41 52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43  9 22 34 24 27 44 45 32  4 42 39 18 13 28 29 17 21 19  2 25 33 10 35 37 40 14  8 15  3 30  5  7 41 16 23 11 31 20  0 36 26 38  1 12  6], a_shuffle_aclus: [63 17 33 50 35 41 64 65 48  8 62 55 27 21 43 44 26 32 28  6 39 49 18 51 53 56 23 15 24  7 45 10 12 60 25 34 19 46 31  3 52 40 54  5 20 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38 19 12  0 45 23  5 27 34 14 37 11 18 26 21 13 31 32  7 25 43 33 28 15 30  4  1 20  8 24  9 39  6 35 41 22 17 40 16 29 44 42 10 36  3  2], a_shuffle_aclus: [54 28 20  3 65 34 10 41 50 23 53 19 27 40 32 21 46 48 12 39 63 49 43 24 45  8  5 31 15 35 17 55 11 51 60 33 26 56 25 44 64 62 18 52  7  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 31 14 21  7 15  0 34 41 25  6 11 35  1 10 36  2 39 29 33 26 23 38 22 16 18  5 43 13 28 20 27 40 30  3 17 12 45 24  8 44 32  4 19 42  9], a_shuffle_aclus: [53 46 23 32 12 24  3 50 60 39 11 19 51  5 18 52  6 55 44 49 40 34 54 33 25 27 10 63 21 43 31 41 56 45  7 26 20 65 35 15 64 48  8 28 62 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40  1 28 15 10  7 20 37 43 18  2  9  4 19 26 30 44  5 22 39 17 11  0  6 16 36  8 24 31 45 34 33 38 29 32  3 23 12 35 14 13 42 27 21 25 41], a_shuffle_aclus: [56  5 43 24 18 12 31 53 63 27  6 17  8 28 40 45 64 10 33 55 26 19  3 11 25 52 15 35 46 65 50 49 54 44 48  7 34 20 51 23 21 62 41 32 39 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 26 15  9 44 31 45 29  8 10 34 38  5  6 28 13  1 33 30 37 19 41 12 17 20 40 18 43 23 42 16 27 32  4 21 14 24  7 25 36  0  3 11 39 22 35], a_shuffle_aclus: [ 6 40 24 17 64 46 65 44 15 18 50 54 10 11 43 21  5 49 45 53 28 60 20 26 31 56 27 63 34 62 25 41 48  8 32 23 35 12 39 52  3  7 19 55 33 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21  6 33 16 12 22 41 23 26  2 38 35 39 27 31 29 42 44  7 14  1 24  3 15 10  5 40 37 20 18 25 34  8  9 11 19 45  0 32 30 28 43 17 36  4 13], a_shuffle_aclus: [32 11 49 25 20 33 60 34 40  6 54 51 55 41 46 44 62 64 12 23  5 35  7 24 18 10 56 53 31 27 39 50 15 17 19 28 65  3 48 45 43 63 26 52  8 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 18 35  8 17 27 30 28 42 45 16 29 14  7 40 13 23  4  6 43  2  9 26 25 22  1 39 37 31 32  3 33 19 11 12 21 10 38 24  5 20 44 36  0 41 15], a_shuffle_aclus: [50 27 51 15 26 41 45 43 62 65 25 44 23 12 56 21 34  8 11 63  6 17 40 39 33  5 55 53 46 48  7 49 28 19 20 32 18 54 35 10 31 64 52  3 60 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27  9 26 21 16 32 33  5 23 39  8 29 15 37 19 10 42 45 18 31 14 40  1 34 24 38 28  0 44 35  4 20 30 13 12  7 17 41  3 36  2 11 43 25 22  6], a_shuffle_aclus: [41 17 40 32 25 48 49 10 34 55 15 44 24 53 28 18 62 65 27 46 23 56  5 50 35 54 43  3 64 51  8 31 45 21 20 12 26 60  7 52  6 19 63 39 33 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 40  5 31 38 17 42 14 33  1  6 18 13 25  2 43 22 28 41 34 37 19  7 30 23  8 44 16 27 36 39 10 26 15 21 35 20 12 32  3  9 11 45  4 29 24], a_shuffle_aclus: [ 3 56 10 46 54 26 62 23 49  5 11 27 21 39  6 63 33 43 60 50 53 28 12 45 34 15 64 25 41 52 55 18 40 24 32 51 31 20 48  7 17 19 65  8 44 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0  7 44 39  2 14 19 32 40 31 26 22 20 33  8 23 11 10 29 35 36 41  1 45 28 24  5  6  9 37 15 25 17 34  3 13 43 42 12 30 38  4 16 18 21 27], a_shuffle_aclus: [ 3 12 64 55  6 23 28 48 56 46 40 33 31 49 15 34 19 18 44 51 52 60  5 65 43 35 10 11 17 53 24 39 26 50  7 21 63 62 20 45 54  8 25 27 32 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20 25 13 22 44 18 33 26  7 17 36 41 19 34 45 21 16 15  5  1 23 31 32  3 38  9 39  4 40 27 10 12 14 37  8 29 43 30 42 28  2 24  0 35 11  6], a_shuffle_aclus: [31 39 21 33 64 27 49 40 12 26 52 60 28 50 65 32 25 24 10  5 34 46 48  7 54 17 55  8 56 41 18 20 23 53 15 44 63 45 62 43  6 35  3 51 19 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 19 45 10 43  1 41 33 35 34 27 39 36  6 20 15 32 28 22 25 21 26 44  3  8 23 37 24 18 17  4 40 31 13 16 14  7  2 12  5  9  0 42 11 29 38], a_shuffle_aclus: [45 28 65 18 63  5 60 49 51 50 41 55 52 11 31 24 48 43 33 39 32 40 64  7 15 34 53 35 27 26  8 56 46 21 25 23 12  6 20 10 17  3 62 19 44 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 37 12 40 25 35 23 27 44 10 42  3 19 30 36 33 18 34 32  4 45 14 16 22 11  5 26 28 17 29  0 38 39  9  1 24  7 31 20 41 13  6  2 21 15 43], a_shuffle_aclus: [15 53 20 56 39 51 34 41 64 18 62  7 28 45 52 49 27 50 48  8 65 23 25 33 19 10 40 43 26 44  3 54 55 17  5 35 12 46 31 60 21 11  6 32 24 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20 45  3 38 37 36 27  2 13 29 17 35 34  1  7 24 43 31 32 14 16 18 39 22 12 21  5 25 15 41 10  8 30 23 42 11 26  6  0 44 28 40  9 19  4 33], a_shuffle_aclus: [31 65  7 54 53 52 41  6 21 44 26 51 50  5 12 35 63 46 48 23 25 27 55 33 20 32 10 39 24 60 18 15 45 34 62 19 40 11  3 64 43 56 17 28  8 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 43 22 26 45 11 12 40 16 10 13 27 32 31 14  7 15 41 35 20 34 38 24 18 44  8 33  6 42  1 28  0  4  5 25  9 39 19 23 36 30 21 17  2 37 29], a_shuffle_aclus: [ 7 63 33 40 65 19 20 56 25 18 21 41 48 46 23 12 24 60 51 31 50 54 35 27 64 15 49 11 62  5 43  3  8 10 39 17 55 28 34 52 45 32 26  6 53 44]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 16 21 44  5  4 34 33  7  3 31 20 40 45 15  9 39 22 10 18 11 42 24 12 37 14  1  8 35 13 17 32 19 41 26  2 23 25  0 29  6 38 36 27 30 28], a_shuffle_aclus: [63 25 32 64 10  8 50 49 12  7 46 31 56 65 24 17 55 33 18 27 19 62 35 20 53 23  5 15 51 21 26 48 28 60 40  6 34 39  3 44 11 54 52 41 45 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 23 24 15  1 42 43  2 44  9 21 39 32 25 19  4 35 18 45 13 20 22 17  8 33 14 31 41  5 16  3  0 26  7 12 27 37 40 10 36 11 28 29 30 38 34], a_shuffle_aclus: [11 34 35 24  5 62 63  6 64 17 32 55 48 39 28  8 51 27 65 21 31 33 26 15 49 23 46 60 10 25  7  3 40 12 20 41 53 56 18 52 19 43 44 45 54 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 36  9 20 34 32 16 13 24 44  8 19 30 35 31 10  1 15 17 26  5 37  6  3 29  4 11 45 18 33  0 25 41 43 40 39  2 14 28 42 23 21  7 22 12 38], a_shuffle_aclus: [41 52 17 31 50 48 25 21 35 64 15 28 45 51 46 18  5 24 26 40 10 53 11  7 44  8 19 65 27 49  3 39 60 63 56 55  6 23 43 62 34 32 12 33 20 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 26 15 16  4  1  9  3 11 13 37 27 40 41 23 12 22 42 33  2 10 31 18  5 36 25 28 43  8 32  6 24  7 38 35 30 29 39 19 44  0 34 17 20 45 21], a_shuffle_aclus: [23 40 24 25  8  5 17  7 19 21 53 41 56 60 34 20 33 62 49  6 18 46 27 10 52 39 43 63 15 48 11 35 12 54 51 45 44 55 28 64  3 50 26 31 65 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 39 18 15 37 43  5 31 45 33  1 22 21 32  7 11 25  0 34 19 35 27  2 29 24 26  3 23 36 20 44 40 12 38  8 13 16 41  4 14  6  9 42 28 10 30], a_shuffle_aclus: [26 55 27 24 53 63 10 46 65 49  5 33 32 48 12 19 39  3 50 28 51 41  6 44 35 40  7 34 52 31 64 56 20 54 15 21 25 60  8 23 11 17 62 43 18 45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 10 38 31 20  2 12 33 37  0 42 19 32 30 45 41  5 13  1  8 21 16 36 22 24  9  3 14 26 25  4 18 44 39  6 34 27 15 43  7 35 17 29 23 28 40], a_shuffle_aclus: [19 18 54 46 31  6 20 49 53  3 62 28 48 45 65 60 10 21  5 15 32 25 52 33 35 17  7 23 40 39  8 27 64 55 11 50 41 24 63 12 51 26 44 34 43 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 14 32 34 23 36 15 10 16 33 30 43 18 35  0  2 39 45 19 44 40 12 27  8 37 24 25 21 28 38  3 17  6  5 26 22 41 20  9 13 29  4  7 11 31  1], a_shuffle_aclus: [62 23 48 50 34 52 24 18 25 49 45 63 27 51  3  6 55 65 28 64 56 20 41 15 53 35 39 32 43 54  7 26 11 10 40 33 60 31 17 21 44  8 12 19 46  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 10 43  8  1 13  5 21 34 27  4 15 19 38 45 41 32 30 20 22 26  2 23  6 37 16 44 31  7 33 11 39  0 25  9 24 28 36 14 35 42  3 18 12 29 40], a_shuffle_aclus: [26 18 63 15  5 21 10 32 50 41  8 24 28 54 65 60 48 45 31 33 40  6 34 11 53 25 64 46 12 49 19 55  3 39 17 35 43 52 23 51 62  7 27 20 44 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 43 13 41  0 10  9 22 11 39 32 34 14 21  4 12 29 37 31 17 42 38  8 40 44  3  2 19 45 35 33 27 20 26 25  7 24 15 30  5 28 36  6 16 23  1], a_shuffle_aclus: [27 63 21 60  3 18 17 33 19 55 48 50 23 32  8 20 44 53 46 26 62 54 15 56 64  7  6 28 65 51 49 41 31 40 39 12 35 24 45 10 43 52 11 25 34  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 20 33 10 12 23  5  8 32 42 11 14 43 28 39 26 22 21 18 40 37 16  7 38  3  6 34 24 45 27 44 35 31 15 19 25  2  1 17  0 41  9  4 29 13 30], a_shuffle_aclus: [52 31 49 18 20 34 10 15 48 62 19 23 63 43 55 40 33 32 27 56 53 25 12 54  7 11 50 35 65 41 64 51 46 24 28 39  6  5 26  3 60 17  8 44 21 45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 24 32 27 19  0 42 10 33 23 20  8 43 35 11  7 31  2 39 25 17  3 38 16 44 14 26 21 15 37 29 12 40  5  6 34  9  1 30 28 36 41 18 13 45 22], a_shuffle_aclus: [ 8 35 48 41 28  3 62 18 49 34 31 15 63 51 19 12 46  6 55 39 26  7 54 25 64 23 40 32 24 53 44 20 56 10 11 50 17  5 45 43 52 60 27 21 65 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 37 28 42  2 16 34 38  8 22 45 44 17 33  9 27 12 10  0 41  6  7 30 32 24 40 35 25 43 15 29 21  5 14 20 18 26 11  4  3  1 19 39 23 31 36], a_shuffle_aclus: [21 53 43 62  6 25 50 54 15 33 65 64 26 49 17 41 20 18  3 60 11 12 45 48 35 56 51 39 63 24 44 32 10 23 31 27 40 19  8  7  5 28 55 34 46 52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 31 23 25 19 40 17 39 29 30  7 28 34 32 16 15 43  9 20 10 24 38 14 36 12 42 37 21 45  3 18  2 26 35 27  1 41  4  0 22 11  5  6  8 33 13], a_shuffle_aclus: [64 46 34 39 28 56 26 55 44 45 12 43 50 48 25 24 63 17 31 18 35 54 23 52 20 62 53 32 65  7 27  6 40 51 41  5 60  8  3 33 19 10 11 15 49 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [16 35  1  3 21 38 25 10 28 29 15  8 12 11 33 45 32 31  0 34 44  5 17 42 37  4 26 40 20 30 23  2 13 19 22  7 14 41  6 27  9 18 36 24 39 43], a_shuffle_aclus: [25 51  5  7 32 54 39 18 43 44 24 15 20 19 49 65 48 46  3 50 64 10 26 62 53  8 40 56 31 45 34  6 21 28 33 12 23 60 11 41 17 27 52 35 55 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 24  4 27 33  2 19  9 14 12 10 23 32  1 38  8 21 30 43 17  5 45 15 26 41 35 16 34 44 20 42  6 13 36 39 22 31 28 40  3 11  0 37 18  7 25], a_shuffle_aclus: [44 35  8 41 49  6 28 17 23 20 18 34 48  5 54 15 32 45 63 26 10 65 24 40 60 51 25 50 64 31 62 11 21 52 55 33 46 43 56  7 19  3 53 27 12 39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 25 38  8 34 40 32 45 21  3 22 43 12 35  4  7  1 26 30 36  0 37 17 39 10 18 42 44 27 13 28 15  5 31 16 29 19  9 41 14 33  2  6 24 20 23], a_shuffle_aclus: [19 39 54 15 50 56 48 65 32  7 33 63 20 51  8 12  5 40 45 52  3 53 26 55 18 27 62 64 41 21 43 24 10 46 25 44 28 17 60 23 49  6 11 35 31 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 32 24 25 33 44 45  4  3 23 17  6 19 26 13 29 18  8 30 31 41 43 21  9 20 28 12 39 11 35 40  0 34 27 22 37  5 15  1 42 14  2 10 38  7 16], a_shuffle_aclus: [52 48 35 39 49 64 65  8  7 34 26 11 28 40 21 44 27 15 45 46 60 63 32 17 31 43 20 55 19 51 56  3 50 41 33 53 10 24  5 62 23  6 18 54 12 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 12 11 28 14 26  0  7  2 44 33  6 17 34  9  5 36 30 40  1 24 23 41 29 31 42 25  4 39 16  8 37  3 22 10 38 32 45 20 13 21 43 15 19 27 18], a_shuffle_aclus: [51 20 19 43 23 40  3 12  6 64 49 11 26 50 17 10 52 45 56  5 35 34 60 44 46 62 39  8 55 25 15 53  7 33 18 54 48 65 31 21 32 63 24 28 41 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 19  4  1 20 27 22 39 13 18 40 35  9 44 17 45  2 28 15 41 24 42 12 14 26  7 31  8 34 30  3 10 23 29 11 38 43 25  5 16 33 37 36  6  0 21], a_shuffle_aclus: [48 28  8  5 31 41 33 55 21 27 56 51 17 64 26 65  6 43 24 60 35 62 20 23 40 12 46 15 50 45  7 18 34 44 19 54 63 39 10 25 49 53 52 11  3 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 24 44 33 29 34 14 15 12  2 13 19 23 43  1 35 36 25 42 22 16 18  6 37 31  9 40 39  4  7  3 28  0 26 20  8 30 10 45  5 32 17 41 27 38 21], a_shuffle_aclus: [19 35 64 49 44 50 23 24 20  6 21 28 34 63  5 51 52 39 62 33 25 27 11 53 46 17 56 55  8 12  7 43  3 40 31 15 45 18 65 10 48 26 60 41 54 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15  3  6  8 27 28 34 13 11 23  1 19 29 14 32 39 30 44 41 35 22 10  4 16 37 17 45 24 12 33  0  9  7 31 26 43 40  2 25 42 21 18 36 20 38  5], a_shuffle_aclus: [24  7 11 15 41 43 50 21 19 34  5 28 44 23 48 55 45 64 60 51 33 18  8 25 53 26 65 35 20 49  3 17 12 46 40 63 56  6 39 62 32 27 52 31 54 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38  7 30 31 44 28 11  1 24 37  8  4 42 20  5 39 13 27 43  2 26 45  9 22 25 10  0 21 34  3 23 19 33 40 14 15 41 36 29 16 35 12 18  6 17 32], a_shuffle_aclus: [54 12 45 46 64 43 19  5 35 53 15  8 62 31 10 55 21 41 63  6 40 65 17 33 39 18  3 32 50  7 34 28 49 56 23 24 60 52 44 25 51 20 27 11 26 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7  0 26 27 44  3 35 42 23 41 38 45 25 32 29 31  5 18 11 24 28 43  6 21 37 36 19 10  4 34 30 40 16 17  9  1 13 12 14  2 15  8 33 20 22 39], a_shuffle_aclus: [12  3 40 41 64  7 51 62 34 60 54 65 39 48 44 46 10 27 19 35 43 63 11 32 53 52 28 18  8 50 45 56 25 26 17  5 21 20 23  6 24 15 49 31 33 55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 29 34  2 16  4 31 43 11 26 17 15 12 20 30  8 24 13 23 36  9 27  0 28  5 21 44 33 35 19 39 32 40 22 18 45  1 38 42 14  7 41 25 10  3  6], a_shuffle_aclus: [53 44 50  6 25  8 46 63 19 40 26 24 20 31 45 15 35 21 34 52 17 41  3 43 10 32 64 49 51 28 55 48 56 33 27 65  5 54 62 23 12 60 39 18  7 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 17 31 12 29 35  9 38 39 34  8  7 20  3 36 26 30  4 45  6 15  1  0 21 28 16 41 19 40 13  5 25 24 43 11  2 33 10 32 27 42 18 44 22 14 23], a_shuffle_aclus: [53 26 46 20 44 51 17 54 55 50 15 12 31  7 52 40 45  8 65 11 24  5  3 32 43 25 60 28 56 21 10 39 35 63 19  6 49 18 48 41 62 27 64 33 23 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15 34 25 45  1 12 41  8  9 13 33 11 42 18 40 17 16 35  3  6 14 32 36 21 44 38  2 24 19 20 37 31  7 28 23 30 10  4 39 29 22  0 43  5 26 27], a_shuffle_aclus: [24 50 39 65  5 20 60 15 17 21 49 19 62 27 56 26 25 51  7 11 23 48 52 32 64 54  6 35 28 31 53 46 12 43 34 45 18  8 55 44 33  3 63 10 40 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39  6 28  5 13 17 32 43  9 38 11 37 40 33 21 15 42 12 20 41 14 36  8 25  2 26 27 23  1 10 30 35 24  4  0 22 45  3 19 44  7 34 29 18 16 31], a_shuffle_aclus: [55 11 43 10 21 26 48 63 17 54 19 53 56 49 32 24 62 20 31 60 23 52 15 39  6 40 41 34  5 18 45 51 35  8  3 33 65  7 28 64 12 50 44 27 25 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 10 15 27  4 21 29 35 45 38  1 18  3 30 14 16 12 39 20 26 37 13 32 44 33  7 36 25 24 23 28 41 31 11  8  6 17 19  2 22  9 43  0 40  5 42], a_shuffle_aclus: [50 18 24 41  8 32 44 51 65 54  5 27  7 45 23 25 20 55 31 40 53 21 48 64 49 12 52 39 35 34 43 60 46 19 15 11 26 28  6 33 17 63  3 56 10 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38 33 34 30 40  6 22  5 39 12 37 21  9 45 32 11 28 31 17 35 29 27 15 10  0 44  3 13  1  8  2  7 16 42 23 26 36 25 14 18  4 20 43 19 24 41], a_shuffle_aclus: [54 49 50 45 56 11 33 10 55 20 53 32 17 65 48 19 43 46 26 51 44 41 24 18  3 64  7 21  5 15  6 12 25 62 34 40 52 39 23 27  8 31 63 28 35 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 15 40 11 41 39 13 36 31 35  6 20 18 44  7 33 26 24 23 38 32  2 12 16  9 10  4 43  5  1 42 14 25 17 22 45 28  8  3 30 37 27 34 21 19  0], a_shuffle_aclus: [44 24 56 19 60 55 21 52 46 51 11 31 27 64 12 49 40 35 34 54 48  6 20 25 17 18  8 63 10  5 62 23 39 26 33 65 43 15  7 45 53 41 50 32 28  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 23  8 32 35  9 28 42 10 43  4 15 26 27 18 44 20 30 17  0 19  7  6 36 11 37 25 21 40 22 33 34  1  2 31 14 41  3 16 13 39  5 24 38 29 12], a_shuffle_aclus: [65 34 15 48 51 17 43 62 18 63  8 24 40 41 27 64 31 45 26  3 28 12 11 52 19 53 39 32 56 33 49 50  5  6 46 23 60  7 25 21 55 10 35 54 44 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7  6 39 23 30 22 29 27  8 20 34 13  9 19  4 36 26 40 38 43 17 25 21 31 15 41 32 37  1 12 35 42 11  0 16 18  3  5 10 14  2 28 33 44 45 24], a_shuffle_aclus: [12 11 55 34 45 33 44 41 15 31 50 21 17 28  8 52 40 56 54 63 26 39 32 46 24 60 48 53  5 20 51 62 19  3 25 27  7 10 18 23  6 43 49 64 65 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33 19  8  6 42 43 10 32 39 37  4 17  9 29 22 13 15 14 38 31 34 35 40 18  1 16 26 20 30 36 27  0 23  7 12 21 45 44 24  2  5 11 25  3 28 41], a_shuffle_aclus: [49 28 15 11 62 63 18 48 55 53  8 26 17 44 33 21 24 23 54 46 50 51 56 27  5 25 40 31 45 52 41  3 34 12 20 32 65 64 35  6 10 19 39  7 43 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 29  9 40 23 42 17 28 37 13 41 44  0 21 19 10 35 45 18 11 38 27 15  6 30 25  1 26 16 24 12 33 36 34  4 31 20  7  3 22  2 14 39 43  8  5], a_shuffle_aclus: [48 44 17 56 34 62 26 43 53 21 60 64  3 32 28 18 51 65 27 19 54 41 24 11 45 39  5 40 25 35 20 49 52 50  8 46 31 12  7 33  6 23 55 63 15 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38 25 14 29 11  7  9 28 35  4  1 34 26 41  0 24 15 23 13 27 30 17 43 10 37 19 40 45 31 16 39  6 36 32 20  2 44  3 21 42 18  5 12 22 33  8], a_shuffle_aclus: [54 39 23 44 19 12 17 43 51  8  5 50 40 60  3 35 24 34 21 41 45 26 63 18 53 28 56 65 46 25 55 11 52 48 31  6 64  7 32 62 27 10 20 33 49 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 20 12 26 32  7  3 16 10 22 40 14  4 24 13  1 42 28 37 35 15 33  2 11 23 44 25 27 41 34  6 39 31 30  5 43 29 45 21 19 18  8 17 38  0 36], a_shuffle_aclus: [17 31 20 40 48 12  7 25 18 33 56 23  8 35 21  5 62 43 53 51 24 49  6 19 34 64 39 41 60 50 11 55 46 45 10 63 44 65 32 28 27 15 26 54  3 52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9  4 14  7 19 29  5  2 11 25 45 43 26 22 24  8 18  1 23 12 31 10 41 33 34 32 39 17 21 44 30 35 28 42 15 13 40  0  6 20 16 38 27 36 37  3], a_shuffle_aclus: [17  8 23 12 28 44 10  6 19 39 65 63 40 33 35 15 27  5 34 20 46 18 60 49 50 48 55 26 32 64 45 51 43 62 24 21 56  3 11 31 25 54 41 52 53  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 27 30 20 32 14 13 45  6 16 35 28 15 38  3 17 24 29  8  4  1 33 11 43 42  9 40  2  5  7 39 44 25  0 41 26 18 23 34 21 22 36 37 10 19 31], a_shuffle_aclus: [20 41 45 31 48 23 21 65 11 25 51 43 24 54  7 26 35 44 15  8  5 49 19 63 62 17 56  6 10 12 55 64 39  3 60 40 27 34 50 32 33 52 53 18 28 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 37 33 24  9 26 21 30 32 44 45 40 12  6 36 20 39 10 27  1 17  5  8 34 18  7 13 29  0 35 15  3 25 22  2 41 31 19 11  4 23 42 28 38 43 16], a_shuffle_aclus: [23 53 49 35 17 40 32 45 48 64 65 56 20 11 52 31 55 18 41  5 26 10 15 50 27 12 21 44  3 51 24  7 39 33  6 60 46 28 19  8 34 62 43 54 63 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8  1 30 33 11 22  0 34 27 28 25 16  3  7 12 42  9 41  6  5 26 37 38 32 29 36 31  4 19 39 14 20 43 35 21 44 24 13 45  2 15 23 10 40 17 18], a_shuffle_aclus: [15  5 45 49 19 33  3 50 41 43 39 25  7 12 20 62 17 60 11 10 40 53 54 48 44 52 46  8 28 55 23 31 63 51 32 64 35 21 65  6 24 34 18 56 26 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 32  9 18 38 14 29  1 25 40 33 19 11 24  3 45 34 16 22 21  0 26 35 37 12  2 23 41 28 31 36 20 44  5  7 42 10 43 13 27 17  6 39  8 15  4], a_shuffle_aclus: [45 48 17 27 54 23 44  5 39 56 49 28 19 35  7 65 50 25 33 32  3 40 51 53 20  6 34 60 43 46 52 31 64 10 12 62 18 63 21 41 26 11 55 15 24  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2  9 24 29 23 15 16 40 21 41 20 33 37 12 22 30  6 25 27 32 17 44  5 19  7 45 39 35 11  3  1  0 36 34  8 26 28 31 14 18  4 42 43 38 10 13], a_shuffle_aclus: [ 6 17 35 44 34 24 25 56 32 60 31 49 53 20 33 45 11 39 41 48 26 64 10 28 12 65 55 51 19  7  5  3 52 50 15 40 43 46 23 27  8 62 63 54 18 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33 37 40  6 18  1  5 11 43 25 44  3 42 30 32 12  7 10 23 21 39 31 14 13 35  8 36 15 24 28 22 16 27 26  2 17 20 38 19 34  4 29 45  0 41  9], a_shuffle_aclus: [49 53 56 11 27  5 10 19 63 39 64  7 62 45 48 20 12 18 34 32 55 46 23 21 51 15 52 24 35 43 33 25 41 40  6 26 31 54 28 50  8 44 65  3 60 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 26  4 39 21 38 36 22 32 31 42 30 25 45 41 14 23 15  9 43 33 11  1 35 17  3  7  2 24  0 40 13 12 16  5 28 44  8 20 18 29 27 37 10 34 19], a_shuffle_aclus: [11 40  8 55 32 54 52 33 48 46 62 45 39 65 60 23 34 24 17 63 49 19  5 51 26  7 12  6 35  3 56 21 20 25 10 43 64 15 31 27 44 41 53 18 50 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 14 16 36  0  6  3 32 13  2 44 30 31 27 28 24 12 35  9 19 45  5  1 41 29  8 38 42  4 43 26 15 22 39 23 40 20 11 33 10  7 21 25 34 18 17], a_shuffle_aclus: [53 23 25 52  3 11  7 48 21  6 64 45 46 41 43 35 20 51 17 28 65 10  5 60 44 15 54 62  8 63 40 24 33 55 34 56 31 19 49 18 12 32 39 50 27 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7  6 30 16 15 42 27 34  4 11 19 37 26 28 12  8  2 45 31  9 44  0 23 21 13 10 36 32 20 18 24 33  3 35  5 17 43 14  1 41 40 39 25 29 22 38], a_shuffle_aclus: [12 11 45 25 24 62 41 50  8 19 28 53 40 43 20 15  6 65 46 17 64  3 34 32 21 18 52 48 31 27 35 49  7 51 10 26 63 23  5 60 56 55 39 44 33 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36  3 38  4 29 23  2 32 20 27 28 30 17 25 26  0 13 15 21  7 43 22  8 16 24 10 44 34 39 45 14  5 19 41  6  1 12 11 33 31 42 35  9 18 37 40], a_shuffle_aclus: [52  7 54  8 44 34  6 48 31 41 43 45 26 39 40  3 21 24 32 12 63 33 15 25 35 18 64 50 55 65 23 10 28 60 11  5 20 19 49 46 62 51 17 27 53 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [31 43 32 15 30  6  2  3 40 12  5 38 42 21 28 41 27  1 16 23 17 18 11 13 14 24 10 34 39 37 29 33 25  9 26 22  0  4  7 20 36 19  8 45 35 44], a_shuffle_aclus: [46 63 48 24 45 11  6  7 56 20 10 54 62 32 43 60 41  5 25 34 26 27 19 21 23 35 18 50 55 53 44 49 39 17 40 33  3  8 12 31 52 28 15 65 51 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 20 21 45 33 13  9 40 35 31 15 11 26 22 12 27 32  6 10 37 23 18 38  2  0 41 39 14 29 42  8  3 24  1 34 30  4 36  7 28 19 44 16 17 43 25], a_shuffle_aclus: [10 31 32 65 49 21 17 56 51 46 24 19 40 33 20 41 48 11 18 53 34 27 54  6  3 60 55 23 44 62 15  7 35  5 50 45  8 52 12 43 28 64 25 26 63 39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 39 45 33 14 16 26 23 42 31 34  5  9 24 20 41  7  3 18 10 22 17 37  0 12 36 35  8 28 11 25 15 21  6 30 29 44 38 32 40 19  2 43  1  4 27], a_shuffle_aclus: [21 55 65 49 23 25 40 34 62 46 50 10 17 35 31 60 12  7 27 18 33 26 53  3 20 52 51 15 43 19 39 24 32 11 45 44 64 54 48 56 28  6 63  5  8 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 15 23 32 13  2 24  1 27  5 40 34 41 28 22 16 25 33 14 18 29  9 31  8 19 12 21 20 17  0  3 42 35 26 44 39  6  4 43 10 36 30 45 37  7 38], a_shuffle_aclus: [19 24 34 48 21  6 35  5 41 10 56 50 60 43 33 25 39 49 23 27 44 17 46 15 28 20 32 31 26  3  7 62 51 40 64 55 11  8 63 18 52 45 65 53 12 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 34 24 36  5 23 15  4 20 32  3 13 17 18 37 31 29 45  7  6  8 40 41 11  2  0  9 39 14 10 16 22 28 33 38  1 35 19 44 21 43 27 25 26 30 42], a_shuffle_aclus: [20 50 35 52 10 34 24  8 31 48  7 21 26 27 53 46 44 65 12 11 15 56 60 19  6  3 17 55 23 18 25 33 43 49 54  5 51 28 64 32 63 41 39 40 45 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 33  6  9 28 30  3 36 17  1 19 42 24 27 21 44 35 20 31  8  5 41 14 22 43 38 39 12 13 10  7 11 23 37  0 29 34 26 40  4 45 15  2 16 32 18], a_shuffle_aclus: [39 49 11 17 43 45  7 52 26  5 28 62 35 41 32 64 51 31 46 15 10 60 23 33 63 54 55 20 21 18 12 19 34 53  3 44 50 40 56  8 65 24  6 25 48 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19 37 25 31 33 20 16 30  5 42 45  3 35 18 36 43  9 22  4  6 40 17  2 28 10 21 29 26 24 13  8 39 34 38 44 12 15 32 11 23  1 27 41 14  0  7], a_shuffle_aclus: [28 53 39 46 49 31 25 45 10 62 65  7 51 27 52 63 17 33  8 11 56 26  6 43 18 32 44 40 35 21 15 55 50 54 64 20 24 48 19 34  5 41 60 23  3 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 27 41 18  2 19 33  7 22  5 42  3 44 14 26 29 25 12 36  9 17 13  6 45 24 39 34 35 38 37 10 11 32 23 20  8 40 31 28 30  1  0 16 15 21  4], a_shuffle_aclus: [63 41 60 27  6 28 49 12 33 10 62  7 64 23 40 44 39 20 52 17 26 21 11 65 35 55 50 51 54 53 18 19 48 34 31 15 56 46 43 45  5  3 25 24 32  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 29 16 43 42 23 22 10 34  5 11  7 38 15 27 30 12 26 44  2 28 39 33  0 24  3  9 45 32 19 13  1  4 35 14 31 40 41 20  6 17 37 21 36 25  8], a_shuffle_aclus: [27 44 25 63 62 34 33 18 50 10 19 12 54 24 41 45 20 40 64  6 43 55 49  3 35  7 17 65 48 28 21  5  8 51 23 46 56 60 31 11 26 53 32 52 39 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 43 12 35  4 27  0 22 42 25 11 31 28 32 37 36 40  7  9 26 17 38 29 19 39 14  3 20 41 45  5 10 44 33 16  2 15 30 24  8  1 13 18 34 23  6], a_shuffle_aclus: [32 63 20 51  8 41  3 33 62 39 19 46 43 48 53 52 56 12 17 40 26 54 44 28 55 23  7 31 60 65 10 18 64 49 25  6 24 45 35 15  5 21 27 50 34 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 43 32  1 40 35  7 28 13 22 25 36 45 33 21 24 38 39 27  2 29 44 41  0 30 34  9 31 18 26  6 19 12 16  8 42  5 15  3 11  4 17 14 23 37 20], a_shuffle_aclus: [18 63 48  5 56 51 12 43 21 33 39 52 65 49 32 35 54 55 41  6 44 64 60  3 45 50 17 46 27 40 11 28 20 25 15 62 10 24  7 19  8 26 23 34 53 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 20 22 45 32 37  6 35 12 36  7 24  0 42 15 27 16 29 28 31 39 14  1  8 23 43 41  5 19 40 13 25 26 34 33 17 44  9 38 30 10 18  4  3  2 11], a_shuffle_aclus: [32 31 33 65 48 53 11 51 20 52 12 35  3 62 24 41 25 44 43 46 55 23  5 15 34 63 60 10 28 56 21 39 40 50 49 26 64 17 54 45 18 27  8  7  6 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 15  3 25 32 18  7  0 27 41 44 28 24 16  8  1 19  2 30 10 39 21 31 37 17 29 13 38 11 12 36 14 26 43 35  4 42 33  9 20 34 22 23  6 40  5], a_shuffle_aclus: [65 24  7 39 48 27 12  3 41 60 64 43 35 25 15  5 28  6 45 18 55 32 46 53 26 44 21 54 19 20 52 23 40 63 51  8 62 49 17 31 50 33 34 11 56 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 27 10 43  6 45 16  5  9 30 37 20 32 33  1 34 15 19 35 41 24  4 39  7 12 38 31 11  8  2 40 42 22 18 17 14 13 28  0 36 25 21 29 26  3 44], a_shuffle_aclus: [34 41 18 63 11 65 25 10 17 45 53 31 48 49  5 50 24 28 51 60 35  8 55 12 20 54 46 19 15  6 56 62 33 27 26 23 21 43  3 52 39 32 44 40  7 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8  7 40  4 37 19 20 45 34 39 28 13  3 23 12 38 42 24 18  9  5 29 17 44 10 15 26  0  6 25 43 30 35 31 16 36 33 41 27 21 32 22  2 11  1 14], a_shuffle_aclus: [15 12 56  8 53 28 31 65 50 55 43 21  7 34 20 54 62 35 27 17 10 44 26 64 18 24 40  3 11 39 63 45 51 46 25 52 49 60 41 32 48 33  6 19  5 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 36 39  3 35 17  6  5 30 10  1 15  9 21  4 19 34 45 31 42 32 13 38 23 14 28 24 33 40 18  7  2 37 20 16 41 27 29 44 12 22 25 11  0  8 26], a_shuffle_aclus: [63 52 55  7 51 26 11 10 45 18  5 24 17 32  8 28 50 65 46 62 48 21 54 34 23 43 35 49 56 27 12  6 53 31 25 60 41 44 64 20 33 39 19  3 15 40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 42 36 25 43 30 34 11 41  6  9  1 40 20  3 33  7 10  2 35 12 29 24 16  4 44 45 32 28 17 27 39 26 37 15 18  5 14  0 19 21 22 13  8 31 38], a_shuffle_aclus: [34 62 52 39 63 45 50 19 60 11 17  5 56 31  7 49 12 18  6 51 20 44 35 25  8 64 65 48 43 26 41 55 40 53 24 27 10 23  3 28 32 33 21 15 46 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 37 18  1 28 32 14 22  7 35  9 30 24 16 44 40  3 13 12 21  8 41  2 26  6 11 36 25 15 38 10 34 27 45 17 42  5 39 33 31 20 23  4 29 43 19], a_shuffle_aclus: [ 3 53 27  5 43 48 23 33 12 51 17 45 35 25 64 56  7 21 20 32 15 60  6 40 11 19 52 39 24 54 18 50 41 65 26 62 10 55 49 46 31 34  8 44 63 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 20  4 29 16 11 26 19  1 42 37 44 14 25  2 45 17 27 34  3  5 36 41 35 22 12 10 21 43  7 31  8 39 40 28  0 24  6 33 30 15 13 32 18 23 38], a_shuffle_aclus: [17 31  8 44 25 19 40 28  5 62 53 64 23 39  6 65 26 41 50  7 10 52 60 51 33 20 18 32 63 12 46 15 55 56 43  3 35 11 49 45 24 21 48 27 34 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 28 38 23 34 31  2  0 27 21 25 41 42  4 29 40 26 15 33  8  6 35  9 19 39 17 43 44 11 22 18 10 45  5 36 20  7 13 30 14 24 16 12  1  3 32], a_shuffle_aclus: [53 43 54 34 50 46  6  3 41 32 39 60 62  8 44 56 40 24 49 15 11 51 17 28 55 26 63 64 19 33 27 18 65 10 52 31 12 21 45 23 35 25 20  5  7 48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32  8 28 24 27 21 16  1 36 43 44 37  9 45 15 19 18 12 22 39 41 26 40 29 30 38  6 11 14 23  7 10 34  0 13  4 35  5 17 20  2 42 33 25  3 31], a_shuffle_aclus: [48 15 43 35 41 32 25  5 52 63 64 53 17 65 24 28 27 20 33 55 60 40 56 44 45 54 11 19 23 34 12 18 50  3 21  8 51 10 26 31  6 62 49 39  7 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 15  2  3 22 41  4  9 37 42 32 18  5 35 25 38 20 33 17 44 19 14 21  8 24  6 13 16 27  0  1 31 34 23 26 45 43 10 40 29 36 39 11 30  7 12], a_shuffle_aclus: [43 24  6  7 33 60  8 17 53 62 48 27 10 51 39 54 31 49 26 64 28 23 32 15 35 11 21 25 41  3  5 46 50 34 40 65 63 18 56 44 52 55 19 45 12 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 45 22 18 38 44 15 23 10  0 34 39  3 37 32 11  7 26 29 31 25  1 36 12  4  8 42  9 30 24 43 21 28 20 41 16 35 33  6 27 40 14 19 13  2 17], a_shuffle_aclus: [10 65 33 27 54 64 24 34 18  3 50 55  7 53 48 19 12 40 44 46 39  5 52 20  8 15 62 17 45 35 63 32 43 31 60 25 51 49 11 41 56 23 28 21  6 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 37  4 13 41 28 42 32 10 30  2  5 17 24 22  7  6 12 18  8 25 31 23 20 38  1  3 33  0 26 39 35 45 16 15 19 43 14 21 34  9 40 44 36 27 11], a_shuffle_aclus: [44 53  8 21 60 43 62 48 18 45  6 10 26 35 33 12 11 20 27 15 39 46 34 31 54  5  7 49  3 40 55 51 65 25 24 28 63 23 32 50 17 56 64 52 41 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 34 33  5 19 25  0 22  4 12 15 45 16 21 13 18 42 32 29 41  9 35 20 23 43  2 38  1 27 36 40  7 28 31 26 17 39 24 11  3  8  6 37 10 14 30], a_shuffle_aclus: [64 50 49 10 28 39  3 33  8 20 24 65 25 32 21 27 62 48 44 60 17 51 31 34 63  6 54  5 41 52 56 12 43 46 40 26 55 35 19  7 15 11 53 18 23 45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 22  6 12 11 39 27 37 43  8  1 41 40 28 18 35 38 36 29  4 20 31  2  5 44 19 30 14  7 33 10 34 23  3 32 15 45 17 21 13 16 42 25 24 26  0], a_shuffle_aclus: [17 33 11 20 19 55 41 53 63 15  5 60 56 43 27 51 54 52 44  8 31 46  6 10 64 28 45 23 12 49 18 50 34  7 48 24 65 26 32 21 25 62 39 35 40  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 44 42 17  9 28 22 11 14 26  8 25 24 13  1 10  7 31  5 32 35 33 29 45 30 43  2 27 12 38 21 15  4  0 20 41 18 19 36 37  6 39 16 40 34 23], a_shuffle_aclus: [ 7 64 62 26 17 43 33 19 23 40 15 39 35 21  5 18 12 46 10 48 51 49 44 65 45 63  6 41 20 54 32 24  8  3 31 60 27 28 52 53 11 55 25 56 50 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 15 18 20 43 12 24 45 32  5  7 10 35 14 40 39  6 25  4 11 34 26  3 23 17 44  0 38 31 19 13 28 29 37 30  8 22 21 36  1  9 33 16  2 42 41], a_shuffle_aclus: [41 24 27 31 63 20 35 65 48 10 12 18 51 23 56 55 11 39  8 19 50 40  7 34 26 64  3 54 46 28 21 43 44 53 45 15 33 32 52  5 17 49 25  6 62 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:395: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ey: float = np.nansum(arr * y_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:396: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ex: float = np.nansum(arr * x_mat) / arr_sum  # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:397: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xy: float = np.nansum(arr * (y_mat - ey) * (x_mat - ex)) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:398: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_yy: float = np.nansum(arr * (y_mat - ey) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:399: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cov_xx: float = np.nansum(arr * (x_mat - ex) ** 2) / arr_sum # RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/halechr/repos/NeuroPy/neuropy/analyses/decoders.py:401: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cov_xy / np.sqrt(cov_xx * cov_yy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29 26 28 45 35 39 18 34 17  5  9  1 43 40  4  3 12  2 23 11  6 25 15 14 41 36  8 31 32 16 20 24 38 30 13 42 19 22 27  7 37  0 44 10 21 33], a_shuffle_aclus: [44 40 43 65 51 55 27 50 26 10 17  5 63 56  8  7 20  6 34 19 11 39 24 23 60 52 15 46 48 25 31 35 54 45 21 62 28 33 41 12 53  3 64 18 32 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/reconstruction.py:347: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5f755b",
   "metadata": {},
   "source": [
    "## 0️⃣ Shared Post-Pipeline load stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ed6fa",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [],
   "source": [
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_GL'\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_rMBP' # TODO: Change this as needed, templating isn't actually doing anything rn.\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Apogee'\n",
    "BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Lab'\n",
    " \n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        BATCH_DATE_TO_USE = f'{BATCH_DATE_TO_USE}{custom_suffix}'\n",
    "        print(f'Adding custom suffix: \"{custom_suffix}\" - BATCH_DATE_TO_USE: \"{BATCH_DATE_TO_USE}\"')\n",
    "except NameError as err:\n",
    "    custom_suffix = None\n",
    "    print(f'NO CUSTOM SUFFIX.')\n",
    "\n",
    "known_collected_output_paths = [Path(v).resolve() for v in ['/nfs/turbo/umms-kdiba/Data/Output/collected_outputs', '/home/halechr/FastData/collected_outputs/',\n",
    "                                                           '/home/halechr/cloud/turbo/Data/Output/collected_outputs',\n",
    "                                                           r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\output\\collected_outputs',\n",
    "                                                           '/Users/pho/data/collected_outputs',\n",
    "                                                          'output/gen_scripts/']]\n",
    "collected_outputs_path = find_first_extant_path(known_collected_output_paths)\n",
    "assert collected_outputs_path.exists(), f\"collected_outputs_path: {collected_outputs_path} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'collected_outputs_path: {collected_outputs_path}')\n",
    "# collected_outputs_path.mkdir(exist_ok=True)\n",
    "# assert collected_outputs_path.exists()\n",
    "\n",
    "## Build the output prefix from the session context:\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: \"{CURR_BATCH_OUTPUT_PREFIX}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e0148",
   "metadata": {},
   "source": [
    "## Specific Recomputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_most_recent_computation_time, each_epoch_latest_computation_time, each_epoch_each_result_computation_completion_times, (global_computations_latest_computation_time, global_computation_completion_times) = curr_active_pipeline.get_computation_times(debug_print=False)\n",
    "# each_epoch_latest_computation_time\n",
    "each_epoch_each_result_computation_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload_exported_kdiba_session_position_info_mat_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import reload_exported_kdiba_session_position_info_mat_completion_function\n",
    "\n",
    "# Results can be extracted from batch output by \n",
    "\n",
    "# Extracts the callback results 'determine_session_t_delta_completion_function':\n",
    "# extracted_callback_fn_results = {a_sess_ctxt:a_result.across_session_results.get('determine_session_t_delta_completion_function', {}) for a_sess_ctxt, a_result in global_batch_run.session_batch_outputs.items() if a_result is not None}\n",
    "\n",
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import compute_diba_quiescent_style_replay_events, overwrite_replay_epochs_and_recompute, try_load_neuroscope_EVT_file_epochs, replace_replay_epochs, _get_custom_suffix_for_replay_filename, finalize_output_shuffled_wcorr\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "a_dummy.should_suppress_errors = False\n",
    "\n",
    "## Settings:\n",
    "\n",
    "# SimpleBatchComputationDummy = make_class('SimpleBatchComputationDummy', attrs=['BATCH_DATE_TO_USE', 'collected_outputs_path'])\n",
    "# a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path)\n",
    "\n",
    "_temp_batch_results_extended_dict = {}\n",
    "## Combine the output of `reload_exported_kdiba_session_position_info_mat_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "_temp_batch_results_extended_dict = _temp_batch_results_extended_dict | reload_exported_kdiba_session_position_info_mat_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_temp_batch_results_extended_dict,\n",
    "                                                # save_hdf=save_hdf, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                # desired_shared_decoding_time_bin_sizes=desired_shared_decoding_time_bin_sizes,\n",
    "                                                )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d4f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd11d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_config.instantaneous_time_bin_size_seconds = 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58db94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_recompute_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_recompute_global = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47820977",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_computations_include_includelist=['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "    #  'ratemap_peaks_prominence2d',\n",
    "    'extended_stats',\n",
    "    'long_short_decoding_analyses',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    # 'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'merged_directional_placefields',\n",
    "    # 'rank_order_shuffle_analysis',\n",
    "    # 'directional_decoders_decode_continuous',\n",
    "    # 'directional_decoders_evaluate_epochs',\n",
    "    # 'directional_decoders_epoch_heuristic_scoring',\n",
    "] # do only specified\n",
    "\n",
    "# ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous']\n",
    "\n",
    "# force_recompute_override_computations_includelist = [\n",
    "#     'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',\n",
    "#     'split_to_directional_laps', 'lap_direction_determination', 'DirectionalLaps',\n",
    "#     'merged_directional_placefields',\n",
    "#     'directional_decoders_decode_continuous',\n",
    "# ]\n",
    "force_recompute_override_computations_includelist = None\n",
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "newly_computed_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extended_computations_include_includelist=['ratemap_peaks_prominence2d', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "extended_computations_include_includelist=['rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs',] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "\n",
    "\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d357f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next wave of computations\n",
    "extended_computations_include_includelist=['ratemap_peaks_prominence2d', 'directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'rank_order_shuffle_analysis',\n",
    "## Next wave of computations\n",
    "extended_computations_include_includelist=['rank_order_shuffle_analysis'] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57498ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d510c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "# newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "#                                                     force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['rank_order_shuffle_analysis'], computation_kwargs_list=[{'num_shuffles': 500, 'skip_laps': True}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9bb808",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ac9f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "# force_recompute_override_computations_includelist = ['_decode_continuous_using_directional_decoders']\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_decode_continuous_using_directional_decoders'], force_recompute_override_computations_includelist=force_recompute_override_computations_includelist,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_decode_continuous_using_directional_decoders'], computation_kwargs_list=[{'time_bin_size': 0.025}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(extended_computations_include_includelist=['_decode_continuous_using_directional_decoders'], computation_kwargs_list=[{'time_bin_size': 0.02}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.20}, {'time_bin_size': 0.20}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "# 2024-04-20 - HACK -- FIXME: Invert the 'is_LR_dir' column since it is clearly reversed. No clue why.\n",
    "# fails due to some types thing?\n",
    "# \terr: Length of values (82) does not match length of index (80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f748deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum ~10ms\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields'], computation_kwargs_list=[{'ripple_decoding_time_bin_size': 0.010, 'laps_decoding_time_bin_size': 0.050}], enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ffa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum ~10ms\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_evaluate_epochs'], computation_kwargs_list=[{'should_skip_radon_transform': True}], enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n",
    "# ## produces: 'DirectionalDecodersEpochsEvaluations'\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_epoch_heuristic_scoring'], enabled_filter_names=None, fail_on_exception=True, debug_print=False) # OK FOR PICKLE\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   computation_kwargs_list=[{'ripple_decoding_time_bin_size': 0.01, 'laps_decoding_time_bin_size': 0.05}, {'time_bin_size': 0.01}, {'should_skip_radon_transform': True}, {}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92db81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f372737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39417243",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['lap_direction_determination'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89757a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_perform_long_short_firing_rate_analyses'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2745bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['EloyAnalysis'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4130eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_train_test_split'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da92d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['perform_wcorr_shuffle_analysis'], computation_kwargs_list=[{'num_shuffles': 350}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}, {'time_bin_size': 0.025}, {'should_skip_radon_transform': True}, {}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4dec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs',], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}, {'time_bin_size': 0.025}, {'should_skip_radon_transform': True},], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62493eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=[\n",
    "    'merged_directional_placefields', \n",
    "    'long_short_decoding_analyses', #'pipeline_complete_compute_long_short_fr_indicies',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    ], enabled_filter_names=None, fail_on_exception=False, debug_print=False) # , computation_kwargs_list=[{'should_skip_radon_transform': False}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca34a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=[\n",
    "    # 'long_short_decoding_analyses', #'pipeline_complete_compute_long_short_fr_indicies',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    # 'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    ], enabled_filter_names=None, fail_on_exception=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99749819",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'TrainTestSplit' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "    training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "    test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "    test_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "    train_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "    train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5cbcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'trial_by_trial_metrics'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed38171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData\n",
    "\n",
    "# directional_decoders_epochs_decode_result\n",
    "# save_path = Path(\"/Users/pho/data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-04-25_CustomDecodingResults.pkl\").resolve()\n",
    "# save_path = curr_active_pipeline.get_output_path().joinpath(\"2024-04-28_CustomDecodingResults.pkl\").resolve()\n",
    "save_path = curr_active_pipeline.get_output_path().joinpath(f\"{DAY_DATE_TO_USE}_CustomDecodingResults.pkl\").resolve()\n",
    "\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "xbin_centers = deepcopy(long_pf2D.xbin_centers)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "ybin_centers = deepcopy(long_pf2D.ybin_centers)\n",
    "\n",
    "print(xbin_centers)\n",
    "save_dict = {\n",
    "'directional_decoders_epochs_decode_result': directional_decoders_epochs_decode_result.__getstate__(),\n",
    "'xbin': xbin, 'xbin_centers': xbin_centers}\n",
    "\n",
    "saveData(save_path, save_dict)\n",
    "print(f'save_path: {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b4531",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# 💾 Export CSVs: \n",
    "## INPUTS: directional_decoders_epochs_decode_result,\n",
    "\n",
    "extracted_merged_scores_df = directional_decoders_epochs_decode_result.build_complete_all_scores_merged_df()\n",
    "# extracted_merged_scores_df\n",
    "\n",
    "print(f'\\tAll scores df CSV exporting...')\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "export_df_dict = {'ripple_all_scores_merged_df': extracted_merged_scores_df}\n",
    "_csv_export_paths = directional_decoders_epochs_decode_result.perform_export_dfs_dict_to_csvs(extracted_dfs_dict=export_df_dict, parent_output_path=collected_outputs_path.resolve(), active_context=active_context, session_name=curr_session_name, curr_session_t_delta=t_delta,\n",
    "                                                                            #   user_annotation_selections={'ripple': any_good_selected_epoch_times},\n",
    "                                                                            #   valid_epochs_selections={'ripple': filtered_valid_epoch_times},\n",
    "                                                                            )\n",
    "\n",
    "print(f'\\t\\tsuccessfully exported ripple_all_scores_merged_df to {collected_outputs_path}!')\n",
    "_output_csv_paths_info_str: str = '\\n'.join([f'{a_name}: \"{file_uri_from_path(a_path)}\"' for a_name, a_path in _csv_export_paths.items()])\n",
    "print(f'\\t\\t\\tCSV Paths: {_output_csv_paths_info_str}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a98fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extracted_merged_scores_df.to_csv('test_(ripple_all_scores_merged_df).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a860a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ripple_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_extras_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbf34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ripple_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_extras_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbcbb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_laps_simple_pf_pearson_merged_df\n",
    "# filtered_ripple_simple_pf_pearson_merged_df\n",
    "# decoder_ripple_weighted_corr_df_dict\n",
    "ripple_weighted_corr_merged_df['ripple_start_t']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a95450",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcorr_column_names = ['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL']\n",
    "filtered_ripple_simple_pf_pearson_merged_df.label = filtered_ripple_simple_pf_pearson_merged_df.label.astype('int64')\n",
    "ripple_weighted_corr_merged_df['label'] = ripple_weighted_corr_merged_df['ripple_idx'].astype('int64')\n",
    "\n",
    "filtered_ripple_simple_pf_pearson_merged_df.join(ripple_weighted_corr_merged_df[wcorr_column_names], on='start') # , on='label'\n",
    "# filtered_ripple_simple_pf_pearson_merged_df.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac433aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(ripple_weighted_corr_merged_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_decoded_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3599f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window.save_selections()\n",
    "\n",
    "a_decoded_filter_epochs_decoder_result_dict.epochs.find_data_indicies_from_epoch_times([380.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77babf98",
   "metadata": {},
   "source": [
    "## 💾 Continue Saving/Exporting stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results() # newly_computed_values: [('pfdt_computation', 'maze_any')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7af96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_save_folder, split_save_paths, split_save_output_types, failed_keys = curr_active_pipeline.save_split_global_computation_results(debug_print=True,\n",
    "                                                                                                                                    #    include_includelist=['long_short_inst_spike_rate_groups'],\n",
    "                                                                                                                                       ) # encountered issue with pickling `long_short_post_decoding`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a869b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5() # NotImplementedError: a_field_attr: Attribute(name='LxC_aclus', default=None, validator=None, repr=True, eq=True, eq_key=None, order=True, order_key=None, hash=None, init=False, metadata=mappingproxy({'tags': ['dataset'], 'serialization': {'hdf': True}, 'custom_serialization_fn': None, 'hdf_metadata': {'track_eXclusive_cells': 'LxC'}}), type=<class 'numpy.ndarray'>, converter=None, kw_only=False, inherited=False, on_setattr=None, alias='LxC_aclus') could not be serialized and _ALLOW_GLOBAL_NESTED_EXPANSION is not allowed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f06d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE) ## #TODO 2024-02-16 14:25: - [ ] PicklingError: Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x7fd35e66b700>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell\n",
    "# curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10989b4",
   "metadata": {},
   "source": [
    "#### Get computation times/info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_most_recent_computation_time, each_epoch_latest_computation_time, each_epoch_each_result_computation_completion_times, (global_computations_latest_computation_time, global_computation_completion_times) = curr_active_pipeline.get_computation_times(debug_print=False)\n",
    "# each_epoch_latest_computation_time\n",
    "# each_epoch_each_result_computation_completion_times\n",
    "# global_computation_completion_times\n",
    "\n",
    "# curr_active_pipeline.get_merged_computation_function_validators()\n",
    "# Get the names of the global and non-global computations:\n",
    "all_validators_dict = curr_active_pipeline.get_merged_computation_function_validators()\n",
    "global_only_validators_dict = {k:v for k, v in all_validators_dict.items() if v.is_global}\n",
    "non_global_only_validators_dict = {k:v for k, v in all_validators_dict.items() if (not v.is_global)}\n",
    "non_global_comp_names: List[str] = [v.short_name for k, v in non_global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))] # ['firing_rate_trends', 'spike_burst_detection', 'pf_dt_sequential_surprise', 'extended_stats', 'placefield_overlap', 'ratemap_peaks_prominence2d', 'velocity_vs_pf_simplified_count_density', 'EloyAnalysis', '_perform_specific_epochs_decoding', 'recursive_latent_pf_decoding', 'position_decoding_two_step', 'position_decoding', 'lap_direction_determination', 'pfdt_computation', 'pf_computation']\n",
    "global_comp_names: List[str] = [v.short_name for k, v in global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))] # ['long_short_endcap_analysis', 'long_short_inst_spike_rate_groups', 'long_short_post_decoding', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_decoding_analyses', 'PBE_stats', 'rank_order_shuffle_analysis', 'directional_decoders_epoch_heuristic_scoring', 'directional_decoders_evaluate_epochs', 'directional_decoders_decode_continuous', 'merged_directional_placefields', 'split_to_directional_laps']\n",
    "\n",
    "# mappings between the long computation function names and their short names:\n",
    "non_global_comp_names_map: Dict[str, str] = {v.computation_fn_name:v.short_name for k, v in non_global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))}\n",
    "global_comp_names_map: Dict[str, str] = {v.computation_fn_name:v.short_name for k, v in global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))} # '_perform_long_short_endcap_analysis': 'long_short_endcap_analysis', '_perform_long_short_instantaneous_spike_rate_groups_analysis': 'long_short_inst_spike_rate_groups', ...}\n",
    "\n",
    "# convert long function names to short-names:\n",
    "each_epoch_each_result_computation_completion_times = {an_epoch:{non_global_comp_names_map.get(k, k):v for k,v in a_results_dict.items()} for an_epoch, a_results_dict in each_epoch_each_result_computation_completion_times.items()}\n",
    "global_computation_completion_times = {global_comp_names_map.get(k, k):v for k,v in global_computation_completion_times.items()}\n",
    "\n",
    "each_epoch_each_result_computation_completion_times\n",
    "global_computation_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967369f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_evaluate_required_computations\n",
    "\n",
    "# force_recompute_global = force_reload\n",
    "force_recompute_global = True\n",
    "active_probe_includelist = extended_computations_include_includelist\n",
    "# active_probe_includelist = ['lap_direction_determination']\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=active_probe_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "needs_computation_output_dict\n",
    "# valid_computed_results_output_list\n",
    "# remaining_include_function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9aeeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "['merged_directional_placefields', ]\n",
    "\n",
    "['long_short_decoding_analyses', 'long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'extended_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85822a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_estimation_parameters = curr_active_pipeline.sess.config.preprocessing_parameters.epoch_estimation_parameters.replays\n",
    "assert replay_estimation_parameters is not None\n",
    "replay_estimation_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3799ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recompute_earlier_than_date = datetime(2024, 4, 1, 0, 0, 0)\n",
    "recompute_earlier_than_date\n",
    "\n",
    "each_epoch_needing_recompute = [an_epoch for an_epoch, last_computed_datetime in each_epoch_latest_computation_time.items() if (last_computed_datetime < recompute_earlier_than_date)]\n",
    "each_epoch_needing_recompute\n",
    "each_epoch_each_result_needing_recompute = {an_epoch:{a_computation_name:last_computed_datetime for a_computation_name, last_computed_datetime in last_computed_datetimes_dict.items() if (last_computed_datetime < recompute_earlier_than_date)} for an_epoch, last_computed_datetimes_dict in each_epoch_each_result_computation_completion_times.items()}\n",
    "each_epoch_each_result_needing_recompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ffa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_times\n",
    "curr_active_pipeline.global_computation_results\n",
    "# curr_active_pipeline.try_load_split_pickled_global_computation_results\n",
    "\n",
    "global_computation_times = deepcopy(curr_active_pipeline.global_computation_results.computation_times.to_dict()) # DynamicParameters({'perform_rank_order_shuffle_analysis': datetime.datetime(2024, 4, 3, 5, 41, 31, 287680), '_decode_continuous_using_directional_decoders': datetime.datetime(2024, 4, 3, 5, 12, 7, 337326), '_perform_long_short_decoding_analyses': datetime.datetime(2024, 4, 3, 5, 43, 10, 361685), '_perform_long_short_pf_overlap_analyses': datetime.datetime(2024, 4, 3, 5, 43, 10, 489296), '_perform_long_short_firing_rate_analyses': datetime.datetime(2024, 4, 3, 5, 45, 3, 73472), '_perform_jonathan_replay_firing_rate_analyses': datetime.datetime(2024, 4, 3, 5, 45, 5, 168790), '_perform_long_short_post_decoding_analysis': datetime.datetime(2024, 2, 16, 18, 13, 4, 734621), '_perform_long_short_endcap_analysis': datetime.datetime(2024, 4, 3, 5, 45, 24, 274261), '_decode_and_evaluate_epochs_using_directional_decoders': datetime.datetime(2024, 4, 3, 5, 14, 37, 935482), '_perform_long_short_instantaneous_spike_rate_groups_analysis': datetime.datetime(2024, 4, 3, 5, 45, 24, 131955), '_split_to_directional_laps': datetime.datetime(2024, 4, 3, 5, 11, 22, 627789), '_build_merged_directional_placefields': datetime.datetime(2024, 4, 3, 5, 11, 28, 376078)})\n",
    "global_computation_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693db067",
   "metadata": {},
   "source": [
    "# 0️⃣ Pho Interactive Pipeline Jupyter Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275e3bb",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe54599",
   "metadata": {},
   "source": [
    "# 1️⃣ End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a533ba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:40.700275900Z",
     "start_time": "2023-11-16T23:21:40.584273Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "\n",
    "assert short_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "assert long_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "t_start, t_delta, t_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e348e0c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "# directional_merged_decoders_result = deepcopy(directional_decoders_epochs_decode_result)\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "spikes_df = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "\n",
    "global_computation_results = curr_active_pipeline.global_computation_results\n",
    "\n",
    " # spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "rank_order_results = global_computation_results.computed_data['RankOrder'] # : \"RankOrderComputationsContainer\"\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "# included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "directional_laps_results: DirectionalLapsResult = global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "# print(f'included_qclu_values: {included_qclu_values}')\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "# pos_bin_size = _recover_position_bin_size(track_templates.get_decoders()[0]) # 3.793023081021702\n",
    "# print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "# pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "\n",
    "## Simple Pearson Correlation\n",
    "assert spikes_df is not None\n",
    "(laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names = directional_merged_decoders_result.compute_simple_spike_time_v_pf_peak_x_by_epoch(track_templates=track_templates, spikes_df=deepcopy(spikes_df))\n",
    "## OUTPUTS: (laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names\n",
    "## Computes the highest-valued decoder for this score:\n",
    "best_decoder_index_col_name: str = 'best_decoder_index'\n",
    "laps_simple_pf_pearson_merged_df[best_decoder_index_col_name] = laps_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n",
    "ripple_simple_pf_pearson_merged_df[best_decoder_index_col_name] = ripple_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed3e0c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "print(f'pos_bin_size: {pos_bin_size}')\n",
    "print(f'ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}')\n",
    "\n",
    "# Radon Transforms:\n",
    "decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "# Weighted correlations:\n",
    "laps_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "ripple_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "decoder_laps_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "decoder_ripple_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "# Pearson's correlations:\n",
    "laps_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "ripple_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# laps_simple_pf_pearson_merged_df\n",
    "# ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "## Drop rows where all are missing\n",
    "corr_column_names = ['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr']\n",
    "# ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='all') # 350/412 rows\n",
    "filtered_laps_simple_pf_pearson_merged_df: pd.DataFrame = laps_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "filtered_ripple_simple_pf_pearson_merged_df: pd.DataFrame = ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "\n",
    "## Update the `decoder_ripple_filter_epochs_decoder_result_dict` with the included epochs:\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_ripple_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_laps_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a593338",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "## INPUTS: collected_outputs_path, directional_decoders_epochs_decode_result\n",
    "\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "## add the additional contexts:\n",
    "# active_context = active_context.adding_context_if_missing(custom_replay_name='TESTNEW', time_bin_size=directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size)\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "# \tif custom_suffix is not None:\n",
    "# \t\tadditional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "# \t\tprint(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "# \tadditional_session_context = None\n",
    "# \tprint(f'NO CUSTOM SUFFIX.')    \n",
    "    \n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_output_csv_paths = directional_decoders_epochs_decode_result.export_csvs(parent_output_path=collected_outputs_path, active_context=active_context, session_name=curr_session_name, curr_session_t_delta=t_delta,\n",
    "                                                                            # user_annotation_selections={'ripple': any_good_selected_epoch_times},\n",
    "                                                                            # valid_epochs_selections={'ripple': filtered_valid_epoch_times},\n",
    "                                                                            )\n",
    "\n",
    "\n",
    "print(f'\\t\\tsuccessfully exported directional_decoders_epochs_decode_result to {collected_outputs_path}!')\n",
    "_output_csv_paths_info_str: str = '\\n'.join([f'{a_name}: \"{file_uri_from_path(a_path)}\"' for a_name, a_path in _output_csv_paths.items()])\n",
    "# print(f'\\t\\t\\tCSV Paths: {_output_csv_paths}\\n')\n",
    "print(f'\\t\\t\\tCSV Paths: {_output_csv_paths_info_str}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b35196",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "# I have several python variables I want to print: t_start, t_delta, t_end\n",
    "# I want to generate a print statement that explicitly lists the variable name prior to its value like `print(f't_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')`\n",
    "# Currently I have to t_start, t_delta, t_end\n",
    "curr_active_pipeline.get_session_context()\n",
    "\n",
    "print(f'{curr_active_pipeline.session_name}:\\tt_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9071e94f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:43.601382Z",
     "start_time": "2023-11-16T23:21:40.702275600Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "## long_short_decoding_analyses:\n",
    "from attrs import astuple\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import LeaveOneOutDecodingAnalysis\n",
    "\n",
    "curr_long_short_decoding_analyses: LeaveOneOutDecodingAnalysis = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global \n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global `long_short_fr_indicies_analysis`:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n",
    "long_short_fr_indicies_df = long_short_fr_indicies_analysis_results['long_short_fr_indicies_df']\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result.Flat_epoch_time_bins_mean, expected_v_observed_result.Flat_decoder_time_bin_centers, expected_v_observed_result.num_neurons, expected_v_observed_result.num_timebins_in_epoch, expected_v_observed_result.num_total_flat_timebins, expected_v_observed_result.is_short_track_epoch, expected_v_observed_result.is_long_track_epoch, expected_v_observed_result.short_short_diff, expected_v_observed_result.long_long_diff\n",
    "\n",
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.05)\n",
    "\n",
    "## Update long_exclusive/short_exclusive properties with `long_short_fr_indicies_df`\n",
    "# long_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n",
    "# short_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f5d4f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Most popular\n",
    "# long_LR_name, short_LR_name, long_RL_name, short_RL_name, global_any_name\n",
    "\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7104fc37",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult, DirectionalLapsResult, DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']   \n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "included_qclu_values: float = rank_order_results.included_qclu_values\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93346114",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.BatchCompletionHandler import BatchSessionCompletionHandler\n",
    "\n",
    "BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617e7a3",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "list(directional_laps_results.directional_lap_specific_configs.keys()) # ['maze1_odd', 'maze1_even', 'maze2_odd', 'maze2_even']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912656a7",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "    \n",
    "    # for k, v in directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict.items():\n",
    "    #     print(f'{k}: v.decoding_time_bin_size: {v.decoding_time_bin_size}')\n",
    "    \n",
    "    individual_result_ripple_time_bin_sizes = [v.decoding_time_bin_size for k, v in directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict.items()]\n",
    "    if not np.allclose(ripple_decoding_time_bin_size, individual_result_ripple_time_bin_sizes):\n",
    "        individual_result_ripple_time_bin_size = individual_result_ripple_time_bin_sizes[0] # get the first\n",
    "        assert np.allclose(individual_result_ripple_time_bin_size, individual_result_ripple_time_bin_sizes), f\"`individual_result_ripple_time_bin_size ({individual_result_ripple_time_bin_size}) does not equal the individual result time bin sizes: {individual_result_ripple_time_bin_sizes}`. This can occur when there are epochs smaller than the desired size ({ripple_decoding_time_bin_size}) for the result and epochs_filtering_mode=EpochFilteringMode.ConstrainDecodingTimeBinSizeToMinimum\"\n",
    "        print(f'WARN: overriding directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size (original value: {directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size}) with individual_result_ripple_time_bin_size: {individual_result_ripple_time_bin_size}')\n",
    "        directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size = individual_result_ripple_time_bin_size # override the time_bin_size with the actually used one\n",
    "        ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "        print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    else:\n",
    "        # all are close, it's good\n",
    "        pass\n",
    "\n",
    "    # assert np.allclose(ripple_decoding_time_bin_size, individual_result_ripple_time_bin_sizes), f\"`directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size ({ripple_decoding_time_bin_size}) does not equal the individual result time bin sizes: {individual_result_ripple_time_bin_sizes}`. This can occur when there are epochs smaller than the desired size ({ripple_decoding_time_bin_size}) for the result and epochs_filtering_mode=EpochFilteringMode.ConstrainDecodingTimeBinSizeToMinimum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1c291",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881402df",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "# active_config_name: str = 'maze_any'\n",
    "active_config_name: str = global_epoch_name\n",
    "## INPUTS: curr_active_pipeline, active_config_name\n",
    "active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "if active_peak_prominence_2d_results is None:\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=None, fail_on_exception=False, debug_print=False)\n",
    "    # curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=[short_LR_name, short_RL_name, long_any_name, short_any_name], fail_on_exception=False, debug_print=False) # or at least\n",
    "    active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "    assert active_peak_prominence_2d_results is not None, f\"bad even after computation\"\n",
    "\n",
    "# active_peak_prominence_2d_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f67cb",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "if 'DirectionalDecodersDecoded' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "    all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "    spikes_df = directional_decoders_decode_result.spikes_df\n",
    "    continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "    previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "    print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4e959",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "\n",
    "wcorr_shuffle_results: SequenceBasedComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('SequenceBased', None)\n",
    "if wcorr_shuffle_results is not None:    \n",
    "    wcorr_ripple_shuffle: WCorrShuffle = wcorr_shuffle_results.wcorr_ripple_shuffle\n",
    "    if wcorr_ripple_shuffle is not None:\n",
    "        print(f'wcorr_ripple_shuffle.n_completed_shuffles: {wcorr_ripple_shuffle.n_completed_shuffles}')\n",
    "    else:\n",
    "        print(f'SequenceBased is computed but `wcorr_shuffle_results.wcorr_ripple_shuffle` is None.')        \n",
    "else:\n",
    "    print(f'SequenceBased is not computed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7394a",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrialByTrialActivityResult\n",
    "\n",
    "directional_trial_by_trial_activity_result: TrialByTrialActivityResult = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None)\n",
    "if directional_trial_by_trial_activity_result is None:\n",
    "    # if `KeyError: 'TrialByTrialActivity'` recompute\n",
    "    print(f'TrialByTrialActivity is not computed, computing it...')\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "    directional_trial_by_trial_activity_result = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None) ## try again to get the result\n",
    "    assert directional_trial_by_trial_activity_result is not None, f\"directional_trial_by_trial_activity_result is None even after forcing recomputation!!\"\n",
    "    print(f'\\t done.')\n",
    "\n",
    "## unpack either way:\n",
    "any_decoder_neuron_IDs = directional_trial_by_trial_activity_result.any_decoder_neuron_IDs\n",
    "active_pf_dt: PfND_TimeDependent = directional_trial_by_trial_activity_result.active_pf_dt\n",
    "directional_lap_epochs_dict: Dict[str, Epoch] = directional_trial_by_trial_activity_result.directional_lap_epochs_dict\n",
    "directional_active_lap_pf_results_dicts: Dict[str, TrialByTrialActivity] = directional_trial_by_trial_activity_result.directional_active_lap_pf_results_dicts\n",
    "## OUTPUTS: directional_trial_by_trial_activity_result, directional_active_lap_pf_results_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fad74c",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "wcorr_shuffle_results: SequenceBasedComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('SequenceBased', None)\n",
    "if wcorr_shuffle_results is not None:    \n",
    "    wcorr_ripple_shuffle: WCorrShuffle = wcorr_shuffle_results.wcorr_ripple_shuffle\n",
    "    if wcorr_ripple_shuffle is not None:  \n",
    "        print(f'wcorr_ripple_shuffle.n_completed_shuffles: {wcorr_ripple_shuffle.n_completed_shuffles}')\n",
    "    else:\n",
    "        print(f'SequenceBased is computed but wcorr_ripple_shuffle is None.')\n",
    "else:\n",
    "    print(f'SequenceBased is not computed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed0870",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "most_recent_time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# most_recent_time_bin_size\n",
    "most_recent_continuously_decoded_dict = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n",
    "# most_recent_continuously_decoded_dict\n",
    "\n",
    "## Adds in the 'pseudo2D' decoder in:\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# time_bin_size: float = 0.01\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict = continuously_decoded_result_cache_dict[time_bin_size]\n",
    "pseudo2D_decoder_continuously_decoded_result = continuously_decoded_dict.get('pseudo2D', None)\n",
    "if pseudo2D_decoder_continuously_decoded_result is None:\n",
    "    # compute here...\n",
    "    ## Currently used for both cases to decode:\n",
    "    t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "    single_global_epoch_df: pd.DataFrame = pd.DataFrame({'start': [t_start], 'stop': [t_end], 'label': [0]}) # Build an Epoch object containing a single epoch, corresponding to the global epoch for the entire session:\n",
    "    single_global_epoch: Epoch = Epoch(single_global_epoch_df)\n",
    "    spikes_df = directional_decoders_decode_result.spikes_df\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = pseudo2D_decoder.decode_specific_epochs(spikes_df=deepcopy(spikes_df), filter_epochs=single_global_epoch, decoding_time_bin_size=time_bin_size, debug_print=False)\n",
    "    continuously_decoded_dict['pseudo2D'] = pseudo2D_decoder_continuously_decoded_result\n",
    "    continuously_decoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2dc5fe",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "# NEW 2023-11-22 method: Get the templates (which can be filtered by frate first) and the from those get the decoders):        \n",
    "# track_templates: TrackTemplates = directional_laps_results.get_shared_aclus_only_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # shared-only\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only\n",
    "long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\n",
    "\n",
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n",
    "\n",
    "# `LongShortStatsItem` form (2024-01-02):\n",
    "# LR_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "# RL_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n",
    "LR_results_long_short_z_diffs = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "RL_results_long_short_z_diff = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260739a4f36c662",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestSplitResult\n",
    "\n",
    "if 'TrainTestSplit' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "    training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "    test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "    test_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "    train_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "    train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18cf18",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "if 'burst_detection' in curr_active_pipeline.computation_results[global_epoch_name].computed_data:\n",
    "    active_burst_intervals = curr_active_pipeline.computation_results[global_epoch_name].computed_data['burst_detection']['burst_intervals']\n",
    "# active_burst_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31f37d",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "active_extended_stats = global_results.get('extended_stats', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554d3bf5955d9d3",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624c62d5c18c556",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "# disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "# trivially_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "# significant_distant_remapping_endcap_aclus\n",
    "appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "appearing_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec24467335a760",
   "metadata": {},
   "source": [
    "# 1️⃣ POST-Compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c46e6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    },
    "tags": [
     "unwrap",
     "initial",
     "run-group-post-compute"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multi_sort_raster_browser\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import paired_separately_sort_neurons, paired_incremental_sort_neurons # _display_directional_template_debugger\n",
    "from neuropy.utils.indexing_helpers import paired_incremental_sorting, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ScrollBarWithSpinBox.ScrollBarWithSpinBox import ScrollBarWithSpinBox\n",
    "\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_SerializationMixin\n",
    "from pyphoplacecellanalysis.General.Model.ComputationResults import ComputedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses, RankOrderResult, ShuffleHelper, Zscorer, LongShortStatsTuple, DirectionalRankOrderLikelihoods, DirectionalRankOrderResult, RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "## Display Testing\n",
    "# from pyphoplacecellanalysis.External.pyqtgraph import QtGui\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import pyqtplot_build_image_bounds_extent, pyqtplot_plot_image\n",
    "\n",
    "spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "ripple_result_tuple, laps_result_tuple = rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')\n",
    "# ripple_result_tuple\n",
    "\n",
    "## Unpacks `rank_order_results`: \n",
    "# global_replays = Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# global_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# active_replay_epochs, active_epochs_df, active_selected_spikes_df = combine_rank_order_results(rank_order_results, global_replays, track_templates=track_templates)\n",
    "# active_epochs_df\n",
    "\n",
    "# ripple_result_tuple.directional_likelihoods_tuple.long_best_direction_indices\n",
    "dir_index_to_direction_name_map: Dict[int, str] = {0:'LR', 1:\"RL\"}\n",
    "\n",
    "\n",
    "## All three DataFrames are the same number of rows, each with one row corresponding to an Epoch:\n",
    "active_replay_epochs_df = deepcopy(rank_order_results.LR_ripple.epochs_df)\n",
    "# active_replay_epochs_df\n",
    "\n",
    "# Change column type to int8 for columns: 'long_best_direction_indices', 'short_best_direction_indices'\n",
    "# directional_likelihoods_df = pd.DataFrame.from_dict(ripple_result_tuple.directional_likelihoods_tuple._asdict()).astype({'long_best_direction_indices': 'int8', 'short_best_direction_indices': 'int8'})\n",
    "directional_likelihoods_df = ripple_result_tuple.directional_likelihoods_df\n",
    "# directional_likelihoods_df\n",
    "\n",
    "# 2023-12-15 - Newest method:\n",
    "# laps_combined_epoch_stats_df = rank_order_results.laps_combined_epoch_stats_df\n",
    "\n",
    "# ripple_combined_epoch_stats_df: pd.DataFrame  = rank_order_results.ripple_combined_epoch_stats_df\n",
    "# ripple_combined_epoch_stats_df\n",
    "\n",
    "\n",
    "# # Concatenate the three DataFrames along the columns axis:\n",
    "# # Assert that all DataFrames have the same number of rows:\n",
    "# assert len(active_replay_epochs_df) == len(directional_likelihoods_df) == len(ripple_combined_epoch_stats_df), \"DataFrames have different numbers of rows.\"\n",
    "# # Assert that all DataFrames have at least one row:\n",
    "# assert len(active_replay_epochs_df) > 0, \"active_replay_epochs_df is empty.\"\n",
    "# assert len(directional_likelihoods_df) > 0, \"directional_likelihoods_df is empty.\"\n",
    "# assert len(ripple_combined_epoch_stats_df) > 0, \"ripple_combined_epoch_stats_df is empty.\"\n",
    "# merged_complete_epoch_stats_df: pd.DataFrame = pd.concat([active_replay_epochs_df.reset_index(drop=True, inplace=False), directional_likelihoods_df.reset_index(drop=True, inplace=False), ripple_combined_epoch_stats_df.reset_index(drop=True, inplace=False)], axis=1)\n",
    "# merged_complete_epoch_stats_df = merged_complete_epoch_stats_df.set_index(active_replay_epochs_df.index, inplace=False)\n",
    "\n",
    "# merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "# merged_complete_epoch_stats_df.to_csv('output/2023-12-21_merged_complete_epoch_stats_df.csv')\n",
    "# merged_complete_epoch_stats_df\n",
    "\n",
    "laps_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.laps_merged_complete_epoch_stats_df ## New method\n",
    "ripple_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "all_directional_decoder_dict_value = directional_merged_decoders_result.all_directional_decoder_dict\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "# long_directional_pf1D_Decoder_value = directional_merged_decoders_result.long_directional_pf1D_Decoder\n",
    "# long_directional_decoder_dict_value = directional_merged_decoders_result.long_directional_decoder_dict\n",
    "# short_directional_pf1D_Decoder_value = directional_merged_decoders_result.short_directional_pf1D_Decoder\n",
    "# short_directional_decoder_dict_value = directional_merged_decoders_result.short_directional_decoder_dict\n",
    "\n",
    "all_directional_laps_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "all_directional_ripple_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\n",
    "\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = directional_merged_decoders_result.laps_track_identity_marginals_tuple\n",
    "ripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.ripple_directional_marginals_tuple\n",
    "ripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = directional_merged_decoders_result.ripple_track_identity_marginals_tuple\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "\n",
    "laps_all_epoch_bins_marginals_df = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "ripple_all_epoch_bins_marginals_df = directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753ca336",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-post-compute"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "# from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import HeuristicReplayScoring\n",
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size,\n",
    "                                                                                                                            should_only_include_user_selected_epochs=False)\n",
    "filtered_epochs_df\n",
    "# filtered_ripple_all_epoch_bins_marginals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae6e077",
   "metadata": {},
   "source": [
    "#### 2024-02-29 - 4pm - Filter the events for those meeting wcorr criteria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8cd0c",
   "metadata": {
    "tags": [
     "run-group-post-compute"
    ]
   },
   "outputs": [],
   "source": [
    "min_wcorr_threshold: float = 0.33\n",
    "min_wcorr_diff_threshold: float = 0.2\n",
    "\n",
    "is_included_large_wcorr_diff = np.any((filtered_ripple_all_epoch_bins_marginals_df[['wcorr_abs_diff']].abs() > min_wcorr_diff_threshold), axis=1)\n",
    "# is_included_large_wcorr_diff\n",
    "is_included_high_wcorr = np.any((filtered_ripple_all_epoch_bins_marginals_df[['long_best_wcorr', 'short_best_wcorr']].abs() > min_wcorr_threshold), axis=1)\n",
    "\n",
    "df = filtered_ripple_all_epoch_bins_marginals_df[is_included_large_wcorr_diff]\n",
    "# df = filtered_ripple_all_epoch_bins_marginals_df[is_included_high_wcorr]\n",
    "df\n",
    "\n",
    "# delta_aligned_start_t\n",
    "\n",
    "significant_epochs_start_ts = np.squeeze(df['ripple_start_t'].to_numpy()) ## for filtering\n",
    "\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(significant_epochs_start_ts) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict\n",
    "filtered_epochs_df = filtered_epochs_df.epochs.matching_epoch_times_slice(significant_epochs_start_ts)\n",
    "# filtered_ripple_all_epoch_bins_marginals_df = filtered_ripple_all_epoch_bins_marginals_df.epochs.matching_epoch_times_slice(significant_epochs_start_ts)\n",
    "\n",
    "included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "included_qclu_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da049a90",
   "metadata": {},
   "source": [
    "### 2024-06-25 - Advanced Time-dependent decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f702d",
   "metadata": {
    "tags": [
     "run-group-post-compute"
    ]
   },
   "outputs": [],
   "source": [
    "## Directional Versions: 'long_LR':\n",
    "from neuropy.core.epoch import subdivide_epochs, ensure_dataframe\n",
    "\n",
    "\n",
    "## INPUTS: long_LR_epochs_obj, long_LR_results\n",
    "\n",
    "a_pf1D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf1D_dt)\n",
    "a_pf2D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf2D_dt)\n",
    "\n",
    "# Example usage\n",
    "df: pd.DataFrame = ensure_dataframe(deepcopy(long_LR_epochs_obj)) \n",
    "df['epoch_type'] = 'lap'\n",
    "df['interval_type_id'] = 666\n",
    "\n",
    "subdivide_bin_size = 0.200  # Specify the size of each sub-epoch in seconds\n",
    "subdivided_df: pd.DataFrame = subdivide_epochs(df, subdivide_bin_size)\n",
    "# print(subdivided_df)\n",
    "\n",
    "## Evolve the ratemaps:\n",
    "_a_pf1D_dt_snapshots = a_pf1D_dt.batch_snapshotting(subdivided_df, reset_at_start=True)\n",
    "_a_pf2D_dt_snapshots = a_pf2D_dt.batch_snapshotting(subdivided_df, reset_at_start=True)\n",
    "# a_pf2D_dt.plot_ratemaps_2D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e607a444",
   "metadata": {},
   "source": [
    "# / 🛑 End Run Section 🛑\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b53c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ripple_merged_complete_epoch_stats_df\n",
    "laps_merged_complete_epoch_stats_df\n",
    "['long_best_direction_indices', 'short_best_direction_indices', 'combined_best_direction_indicies', 'long_relative_direction_likelihoods', 'short_relative_direction_likelihoods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the time series of Long-likely events\n",
    "# type(long_RL_results) # DynamicParameters\n",
    "long_LR_pf1D_Decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_directional_decoder_dict_value)\n",
    "list(all_directional_decoder_dict_value.keys()) # ['long_LR', 'long_RL', 'short_LR', 'short_RL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_all_epoch_bins_marginals_df\n",
    "laps_most_likely_direction_from_decoder\n",
    "long_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdabd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ripple_result_tuple) # pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations.DirectionalRankOrderResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "\n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15629dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots \n",
    "\n",
    "# @register_type_display(DirectionalRankOrderResult)\n",
    "def plot_histograms(self: DirectionalRankOrderResult, **kwargs) -> \"MatplotlibRenderPlots\":\n",
    "    \"\"\" \n",
    "    num='RipplesRankOrderZscore'\n",
    "    \"\"\"\n",
    "    print(f'.plot_histograms(..., kwargs: {kwargs})')\n",
    "    fig = plt.figure(layout=\"constrained\", **kwargs)\n",
    "    ax_dict = fig.subplot_mosaic(\n",
    "        [\n",
    "            [\"long_short_best_z_score_diff\", \"long_short_best_z_score_diff\"],\n",
    "            [\"long_best_z_scores\", \"short_best_z_scores\"],\n",
    "        ],\n",
    "    )\n",
    "    plots = (pd.DataFrame({'long_best_z_scores': self.long_best_dir_z_score_values}).hist(ax=ax_dict['long_best_z_scores'], bins=21, alpha=0.8),\n",
    "        pd.DataFrame({'short_best_z_scores': self.short_best_dir_z_score_values}).hist(ax=ax_dict['short_best_z_scores'], bins=21, alpha=0.8),\n",
    "        pd.DataFrame({'long_short_best_z_score_diff': self.long_short_best_dir_z_score_diff_values}).hist(ax=ax_dict['long_short_best_z_score_diff'], bins=21, alpha=0.8),\n",
    "    )\n",
    "    return MatplotlibRenderPlots(name='plot_histogram_figure', figures=[fig], axes=ax_dict)\n",
    "\n",
    "\n",
    "# register_type_display(plot_histograms, DirectionalRankOrderResult)\n",
    "## Call the newly added `plot_histograms` function on the `ripple_result_tuple` object which is of type `DirectionalRankOrderResult`:\n",
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c291690",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_result_tuple.plot_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b30bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💾 CSVs \n",
    "print(f'\\t try saving to CSV...')\n",
    "merged_complete_epoch_stats_df = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "merged_complete_epoch_stats_df\n",
    "merged_complete_ripple_epoch_stats_df_output_path = curr_active_pipeline.get_output_path().joinpath(f'{DAY_DATE_TO_USE}_merged_complete_epoch_stats_df.csv').resolve()\n",
    "merged_complete_epoch_stats_df.to_csv(merged_complete_ripple_epoch_stats_df_output_path)\n",
    "print(f'\\t saving to CSV: {merged_complete_ripple_epoch_stats_df_output_path} done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60749347",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "print(f'\\tdone. building global result.')\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "selected_spikes_df = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.selected_spikes_df)\n",
    "# active_epochs = global_computation_results.computed_data['RankOrder'].ripple_most_likely_result_tuple.active_epochs\n",
    "active_epochs = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.epochs_df)\n",
    "track_templates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "\n",
    "ripple_combined_epoch_stats_df, ripple_new_output_tuple = RankOrderAnalyses.pandas_df_based_correlation_computations(selected_spikes_df=selected_spikes_df, active_epochs_df=active_epochs, track_templates=track_templates, num_shuffles=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313886d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_output_tuple (output_active_epoch_computed_values, valid_stacked_arrays, real_stacked_arrays, n_valid_shuffles) = ripple_new_output_tuple\n",
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_combined_epoch_stats_df, curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_new_output_tuple = ripple_combined_epoch_stats_df, ripple_new_output_tuple\n",
    "print(f'done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc018065",
   "metadata": {},
   "source": [
    "# Call perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _subfn_compute_complete_df_metrics\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = True\n",
    "save_csvs:bool = True\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "# %pdb on\n",
    "## Combine the output of `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "# desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=10)\n",
    "# desired_shared_decoding_time_bin_sizes = np.linspace(start=0.005, stop=0.03, num=10)\n",
    "# _across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, return_full_decoding_results=return_full_decoding_results,\n",
    "#                                                 desired_shared_decoding_time_bin_sizes=desired_shared_decoding_time_bin_sizes,\n",
    "#                                                 )\n",
    "\n",
    "\n",
    "# desired_laps_decoding_time_bin_size = [None] # doesn't work\n",
    "# desired_laps_decoding_time_bin_size = [1.5] # large so it doesn't take long\n",
    "# desired_ripple_decoding_time_bin_size = [0.010, 0.020]\n",
    "# desired_ripple_decoding_time_bin_size = [0.010, 0.020, 0.025]\n",
    "\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.030, 0.044, 0.050, 0.058, 0.072, 0.086, 0.100])\n",
    "desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.030, 0.044, 0.050, 0.058,])\n",
    "\n",
    "# custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_size,\n",
    "#                                                                                 desired_ripple_decoding_time_bin_size=desired_ripple_decoding_time_bin_size,\n",
    "#                                                                         use_single_time_bin_per_epoch=[False],\n",
    "#                                                                         minimum_event_duration=[desired_ripple_decoding_time_bin_size[-1]])\n",
    "\n",
    "# Shared time bin sizes\n",
    "custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_shared_decoding_time_bin_size=desired_shared_decoding_time_bin_sizes, use_single_time_bin_per_epoch=[False], minimum_event_duration=[desired_shared_decoding_time_bin_sizes[-1]]) # with Ripples\n",
    "\n",
    "\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, save_csvs=save_csvs, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                # desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=4),\n",
    "                                                custom_all_param_sweep_options=custom_all_param_sweep_options, # directly provide the parameter sweeps\n",
    "                                                # additional_session_context=additional_session_context,\n",
    "                                                additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n",
    "\n",
    "\n",
    "if return_full_decoding_results:\n",
    "    # with `return_full_decoding_results == True`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_full_directional_merged_decoders_result, output_directional_decoders_epochs_decode_results_dict = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    # validate the result:\n",
    "    {k:v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size for k,v in output_full_directional_merged_decoders_result.items()}\n",
    "    # assert np.all([np.isclose(dict(k)['desired_shared_decoding_time_bin_size'], v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size) for k,v in output_full_directional_merged_decoders_result.items()]), f\"the desired time_bin_size in the parameters should match the one used that will appear in the decoded result\"\n",
    "\n",
    "else:\n",
    "    # with `return_full_decoding_results == False`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    output_full_directional_merged_decoders_result = None\n",
    "\n",
    "\n",
    "(several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb39d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {frozenset({('desired_shared_decoding_time_bin_size', 0.025), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.025,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.03), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.03,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.044), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.044,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.05), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c59a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df\n",
    "\n",
    "ripple_out_path # 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_marginals_df).csv'\n",
    "# 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_marginals_df).csv'\n",
    "several_time_bin_sizes_time_bin_ripple_df\n",
    "\n",
    "ripple_time_bin_marginals_out_path # 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_time_bin_marginals_df).csv'\n",
    "# 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_time_bin_marginals_df).csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dfa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v: DecoderDecodedEpochsResult = list(output_directional_decoders_epochs_decode_results_dict.values())[0]\n",
    "v.add_all_extra_epoch_columns(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates)\n",
    "# _out = v.export_csvs(parent_output_path=collected_outputs_path, active_context=curr_active_pipeline.get_session_context(), session_name=curr_active_pipeline.session_name, curr_session_t_delta=t_delta)\n",
    "\n",
    "# assert self.collected_outputs_path.exists()\n",
    "# curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "# CURR_BATCH_OUTPUT_PREFIX: str = f\"{self.BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "# print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_computations\n",
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "# batch_extended_computations(curr_active_pipeline, include_includelist=['merged_directional_placefields'], include_global_functions=True, fail_on_exception=True, force_recompute=False)\n",
    "# directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context()\n",
    "# _out = directional_merged_decoders_result.compute_and_export_marginals_df_csvs(parent_output_path=self.collected_outputs_path, active_context=active_context)\n",
    "# print(f'successfully exported marginals_df_csvs to {self.collected_outputs_path}!')\n",
    "# (laps_marginals_df, laps_out_path), (ripple_marginals_df, ripple_out_path) = _out\n",
    "# (laps_marginals_df, laps_out_path, laps_time_bin_marginals_df, laps_time_bin_marginals_out_path), (ripple_marginals_df, ripple_out_path, ripple_time_bin_marginals_df, ripple_time_bin_marginals_out_path) = _out\n",
    "# print(f'\\tlaps_out_path: {laps_out_path}\\n\\tripple_out_path: {ripple_out_path}\\n\\tdone.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take extra computations from `_decode_and_evaluate_epochs_using_directional_decoders` and integrate into the multi-time-bin results from `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_all_df_score_metrics\n",
    "\n",
    "should_skip_radon_transform = True\n",
    "## Recompute the epoch scores/metrics such as radon transform and wcorr:\n",
    "\n",
    "a_sweep_tuple, a_pseudo_2D_result = list(output_full_directional_merged_decoders_result.items())[0]\n",
    "a_decoder_laps_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result)\n",
    "a_decoder_ripple_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_ripple_filter_epochs_decoder_result)\n",
    "\n",
    "(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict), merged_df_outputs_tuple, raw_dict_outputs_tuple = _compute_all_df_score_metrics(directional_merged_decoders_result, track_templates,\n",
    "                                                                                                                                                                                    decoder_laps_filter_epochs_decoder_result_dict=a_decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict=a_decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                                                                    spikes_df=deepcopy(curr_active_pipeline.sess.spikes_df),\n",
    "                                                                                                                                                                                    should_skip_radon_transform=should_skip_radon_transform)\n",
    "laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df, laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df = merged_df_outputs_tuple\n",
    "decoder_laps_radon_transform_df_dict, decoder_ripple_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict, decoder_ripple_radon_transform_extras_dict, decoder_laps_weighted_corr_df_dict, decoder_ripple_weighted_corr_df_dict = raw_dict_outputs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfda868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `_perform_compute_custom_epoch_decoding`\n",
    "\n",
    "a_sweep_tuple\n",
    "# a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result\n",
    "# a_pseudo_2D_result\n",
    "# a_pseudo_2D_result.short_directional_decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9603a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_keys_if_possible('several_time_bin_sizes_laps_df', several_time_bin_sizes_laps_df)\n",
    "print_keys_if_possible('output_full_directional_merged_decoders_result', output_full_directional_merged_decoders_result, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a71abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_file_pat\n",
    "collected_outputs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_laps_decoding_accuracy_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd6f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from neuropy.utils.matplotlib_helpers import pho_jointplot\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot, plot_histograms\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# def pho_jointplot(*args, **kwargs):\n",
    "# \t\"\"\" wraps sns.jointplot to allow adding titles/axis labels/etc.\"\"\"\n",
    "# \ttitle = kwargs.pop('title', None)\n",
    "# \t_out = sns.jointplot(*args, **kwargs)\n",
    "# \tif title is not None:\n",
    "# \t\tplt.suptitle(title)\n",
    "# \treturn _out\n",
    "\n",
    "common_kwargs = dict(ylim=(0,1), hue='time_bin_size') # , marginal_kws=dict(bins=25, fill=True)\n",
    "# sns.jointplot(data=a_laps_all_epoch_bins_marginals_df, x='lap_start_t', y='P_Long', kind=\"scatter\", color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per epoch') #color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per epoch')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per time bin')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per time bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43311ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_histograms\n",
    "\n",
    "# You can use it like this:\n",
    "plot_histograms('Laps', 'One Session', several_time_bin_sizes_time_bin_laps_df, \"several\")\n",
    "plot_histograms('Ripples', 'One Session', several_time_bin_sizes_time_bin_ripple_df, \"several\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(\n",
    "#     several_time_bin_sizes_laps_df, x=\"P_Long\", col=\"species\", row=\"time_bin_size\",\n",
    "#     binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    "# )\n",
    "\n",
    "sns.displot(\n",
    "    several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', row=\"time_bin_size\",\n",
    "    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be351c18",
   "metadata": {},
   "source": [
    "# 2024-01-31 - Reinvestigation regarding remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d7495",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis:\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "truncation_checking_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d9b54",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "## From Jonathan Long/Short Peaks\n",
    "\n",
    "adds `active_peak_prominence_2d_results` to existing `neuron_replay_stats_df` from `jonathan_firing_rate_analysis_result`, adding the `['long_pf2D_peak_x', 'long_pf2D_peak_y'] + ['short_pf2D_peak_x', 'short_pf2D_peak_y']` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3641aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "neuron_replay_stats_df: pd.DataFrame = deepcopy(jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "neuron_replay_stats_df, all_modified_columns = jonathan_firing_rate_analysis_result.add_peak_promenance_pf_peaks(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates)\n",
    "neuron_replay_stats_df, all_modified_columns = jonathan_firing_rate_analysis_result.add_directional_pf_maximum_peaks(track_templates=track_templates)\n",
    "both_included_neuron_stats_df = deepcopy(neuron_replay_stats_df[neuron_replay_stats_df['LS_pf_peak_x_diff'].notnull()]).drop(columns=['track_membership', 'neuron_type'])\n",
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(jonathan_firing_rate_analysis_result) # pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.JonathanFiringRateAnalysisResult\n",
    "\n",
    "rdf_df: pd.DataFrame = deepcopy(jonathan_firing_rate_analysis_result.rdf.rdf)\n",
    "rdf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d371a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to JSON\n",
    "output_path = Path(f'output/{get_now_day_str()}_rdf_df.json').resolve()\n",
    "rdf_df.to_json(output_path, orient='records', lines=True) ## This actually looks pretty good!\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a677cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to JSON\n",
    "output_path = Path(f'output/{get_now_day_str()}_neuron_replay_stats_df.json').resolve()\n",
    "neuron_replay_stats_df.to_json(output_path, orient='records', lines=True) ## This actually looks pretty good!\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b794a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_columns = ['start', 'end']\n",
    "invalid_columns = ['active_aclus', 'is_neuron_active', 'firing_rates']\n",
    "invalid_df_subset = rdf_df[join_columns + invalid_columns]\n",
    "invalid_df_subset\n",
    "\n",
    "# Reload DataFrame from JSON\n",
    "df_read: pd.DataFrame = pd.read_json(output_path, orient='records', lines=True)\n",
    "df_read\n",
    "\n",
    "# rdf_df.convert_dtypes().dtypes\n",
    "# rdf_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b50ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf_aclus = both_included_neuron_stats_df.aclu[both_included_neuron_stats_df.has_long_pf].to_numpy()\n",
    "short_pf_aclus = both_included_neuron_stats_df.aclu[both_included_neuron_stats_df.has_short_pf].to_numpy()\n",
    "\n",
    "long_pf_aclus, short_pf_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c34fd9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "# 2024-04-09 - Maximum peaks only for each template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbcdfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import NumpyHelpers\n",
    "from neuropy.utils.indexing_helpers import intersection_of_arrays, union_of_arrays\n",
    "from neuropy.utils.indexing_helpers import unwrap_single_item\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing import NewType\n",
    "from typing_extensions import TypeAlias\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "DecoderName = NewType('DecoderName', str)\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "\n",
    "# from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _get_directional_pf_peaks_dfs\n",
    "\n",
    "# (LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df), AnyDir_decoder_aclu_MAX_peak_maps_df = _get_directional_pf_peaks_dfs(track_templates, drop_aclu_if_missing_long_or_short=False)\n",
    "\n",
    "(LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df), AnyDir_decoder_aclu_MAX_peak_maps_df = track_templates.get_directional_pf_maximum_peaks_dfs(drop_aclu_if_missing_long_or_short=False)\n",
    "\n",
    "\n",
    "AnyDir_decoder_aclu_MAX_peak_maps_df\n",
    "# LR_only_decoder_aclu_MAX_peak_maps_df\n",
    "# RL_only_decoder_aclu_MAX_peak_maps_df\n",
    "\n",
    "long_peak_x = LR_only_decoder_aclu_MAX_peak_maps_df['long_LR'].to_numpy()\n",
    "short_peak_x = LR_only_decoder_aclu_MAX_peak_maps_df['short_LR'].to_numpy()\n",
    "peak_x_diff = LR_only_decoder_aclu_MAX_peak_maps_df['peak_diff'].to_numpy()\n",
    "# decoder_aclu_peak_maps_dict\n",
    "\n",
    "## OUTPUTS: AnyDir_decoder_aclu_MAX_peak_maps_df,\n",
    "## OUTPUTS: LR_only_decoder_aclu_MAX_peak_maps_df, long_peak_x, long_peak_x, peak_x_diff\n",
    "## OUTPUTS: RL_only_decoder_aclu_MAX_peak_maps_df, long_peak_x, long_peak_x, peak_x_diff\n",
    "\n",
    "AnyDir_decoder_aclu_MAX_peak_maps_df\n",
    "LR_only_decoder_aclu_MAX_peak_maps_df\n",
    "RL_only_decoder_aclu_MAX_peak_maps_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed05490",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_filtered_flat_peaks_df: pd.DataFrame = deepcopy(AnyDir_decoder_aclu_MAX_peak_maps_df).reset_index(drop=False, names=['aclu'])\n",
    "a_filtered_flat_peaks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9527c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_peak_prominence_2d_results.filtered_flat_peaks_df\n",
    "\n",
    "binned_peak_columns = ['peak_center_binned_x', 'peak_center_binned_y']\n",
    "continuous_peak_columns = ['peak_center_x', 'peak_center_y']\n",
    "\n",
    "['peak_prominence', 'peak_relative_height', 'slice_level_multiplier']\n",
    "\n",
    "['neuron_id', 'neuron_peak_firing_rate']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b90dc",
   "metadata": {},
   "source": [
    "## 2024-02-08 - Filter to find only the clear remap examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphocorehelpers.indexing_helpers import dict_to_full_array\n",
    "\n",
    "any_decoder_neuron_IDs = deepcopy(track_templates.any_decoder_neuron_IDs)\n",
    "any_decoder_neuron_IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0cf56",
   "metadata": {},
   "source": [
    "### Get num peaks exclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c849dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: `directional_active_lap_pf_results_dicts`, not sure why\n",
    "\n",
    "neuron_ids_dict = {k:v.neuron_ids for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "neuron_ids_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec42a8d",
   "metadata": {},
   "source": [
    "## 🟢 Get stability for each cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ec2d7",
   "metadata": {},
   "source": [
    "### 2024-02-08 - 3pm - new stability dataframe to look at stability of each cell across decoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57869e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: directional_active_lap_pf_results_dicts\n",
    "\n",
    "# for k,v in directional_active_lap_pf_results_dicts.items():\n",
    "# stability_dict = {k:v.aclu_to_stability_score_dict for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "# stability_dict = {k:dict_to_full_array(v.aclu_to_stability_score_dict, full_indicies=any_decoder_neuron_IDs, fill_value=0.0) for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "# stability_dict\n",
    "\n",
    "\n",
    "# list(stability_dict.values())\n",
    "\n",
    "stability_dict = {k:list(v.aclu_to_stability_score_dict.values()) for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "# stability_dict\n",
    "## all the same size hopefully!\n",
    "# [len(v) for v in list(stability_dict.values())]\n",
    "\n",
    "stability_df: pd.DataFrame = pd.DataFrame({'aclu': any_decoder_neuron_IDs, **stability_dict})\n",
    "# stability_df.rename(dict(zip([], [])))\n",
    "stability_df\n",
    "\n",
    "## OUTPUTS: stability_df, stability_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b4ec86",
   "metadata": {},
   "source": [
    "# 2023-09-07 - Track Graphics Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b53254",
   "metadata": {},
   "source": [
    "## 🟢🖼️🎨 2024-02-16 - NOW - Working Track Remapping Diagram Figure!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import plot_bidirectional_track_remapping_diagram, _plot_track_remapping_diagram\n",
    "\n",
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "collector = plot_bidirectional_track_remapping_diagram(track_templates, grid_bin_bounds=long_pf2D.config.grid_bin_bounds, active_context=curr_active_pipeline.build_display_context_for_session(display_fn_name='plot_bidirectional_track_remapping_diagram'),\n",
    "                                                        enable_adjust_overlapping_text=False, draw_point_aclu_labels=False, enable_interactivity=False, is_dark_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d1e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "curr_active_pipeline.display('_display_directional_track_remapping_diagram', save_figure=True, is_dark_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4701a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_aclu_if_missing_long_or_short = True\n",
    "# LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df = _get_directional_pf_peaks_dfs(track_templates, drop_aclu_if_missing_long_or_short=drop_aclu_if_missing_long_or_short)\n",
    "# drop_aclu_if_missing_long_or_short =False\n",
    "(LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df), AnyDir_decoder_aclu_MAX_peak_maps_df = track_templates.get_directional_pf_maximum_peaks_dfs(drop_aclu_if_missing_long_or_short=drop_aclu_if_missing_long_or_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c35494",
   "metadata": {},
   "outputs": [],
   "source": [
    "AnyDir_decoder_aclu_MAX_peak_maps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfe113",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "_by_ANY = AnyDir_decoder_aclu_MAX_peak_maps_df.sort_values(by=['long_LR', 'long_RL'], inplace=False)\n",
    "long_peak_sorted_unit_colors_ndarray_map = dict(zip(_by_ANY.index.to_numpy(), list(_unit_colors_ndarray_map.values())))\n",
    "long_peak_sorted_unit_colors_ndarray_map\n",
    "\n",
    "# LR_only_decoder_aclu_MAX_peak_maps_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5286baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "AnyDir_decoder_aclu_MAX_peak_maps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_helper_neuron_id_to_sort_IDX_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7183e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_peak_sorted_unit_colors_ndarray_map_LR = dict(zip(sorted_neuron_IDs_lists[0], list(_unit_colors_ndarray_map.values())))\n",
    "long_peak_sorted_unit_colors_ndarray_map_RL = dict(zip(sorted_neuron_IDs_lists[1], list(_unit_colors_ndarray_map.values())))\n",
    "long_peak_sorted_unit_colors_ndarray_map_LR\n",
    "long_peak_sorted_unit_colors_ndarray_map_RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be25d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "colormap = mcolors.ListedColormap(['white'])\n",
    "normalize = mcolors.Normalize(vmin=active_aclus.min(), vmax=active_aclus.max())\n",
    "scalar_map = cm.ScalarMappable(norm=normalize, cmap=colormap)\n",
    "\n",
    "# Create a constant colormap with only white color\n",
    "\n",
    "color = scalar_map.to_rgba(active_aclus)\n",
    "\n",
    "color = [_unit_colors_ndarray_map[an_aclu] for an_aclu in active_aclus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a9a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS:\n",
    "neuron_replay_stats_df\n",
    "\n",
    "_active_LR_aclus = np.array(list(_output_by_aclu_dict_LR.keys()))\n",
    "_active_LR_aclus\n",
    "\n",
    "is_active_LR_aclus = np.isin(neuron_replay_stats_df.aclu, _active_LR_aclus)\n",
    "_temp_neuron_replay_stats_df = neuron_replay_stats_df[is_active_LR_aclus]\n",
    "\n",
    "is_active_LR_long_peak_either_cap_dict = _temp_neuron_replay_stats_df['is_long_peak_either_cap'].to_dict()\n",
    "is_active_LR_long_peak_either_cap_dict\n",
    "\n",
    "\n",
    "# either_cap_aclu = {k:v for k,v in is_active_LR_long_peak_either_cap_dict.items() if (v is True)}\n",
    "\n",
    "active_LR_either_cap_aclus = np.array([k for k,v in is_active_LR_long_peak_either_cap_dict.items() if (v is True)])\n",
    "active_LR_either_cap_aclus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dac9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Selected ACLUS manually:\n",
    "\n",
    "## `FakePickEvent` is used to highlight specified aclus by emulating a selection event.\n",
    "#  matplotlib.backend_bases.PickEvent\n",
    "import attrs\n",
    "FakePickEvent = attrs.make_class(\"FakePickEvent\", {k:field() for k in (\"ind\", )})\n",
    "\n",
    "included_aclus = [45, 24, 17, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689f191",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: included_aclus, LR_only_decoder_aclu_MAX_peak_maps_df, RL_only_decoder_aclu_MAX_peak_maps_df, _outputs_tuple_LR, _outputs_tuple_RL\n",
    "included_aclus = active_LR_either_cap_aclus\n",
    "# LR:\n",
    "LR_included_indicies = np.where(np.isin(LR_only_decoder_aclu_MAX_peak_maps_df.index, included_aclus))[0] # LR_included_indicies # [ 6,  9, 22, 36]\n",
    "LR_fake_event: FakePickEvent = FakePickEvent(ind=np.array(LR_included_indicies))\n",
    "_output_dict_LR, _output_by_aclu_dict_LR = _outputs_tuple_LR\n",
    "scatter_select_function_LR = _output_dict_LR['scatter_select_function']\n",
    "scatter_select_function_LR(LR_fake_event)\n",
    "\n",
    "## RL:\n",
    "RL_included_indicies = np.where(np.isin(RL_only_decoder_aclu_MAX_peak_maps_df.index, included_aclus))[0]\n",
    "RL_fake_event: FakePickEvent = FakePickEvent(ind=np.array(RL_included_indicies))\n",
    "_output_dict_RL, _output_by_aclu_dict_RL = _outputs_tuple_RL\n",
    "scatter_select_function_RL = _output_dict_RL['scatter_select_function']\n",
    "scatter_select_function_RL(RL_fake_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce7326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.preprocessing_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6fcb1",
   "metadata": {},
   "source": [
    "# 🎨 2024-02-06 - Other Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5623a2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "#  Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "curr_active_pipeline.prepare_for_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968df7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.tree_helpers import find_tree_item_by_text\n",
    "from pyphoplacecellanalysis.GUI.Qt.MainApplicationWindows.LauncherWidget.LauncherWidget import LauncherWidget\n",
    "\n",
    "widget = LauncherWidget()\n",
    "treeWidget = widget.mainTreeWidget # QTreeWidget\n",
    "widget.build_for_pipeline(curr_active_pipeline=curr_active_pipeline)\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650eea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "spike_raster_window, (active_2d_plot, active_3d_plot, main_graphics_layout_widget, main_plot_widget, background_static_scroll_plot_widget) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=True)\n",
    "spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_spikes_df\n",
    "# curr_active_pipeline\n",
    "epoch_spikes_df = deepcopy(long_one_step_decoder_1D.spikes_df)\n",
    "# filter_epoch_spikes_df_L\n",
    "# filter_epoch_spikes_df_S\n",
    "epoch_spikes_df\n",
    "\n",
    "epochs_df_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99892ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_specific_binned_spike_rate_df, unit_specific_binned_spike_counts_df, time_window_edges, time_window_edges_binning_info = SpikeRateTrends.compute_simple_time_binned_firing_rates_df(epoch_spikes_df, time_bin_size_seconds=0.005, debug_print=False)\n",
    "# unit_specific_binned_spike_rate_df.to_numpy() # (160580, 45)\n",
    "\n",
    "# Compute average firing rate for each neuron\n",
    "unit_avg_firing_rates = np.nanmean(unit_specific_binned_spike_rate_df.to_numpy(), axis=0) # (n_neurons, )\n",
    "unit_avg_firing_rates = np.nanmax(unit_specific_binned_spike_rate_df.to_numpy(), axis=0) # (n_neurons, )\n",
    "unit_avg_firing_rates            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d5dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "# instantaneous_time_bin_size_seconds = 0.005\n",
    "instantaneous_time_bin_size_seconds = 0.02\n",
    "\n",
    "# epoch_inst_fr_df_list, epoch_inst_fr_signal_list, epoch_avg_firing_rates_list = SpikeRateTrends.compute_epochs_unit_avg_inst_firing_rates(spikes_df=filter_epoch_spikes_df_L, filter_epochs=epochs_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, instantaneous_time_bin_size_seconds=0.005, use_instantaneous_firing_rate=True, debug_print=True)\n",
    "epoch_inst_fr_df_list, epoch_inst_fr_signal_list, epoch_avg_firing_rates_list = SpikeRateTrends.compute_epochs_unit_avg_inst_firing_rates(spikes_df=filter_epoch_spikes_df_L, filter_epochs=epochs_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, instantaneous_time_bin_size_seconds=instantaneous_time_bin_size_seconds, use_instantaneous_firing_rate=False, debug_print=False)\n",
    "# epoch_avg_firing_rates_list # (294, 42), (n_filter_epochs, n_neurons)\n",
    "# epoch_avg_firing_rates_list\n",
    "\n",
    "across_epoch_avg_firing_rates = np.mean(epoch_avg_firing_rates_list, 0) # (42,)\n",
    "across_epoch_avg_firing_rates\n",
    "# unit_specific_binned_spike_rate_df\n",
    "# unit_specific_binned_spike_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch_inst_fr_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch_inst_fr_df_list) # (n_epoch_time_bins[i], n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a0c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps'] # , 'AddTimeIntervals.SessionEpochs'\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95289eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps'] # , 'AddTimeIntervals.SessionEpochs'\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('active_2d_plot.ui.menus.custom_context_menus', active_2d_plot.ui.menus.custom_context_menus, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d0bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Menus.PhoMenuHelper import PhoMenuHelper\n",
    "\n",
    "_menu_commands_dict = PhoMenuHelper.build_programmatic_menu_command_dict(active_2d_plot)\n",
    "print_keys_if_possible('_menu_commands_dict', _menu_commands_dict, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7e1345",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_renderables_menu    \n",
    "menu_commands = ['AddMatplotlibPlot.DecodedPosition', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps'] # , 'AddTimeIntervals.SessionEpochs'\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()\n",
    "\n",
    "['AddMatplotlibPlot'\n",
    " 'DecodedPosition'\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfb6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f'AddTimeCurves.{k}' for k in add_renderables_menu['AddTimeCurves']] # ['AddTimeCurves.Position', 'AddTimeCurves.Velocity', 'AddTimeCurves.Random', 'AddTimeCurves.RelativeEntropySurprise', 'AddTimeCurves.Custom']\n",
    "[f'AddMatplotlibPlot.{k}' for k in add_renderables_menu['AddMatplotlibPlot']] # ['AddMatplotlibPlot.DecodedPosition', 'AddMatplotlibPlot.Custom']\n",
    "[f'Clear.{k}' for k in add_renderables_menu['Clear']] # ['Clear.all']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13876513",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = curr_active_pipeline.display(display_function='_display_trial_to_trial_reliability', active_session_configuration_context=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac20997",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = _out.root_render_widget\n",
    "# Set column stretches to adjust column widths\n",
    "# win.ci.setColumnStretch(0, 5)  # First column, stretch factor of 5\n",
    "# win.ci.setColumnStretch(1, 5)  # Second column, stretch factor of 5\n",
    "# win.ci.setColumnStretch(6, 1)  # Last column, stretch factor of 1 (smaller width)\n",
    "\n",
    "max_col_idx: int = 5\n",
    "# for i in np.arange(max_col_idx+1):\n",
    "# \twin.ci.layout.setColumnPreferredWidth(i, 250) # larger\n",
    "win.ci.layout.setColumnPreferredWidth(max_col_idx, 5)   # Last column width (smaller)\n",
    "win.ci.layout.setColumnFixedWidth(max_col_idx, 5)\n",
    "win.ci.layout.setColumnMaximumWidth(max_col_idx, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label item for the footer\n",
    "footer = pg.LabelItem(justify='center')\n",
    "footer.setText('Footer Text Here')\n",
    "\n",
    "# Add the footer label below the plot\n",
    "win.addItem(footer, row=2, col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c2bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('add_renderables_menu', add_renderables_menu, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a70360",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.build_epoch_intervals_visual_configs_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b41f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downsample the preview background scroller for more fluid scrolling? Or is that not the problem?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Disconnect the connection to see if that's what lagging out the scrolling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.connection_man.active_connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.rate_limited_signal_scrolled_proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e77367",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.enable_debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71114415",
   "metadata": {},
   "outputs": [],
   "source": [
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-SpikeRaster2D_update_time.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    active_2d_plot.update_scroll_window_region(441.0, 442.0, block_signals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf6288",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the legends:\n",
    "legends_dict = active_2d_plot.build_or_update_all_epoch_interval_rect_legends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the legends\n",
    "active_2d_plot.remove_all_epoch_interval_rect_legends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72734c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.epochs_plotting_mixins import EpochDisplayConfig, _get_default_epoch_configs\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.EpochRenderConfigWidget.EpochRenderConfigWidget import EpochRenderConfigWidget, EpochRenderConfigsListWidget\n",
    "\n",
    "## Build right-sidebar epoch interval configs widget:\n",
    "spike_raster_window.build_epoch_intervals_visual_configs_widget()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" `Plotted Rects` -> `configs widget`\"\"\" \n",
    "active_2d_plot.build_or_update_epoch_render_configs_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25608e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update plots from configs:\n",
    "#     configs widget -> `Plotted Rects` \n",
    "active_2d_plot.update_epochs_from_configs_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd250fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_epochs_display_list_widget = active_2d_plot.ui['epochs_render_configs_widget']\n",
    "_out_configs = deepcopy(an_epochs_display_list_widget.configs_from_states())\n",
    "_out_configs\n",
    "\n",
    "# {'diba_evt_file': EpochDisplayConfig(brush_color='#008000', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='diba_evt_file', pen_color='#008000', pen_opacity=0.6078431372549019, y_location=-52.0),\n",
    "#  'initial_loaded': EpochDisplayConfig(brush_color='#ffffff', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='initial_loaded', pen_color='#ffffff', pen_opacity=0.6078431372549019, y_location=-42.0),\n",
    "#  'PBEs': EpochDisplayConfig(brush_color='#aa55ff', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='PBEs', pen_color='#aaaaff', pen_opacity=0.6078431372549019, y_location=-32.0),\n",
    "#  'Ripples': EpochDisplayConfig(brush_color='#0000ff', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='Ripples', pen_color='#0000ff', pen_opacity=0.6078431372549019, y_location=-22.0),\n",
    "#  'Laps': EpochDisplayConfig(brush_color='#ff0000', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='Laps', pen_color='#ff0000', pen_opacity=0.6078431372549019, y_location=-12.0),\n",
    "#  'normal_computed': EpochDisplayConfig(brush_color='#800080', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='normal_computed', pen_color='#800080', pen_opacity=0.6078431372549019, y_location=-62.0),\n",
    "#  'diba_quiescent_method_replay_epochs': EpochDisplayConfig(brush_color='#ffa500', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='diba_quiescent_method_replay_epochs', pen_color='#ffa500', pen_opacity=0.6078431372549019, y_location=-72.0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86465b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_dict = {k:v.to_dict() for k, v in _out_configs.items()}\n",
    "update_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e187827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _on_update_rendered_intervals(active_2d_plot):\n",
    "    print(f'_on_update_rendered_intervals(...)')\n",
    "    _legends_dict = active_2d_plot.build_or_update_all_epoch_interval_rect_legends()\n",
    "    epoch_display_configs = active_2d_plot.extract_interval_display_config_lists()\n",
    "    an_epochs_display_list_widget = active_2d_plot.ui.get('epochs_render_configs_widget', None)\n",
    "    if an_epochs_display_list_widget is None:\n",
    "        # create a new one:    \n",
    "        an_epochs_display_list_widget:EpochRenderConfigsListWidget = EpochRenderConfigsListWidget(epoch_display_configs, parent=a_layout_widget)\n",
    "        active_2d_plot.ui.epochs_render_configs_widget = an_epochs_display_list_widget\n",
    "    else:\n",
    "        an_epochs_display_list_widget.update_from_configs(configs=epoch_display_configs)\n",
    "\n",
    "_a_connection = active_2d_plot.sigRenderedIntervalsListChanged.connect(_on_update_rendered_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3096fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import EpochRenderingMixin\n",
    "\n",
    "@function_attributes(short_name=None, tags=['epoch_intervals', 'layout', 'update', 'IMPORTANT'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2024-07-03 05:21', related_items=[])\n",
    "def rebuild_epoch_interval_layouts_given_normalized_heights(active_2d_plot, desired_epoch_render_stack_height:float=70.0):\n",
    "    \"\"\" Re-builds the stacked epoch layout to prevent them from overlapping and to normalize their height\n",
    "    \n",
    "    desired_epoch_render_stack_height: total height for all of the epochs\n",
    "    \n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import EpochRenderingMixin\n",
    "    active_epochs_formatting_dict = active_2d_plot.extract_interval_display_config_lists() ## gets existing formatting dict\n",
    "\n",
    "    # extracts only the height, considers only the first config if the entry is a list:\n",
    "    # original_epoch_display_config_heights = {k:v[0].to_dict()['height'] for k, v in active_epochs_formatting_dict.items()} # {'Replays': 1.9, 'Laps': 0.9, 'diba_evt_file': 10.0, 'initial_loaded': 10.0, 'diba_quiescent_method_replay_epochs': 10.0, 'Ripples': 0.9, 'normal_computed': 10.0}\n",
    "    # original_epoch_display_config_heights ## original heights\n",
    "    required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout((len(active_epochs_formatting_dict) * [1.0]), epoch_render_stack_height=desired_epoch_render_stack_height, interval_stack_location='below') # ratio of heights to each interval\n",
    "    stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(active_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "    # stacked_epoch_layout_dict # {'LapsAll': {'y_location': -3.6363636363636367, 'height': 3.6363636363636367}, 'LapsTrain': {'y_location': -21.818181818181817, 'height': 18.18181818181818}, 'LapsTest': {'y_location': -40.0, 'height': 18.18181818181818}}\n",
    "    # stacked_epoch_layout_dict\n",
    "\n",
    "    # replaces 'y_location', 'position' for each dict:\n",
    "    update_dict = {k:(v[0].to_dict()|stacked_epoch_layout_dict[k]) for k, v in active_epochs_formatting_dict.items()} # builds a proper update dict from the `active_epochs_formatting_dict` and the new position and height adjustments\n",
    "    # update_dict\n",
    "    active_2d_plot.update_rendered_intervals_visualization_properties(update_dict=update_dict)\n",
    "\n",
    "rebuild_epoch_interval_layouts_given_normalized_heights(active_2d_plot, desired_epoch_render_stack_height=60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd03f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_display_configs = {k:get_dict_subset(v[0].to_dict(), ['height', 'y_location']) for k, v in active_2d_plot.extract_interval_display_config_lists().items()}\n",
    "# epoch_display_configs\n",
    "\n",
    "## Re-build the stacked epochs to prevent them from overlapping:\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import EpochRenderingMixin\n",
    "\n",
    "\n",
    "active_epochs_formatting_dict = active_2d_plot.extract_interval_display_config_lists()\n",
    "\n",
    "epoch_display_config_heights = {k:v[0].to_dict()['height'] for k, v in active_epochs_formatting_dict.items()} # {'Replays': 1.9, 'Laps': 0.9, 'diba_evt_file': 10.0, 'initial_loaded': 10.0, 'diba_quiescent_method_replay_epochs': 10.0, 'Ripples': 0.9, 'normal_computed': 10.0}\n",
    "epoch_display_config_heights\n",
    "required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout((len(active_epochs_formatting_dict) * [1.0]), epoch_render_stack_height=70.0, interval_stack_location='below') # ratio of heights to each interval\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(active_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "# stacked_epoch_layout_dict # {'LapsAll': {'y_location': -3.6363636363636367, 'height': 3.6363636363636367}, 'LapsTrain': {'y_location': -21.818181818181817, 'height': 18.18181818181818}, 'LapsTest': {'y_location': -40.0, 'height': 18.18181818181818}}\n",
    "# stacked_epoch_layout_dict\n",
    "\n",
    "# replaces 'y_location', 'position' for each dict:\n",
    "update_dict = {k:(v[0].to_dict()|stacked_epoch_layout_dict[k]) for k, v in active_epochs_formatting_dict.items()}\n",
    "update_dict\n",
    "\n",
    "\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(update_dict=update_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c93e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract/Save all active epochs:\n",
    "active_epochs_formatting_dict: Dict[str, List[EpochDisplayConfig]] = deepcopy(active_2d_plot.extract_interval_display_config_lists())\n",
    "active_epochs_formatting_dict\n",
    "\n",
    "# an_epochs_display_list_widget.configs_from_states()\n",
    "\n",
    "\n",
    "an_epochs_display_list_widget = active_2d_plot.ui.get('epochs_render_configs_widget', None)\n",
    "if an_epochs_display_list_widget is None:\n",
    "    raise NotImplementedError\n",
    "    # create a new one:    \n",
    "    an_epochs_display_list_widget:EpochRenderConfigsListWidget = EpochRenderConfigsListWidget(active_epochs_formatting_dict, parent=a_layout_widget)\n",
    "    active_2d_plot.ui.epochs_render_configs_widget = an_epochs_display_list_widget\n",
    "else:\n",
    "    an_epochs_display_list_widget.update_from_configs(configs=active_epochs_formatting_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ad3bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epochs_confgs_dict: Dict[str, EpochDisplayConfig] = deepcopy(an_epochs_display_list_widget.configs_from_states())\n",
    "active_epochs_confgs_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f93d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveData('SpikeRaster2D_saved_Epochs.pkl', active_epochs_confgs_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epochs_formatting_dict['Replays'][0].brush_QColor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7318fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Restore/Load all active epochs:\n",
    "# update_dict = {k:(v[0].to_dict()|stacked_epoch_layout_dict[k]) for k, v in active_epochs_formatting_dict.items()}\n",
    "\n",
    "update_dict = {k:v.to_dict() for k, v in active_epochs_confgs_dict.items()} ## from active_epochs_confgs_dict\n",
    "update_dict\n",
    "\n",
    "## Updates intervals themselves\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(update_dict=update_dict)\n",
    "\n",
    "## updates configs:\n",
    "# active_2d_plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673515f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_all_rendered_intervals_dict = active_2d_plot.get_all_rendered_intervals_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1292a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epochs_interval_datasources_dict: Dict[str, IntervalsDatasource] = active_2d_plot.interval_datasources\n",
    "active_epochs_interval_datasources_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb58bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {}\n",
    "rendered_epoch_names = active_2d_plot.interval_datasource_names\n",
    "print(f'rendered_epoch_names: {rendered_epoch_names}')\n",
    "for a_name in rendered_epoch_names:\n",
    "    a_render_container = active_2d_plot.rendered_epochs[a_name]\n",
    "    out_dict[a_name] = a_render_container\n",
    "\n",
    "out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_widget.setVisible(False) ## top plot disappeared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedfcbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_widget.setVisible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Connections\n",
    "active_2d_plot.setVisible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdaaca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.get_all_rendered_intervals_dict()\n",
    "active_2d_plot.interval_datasources\n",
    "# active_2d_plot.interval_rendering_plots\n",
    "active_2d_plot.interval_datasource_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaca430",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.setVisible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c1badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.isVisible()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import ensure_Epoch, Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, inline_mkColor\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.EpochRenderingMixin import EpochRenderingMixin, RenderedEpochsItemsContainer\n",
    "from pyphoplacecellanalysis.General.Model.Datasources.IntervalDatasource import IntervalsDatasource\n",
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "\n",
    "## Add various replay epochs as interval rects:\n",
    "\n",
    "## INPUTS: replay_epoch_variations\n",
    "\n",
    "# replay_epoch_variations\n",
    "\n",
    "\n",
    "## Use the three dataframes as separate Epoch series:\n",
    "custom_replay_dfs_dict = {k:ensure_dataframe(deepcopy(v)) for k, v in replay_epoch_variations.items()}\n",
    "custom_replay_keys = list(custom_replay_dfs_dict.keys()) # \n",
    "print(f'{custom_replay_keys}') # ['initial_loaded', 'normal_computed', 'diba_evt_file', 'diba_quiescent_method_replay_epochs']\n",
    "\n",
    "\n",
    "_color_rotation_order = ['white', 'purple', 'green', 'orange', 'pink', 'red']\n",
    "\n",
    "custom_replay_epochs_formatting_dict = {\n",
    "    'initial_loaded':dict(pen_color=inline_mkColor('white', 0.8), brush_color=inline_mkColor('white', 0.5)),\n",
    "    'normal_computed':dict(pen_color=inline_mkColor('purple', 0.8), brush_color=inline_mkColor('purple', 0.5)),\n",
    "    'diba_evt_file':dict(pen_color=inline_mkColor('green', 0.8), brush_color=inline_mkColor('green', 0.5)),\n",
    "    'diba_quiescent_method_replay_epochs':dict(pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5)),\n",
    "}\n",
    "\n",
    "# required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout((len(custom_replay_dfs_dict) * [1.0]), epoch_render_stack_height=40.0, interval_stack_location='below') # ratio of heights to each interval\n",
    "# stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(custom_replay_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(custom_replay_epochs_formatting_dict.keys()), *EpochRenderingMixin.build_stacked_epoch_layout((len(custom_replay_dfs_dict) * [1.0]), epoch_render_stack_height=40.0, interval_stack_location='below'))} # Build a stacked_epoch_layout_dict to update the display\n",
    "# replaces 'y_location', 'position' for each dict:\n",
    "custom_replay_epochs_formatting_dict = {k:(v|stacked_epoch_layout_dict[k]) for k, v in custom_replay_epochs_formatting_dict.items()}\n",
    "# custom_replay_epochs_formatting_dict\n",
    "\n",
    "# OUTPUTS: train_test_split_laps_dfs_dict, custom_replay_epochs_formatting_dict\n",
    "## INPUTS: train_test_split_laps_dfs_dict\n",
    "custom_replay_dfs_dict = {k:TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(df=v, required_columns_synonym_dict=IntervalsDatasource._time_column_name_synonyms) for k, v in custom_replay_dfs_dict.items()}\n",
    "\n",
    "## Build interval datasources for them:\n",
    "custom_replay_dfs_datasources_dict = {k:General2DRenderTimeEpochs.build_render_time_epochs_datasource(v) for k, v in custom_replay_dfs_dict.items()}\n",
    "## INPUTS: active_2d_plot, train_test_split_laps_epochs_formatting_dict, train_test_split_laps_dfs_datasources_dict\n",
    "assert len(custom_replay_epochs_formatting_dict) == len(custom_replay_dfs_datasources_dict)\n",
    "for k, an_interval_ds in custom_replay_dfs_datasources_dict.items():\n",
    "    an_interval_ds.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, **(custom_replay_epochs_formatting_dict[k] | kwargs)))\n",
    "\n",
    "\n",
    "## Full output: train_test_split_laps_dfs_datasources_dict\n",
    "\n",
    "\n",
    "# actually add the epochs:\n",
    "for k, an_interval_ds in custom_replay_dfs_datasources_dict.items():\n",
    "    active_2d_plot.add_rendered_intervals(an_interval_ds, name=f'{k}', debug_print=False) # adds the interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34342d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params.enable_time_interval_legend_in_right_margin = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51663689",
   "metadata": {},
   "outputs": [],
   "source": [
    "## They can later be updated via:\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(custom_replay_epochs_formatting_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d073b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_replay_epochs.to_file('new_replays.csv')\n",
    "new_replay_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d680b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_order_results.minimum_inclusion_fr_Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc7f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.long_LR_decoder.neuron_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e8b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a672c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg # Used to get the app for TopLevelWindowHelper.top_level_windows\n",
    "## For searching with `TopLevelWindowHelper.all_widgets(...)`:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike3DRaster import Spike3DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "found_spike_raster_windows = TopLevelWindowHelper.all_widgets(pg.mkQApp(), searchType=Spike3DRasterWindowWidget)\n",
    "\n",
    "if len(found_spike_raster_windows) < 1:\n",
    "    # no existing spike_raster_windows. Make a new one\n",
    "    print(f'no existing SpikeRasterWindow. Creating a new one.')\n",
    "    # Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "    active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\n",
    "\n",
    "else:\n",
    "    print(f'found {len(found_spike_raster_windows)} existing Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...). Will use the most recent.')\n",
    "    # assert len(found_spike_raster_windows) == 1, f\"found {len(found_spike_raster_windows)} Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...) but require exactly one.\"\n",
    "    # Get the most recent existing one and reuse that:\n",
    "    spike_raster_window = found_spike_raster_windows[0]\n",
    "\n",
    "\n",
    "# Extras:\n",
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "active_3d_plot = spike_raster_window.spike_raster_plt_3d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "main_graphics_layout_widget = active_2d_plot.ui.main_graphics_layout_widget # GraphicsLayoutWidget\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "background_static_scroll_plot_widget = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_items = widget.get_display_function_items()\n",
    "_display_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_fcn_name = '_display_batch_pho_jonathan_replay_firing_rate_comparison'\n",
    "a_fn_handle = widget._perform_get_display_function_code(a_fcn_name=a_fcn_name)\n",
    "assert a_fn_handle is not None\n",
    "# args = []\n",
    "# kwargs = {}\n",
    "a_disp_fn_item = widget.get_display_function_item(a_fn_name=a_fcn_name)\n",
    "assert a_disp_fn_item is not None, f\"a_disp_fn_item is None! for a_fn_name='{a_fcn_name}'\"\n",
    "\n",
    "a_disp_fn_item.is_global\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c91ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display(display_function=a_fcn_name, active_session_configuration_context=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_display_config_manager = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac563836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import LongShortDisplayConfigManager, long_short_display_config_manager\n",
    "from pyphocorehelpers.gui.Qt.color_helpers import ColorFormatConverter, debug_print_color, build_adjusted_color\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import render_colors\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import apply_LR_to_RL_adjustment\n",
    "\n",
    "long_epoch_config = long_short_display_config_manager.long_epoch_config.as_pyqtgraph_kwargs()\n",
    "short_epoch_config = long_short_display_config_manager.short_epoch_config.as_pyqtgraph_kwargs()\n",
    "\n",
    "color_dict = {'long_LR': long_epoch_config['brush'].color(), 'long_RL': apply_LR_to_RL_adjustment(long_epoch_config['brush'].color()),\n",
    "  'short_LR': short_epoch_config['brush'].color(), 'short_RL': apply_LR_to_RL_adjustment(short_epoch_config['brush'].color())}\n",
    "\n",
    "render_colors(color_dict)\n",
    "\n",
    "\n",
    "ColorFormatConverter.qColor_to_hexstring(curr_color) # '#0099ff42'\n",
    "\n",
    "\n",
    "# long_epoch_config['brush'].color()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6abda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the list of colors you want to display\n",
    "# color_list = ['red', 'blue', 'green', '#FFA500', '#800080']\n",
    "# color_list = _plot_backup_colors.neuron_colors_hex\n",
    "\n",
    "# RL_adjustment_kwargs = dict(hue_shift=0.0, saturation_scale=0.35, value_scale=1.0)\n",
    "RL_adjustment_kwargs = dict(hue_shift=0.18, saturation_scale=1.0, value_scale=1.0)\n",
    "color_dict = {'long_LR': long_epoch_config['brush'].color(), 'long_RL': build_adjusted_color(long_epoch_config['brush'].color(), **RL_adjustment_kwargs),\n",
    "  'short_LR': short_epoch_config['brush'].color(), 'short_RL': build_adjusted_color(short_epoch_config['brush'].color(), **RL_adjustment_kwargs)}\n",
    "\n",
    "\n",
    "\n",
    "# color_dict = {'long_LR': long_epoch_config['brush'].color(), 'long_RL': apply_LR_to_RL_adjustment(long_epoch_config['brush'].color()),\n",
    "#   'short_LR': short_epoch_config['brush'].color(), 'short_RL': apply_LR_to_RL_adjustment(short_epoch_config['brush'].color())}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "color_list = [curr_color, curr_color_copy]\n",
    "\n",
    "render_colors(color_list)\n",
    "render_colors(color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrackTemplates.get_decoder_names()\n",
    "\n",
    "base_color_names_dict = dict(zip(TrackTemplates.get_decoder_names(), ['red', 'purple', 'green', 'orange'])) # {'long_LR': 'red', 'long_RL': 'purple', 'short_LR': 'green', 'short_RL': 'orange'}\n",
    "\n",
    "additional_cmaps = {name: pg.ColorMap(np.array([0.0, 1.0]), np.array([pg.mkColor(color).getRgb()[:3] + (0,), pg.mkColor(color).getRgb()[:3] + (255,)], dtype=np.ubyte)) for name, color in base_color_names_dict.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c667149",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = pg.ColorMap(np.array([0.0, 1.0]), np.array([[255, 0, 0, 0], [255, 0, 0, 255]], dtype=np.ubyte))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d735d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, n_max_page_rows=10, disable_top_row=True, write_png=False, write_vector_format=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out.figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_spike_rasters_pyqtplot_3D_with_2D_controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c70b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(_display_items.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29925698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import FigureCollector\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_remapping_cells\n",
    "\n",
    "collector: FigureCollector = fig_remapping_cells(curr_active_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not isinstance(curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis, JonathanFiringRateAnalysisResult):\n",
    "    jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "else:\n",
    "    jonathan_firing_rate_analysis_result = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "\n",
    "neuron_replay_stats_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df.copy()\n",
    "neuron_replay_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_sorted_neuron_stats_df = neuron_replay_stats_df.sort_values(by=sortby, ascending=[True, True, True], inplace=False).copy() # also did test_df = neuron_replay_stats_df.sort_values(by=['long_pf_peak_x'], inplace=False, ascending=True).copy()\n",
    "_sorted_neuron_stats_df = _sorted_neuron_stats_df[np.isin(_sorted_neuron_stats_df.index, curr_any_context_neurons)] # clip to only those neurons included in `curr_any_context_neurons`\n",
    "_sorted_aclus = _sorted_neuron_stats_df.index.to_numpy()\n",
    "_sorted_neuron_IDXs = _sorted_neuron_stats_df.neuron_IDX.to_numpy()\n",
    "if debug_print:\n",
    "    print(f'_sorted_aclus: {_sorted_aclus}')\n",
    "    print(f'_sorted_neuron_IDXs: {_sorted_neuron_IDXs}')\n",
    "\n",
    "## Use this sort for the 'curr_any_context_neurons' sort order:\n",
    "new_all_aclus_sort_indicies, desired_sort_arr = find_desired_sort_indicies(curr_any_context_neurons, _sorted_aclus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2fa1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _directional_laps_overview = curr_active_pipeline.plot._display_directional_laps_overview(curr_active_pipeline.computation_results, a)\n",
    "# _directional_laps_overview = curr_active_pipeline.display('_display_directional_laps_overview')\n",
    "# _directional_laps_overview = curr_active_pipeline.display('_display_grid_bin_bounds_validation')\n",
    "_directional_laps_overview = curr_active_pipeline.display('_display_long_short_pf1D_comparison')\n",
    "\n",
    "_directional_laps_overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9992e42",
   "metadata": {},
   "source": [
    "### 🟢🔝🖼️🎨 2024-06-06 - Works to render the contour curve at a fixed promenence (the shape of the placefield's cap/crest) for each placefield:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff6d67",
   "metadata": {
    "tags": [
     "3d"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho3D.PyVista.peak_prominences import render_all_neuron_peak_prominence_2d_results_on_pyvista_plotter\n",
    "\n",
    "display_output = {}\n",
    "active_config_name = long_LR_name\n",
    "print(f'active_config_name: {active_config_name}')\n",
    "active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "pActiveTuningCurvesPlotter = None\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "active_config_modifiying_kwargs = {\n",
    "    'plotting_config': {'should_use_linear_track_geometry': True, \n",
    "                        't_start': t_start, 't_delta': t_delta, 't_end': t_end,\n",
    "                        }\n",
    "}\n",
    "display_output = display_output | curr_active_pipeline.display('_display_3d_interactive_tuning_curves_plotter', active_config_name, extant_plotter=display_output.get('pActiveTuningCurvesPlotter', None),\n",
    "                                                panel_controls_mode='Qt', should_nan_non_visited_elements=False, zScalingFactor=2000.0, active_config_modifiying_kwargs=active_config_modifiying_kwargs,\n",
    "                                                params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                            ) # Works now!\n",
    "ipcDataExplorer = display_output['ipcDataExplorer']\n",
    "display_output['pActiveTuningCurvesPlotter'] = display_output.pop('plotter') # rename the key from the generic \"plotter\" to \"pActiveSpikesBehaviorPlotter\" to avoid collisions with others\n",
    "pActiveTuningCurvesPlotter = display_output['pActiveTuningCurvesPlotter']\n",
    "root_dockAreaWindow, placefieldControlsContainerWidget, pf_widgets = display_output['pane'] # for Qt mode\n",
    "\n",
    "active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "render_all_neuron_peak_prominence_2d_results_on_pyvista_plotter(ipcDataExplorer, active_peak_prominence_2d_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aecde7d",
   "metadata": {},
   "source": [
    "### 2024-06-06 - Works to disable/hide all elements except the contour curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ff05b",
   "metadata": {
    "tags": [
     "3d"
    ]
   },
   "outputs": [],
   "source": [
    "all_placefield_surfaces_are_hidden: bool = True\n",
    "all_placefield_points_are_hidden: bool = True\n",
    "\n",
    "disabled_peak_subactors_names_list = ['boxes', 'text', 'peak_points']\n",
    "# disabled_peak_subactors_names_list = ['text', 'peak_points']\n",
    "for active_neuron_id, a_plot_dict in ipcDataExplorer.plots['tuningCurvePlotActors'].items():\n",
    "    if a_plot_dict is not None:\n",
    "        # a_plot_dict.peaks\n",
    "        print(f'active_neuron_id: {active_neuron_id}, a_plot_dict.keys(): {list(a_plot_dict.keys())}')\n",
    "        # ['main', 'points', 'peaks']\n",
    "        if a_plot_dict.main is not None:\n",
    "            if all_placefield_surfaces_are_hidden:\n",
    "                a_plot_dict.main.SetVisibility(False)\n",
    "                # pass\n",
    "            \n",
    "        if a_plot_dict.points is not None:\n",
    "            if all_placefield_points_are_hidden:\n",
    "                a_plot_dict.points.SetVisibility(False)\n",
    "                # pass\n",
    "\n",
    "        if a_plot_dict.peaks is not None:\n",
    "            print(f'active_neuron_id: {active_neuron_id}, a_plot_dict.peaks: {list(a_plot_dict.peaks.keys())}')\n",
    "            for a_subactor_name in disabled_peak_subactors_names_list:\n",
    "                a_subactor = a_plot_dict.peaks.get(a_subactor_name, None)\n",
    "                if a_subactor is not None:\n",
    "                    a_subactor.SetVisibility(False)\n",
    "            # if all_placefield_surfaces_are_hidden:\n",
    "            #     a_plot_dict.main.SetVisibility(False) # Change the visibility to match the current tuning_curve_visibility_state\n",
    "\n",
    "# Once done, render\n",
    "ipcDataExplorer.p.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c88dd",
   "metadata": {},
   "source": [
    "### 2024-06-05 - Offset the long and short track to match the `_plot_track_remapping_diagram` 2D remapping figure\n",
    "\n",
    "[/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Pho2D/track_shape_drawing.py:1236](vscode://file/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Pho2D/track_shape_drawing.py:1236)\n",
    "```python\n",
    "# From `Pho2D.track_shape_drawing.a_dir_decoder_aclu_MAX_peak_maps_df`\n",
    "_plot_track_remapping_diagram\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391be83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "track_half_offset: float = 25.0\n",
    "\n",
    "# Long:\n",
    "actor = ipcDataExplorer.long_maze_bg\n",
    "# Get the current position\n",
    "current_position = actor.GetPosition()\n",
    "# Translate by 5.0 units in the y-direction\n",
    "# new_position = (current_position[0], current_position[1] + 5.0, current_position[2])\n",
    "new_position = (current_position[0], track_half_offset, current_position[2])\n",
    "# Set the new position\n",
    "actor.SetPosition(new_position)\n",
    "\n",
    "## Short\n",
    "actor = ipcDataExplorer.short_maze_bg\n",
    "# Get the current position\n",
    "current_position = actor.GetPosition()\n",
    "# Translate by 5.0 units in the y-direction\n",
    "# new_position = (current_position[0], current_position[1] + 5.0, current_position[2])\n",
    "new_position = (current_position[0], -track_half_offset, current_position[2])\n",
    "# Set the new position\n",
    "actor.SetPosition(new_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc3078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out_graphics_dict = curr_active_pipeline.display('_display_two_step_decoder_prediction_error_2D', 'maze_any') # 'maze_any'\n",
    "\n",
    "update_fn = _out_graphics_dict.plot_data['draw_update_fn']\n",
    "num_frames = _out_graphics_dict.plot_data['num_frames']\n",
    "\n",
    "print(f'num_frames: {num_frames}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b374e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "all_save_paths = {}\n",
    "\n",
    "ani = animation.FuncAnimation(_out_graphics_dict.figures[0], update_fn, frames=num_frames, blit=False, repeat=False, interval=20, save_count=50)\n",
    "\n",
    "# ani.to_html5_video()\n",
    "\n",
    "# # To save the animation using Pillow as a gif\n",
    "# _temp_gif_save_path = Path('scatter.gif').resolve()\n",
    "# writer = animation.PillowWriter(fps=15, metadata=dict(artist='Pho Hale'), bitrate=1800)\n",
    "# ani.save(_temp_gif_save_path, writer=writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f69ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.pause()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.show()\n",
    "\n",
    "# # Save the animation to a BytesIO buffer\n",
    "# buf = io.BytesIO()\n",
    "# ani.save(buf, codec='gif', writer='imagemagick', fps=10)\n",
    "# buf.seek(0)\n",
    "\n",
    "# # Display the GIF\n",
    "# display(Image(data=buf.getvalue(), format='gif'))\n",
    "# Display the GIF\n",
    "# assert _temp_gif_save_path.exists()\n",
    "# Image(_temp_gif_save_path)\n",
    "\n",
    "\n",
    "# for i in np.arange(num_frames):\n",
    "#     update_fn(i) ## Adjust the slider, using its callbacks as well to update the displayed epoch.\n",
    "    \n",
    "#     # _out_rank_order_event_raster_debugger.on_update_epoch_IDX(an_epoch_idx=i)\n",
    "#     active_epoch_label = self.active_epoch_label\n",
    "\n",
    "#     save_paths = []\n",
    "\n",
    "#     for a_decoder, a_plot in self.root_plots_dict.items():\n",
    "#         curr_filename_prefix = f'Epoch{active_epoch_label}_{a_decoder}'\n",
    "#         # a_plot.setYRange(-0.5, float(self.max_n_neurons))\n",
    "#         out_path = export_path.joinpath(f'{curr_filename_prefix}_plot.png').resolve()\n",
    "#         export_pyqtgraph_plot(a_plot, savepath=out_path, background=pg.mkColor(0, 0, 0, 0))\n",
    "#         save_paths.append(out_path)\n",
    "\n",
    "#     all_save_paths[active_epoch_label] = save_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77194b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bbd956",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_display_long_short_laps', '_display_long_short_pf1D_comparison', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b267e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_display_two_step_decoder_prediction_error_2D'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8adcd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import Image, display\n",
    "import io\n",
    "from pyphocorehelpers.plotting.media_output_helpers import fig_to_clipboard\n",
    "\n",
    "\n",
    "# Generate the frames for the animation\n",
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "line, = ax.plot(x, np.sin(x))\n",
    "\n",
    "def update(frame):\n",
    "    line.set_ydata(np.sin(x + frame / 10.0))\n",
    "    return line,\n",
    "\n",
    "frames = len(x) - 1\n",
    "ani = animation.FuncAnimation(fig, update, frames=frames, blit=True, repeat=True, interval=50)\n",
    "\n",
    "# To save the animation using Pillow as a gif\n",
    "_temp_gif_save_path = Path('scatter.gif').resolve()\n",
    "writer = animation.PillowWriter(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "ani.save(_temp_gif_save_path, writer=writer)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# # Save the animation to a BytesIO buffer\n",
    "# buf = io.BytesIO()\n",
    "# ani.save(buf, codec='gif', writer='imagemagick', fps=10)\n",
    "# buf.seek(0)\n",
    "\n",
    "# # Display the GIF\n",
    "# display(Image(data=buf.getvalue(), format='gif'))\n",
    "# Display the GIF\n",
    "assert _temp_gif_save_path.exists()\n",
    "Image(_temp_gif_save_path)\n",
    "\n",
    "\n",
    "# fig_to_clipboard(fig, format='gif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7be129",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_long_short_laps')\n",
    "graphics_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedac3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_grid_bin_bounds_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68008d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_long_short_laps()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685113bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\n",
    "\n",
    "_out_graphics_dict = curr_active_pipeline.display('_display_spike_rasters_pyqtplot_2D', 'maze_any') # 'maze_any'\n",
    "assert isinstance(_out_graphics_dict, dict)\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = _out_graphics_dict['spike_raster_plt_2d'], _out_graphics_dict['spike_raster_plt_3d'], _out_graphics_dict['spike_raster_window']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.SessionEpochs']\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5650ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(add_renderables_menu.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a83aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('add_renderables_menu', add_renderables_menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d_interactive_tuning_curves_plotter\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "active_config_modifiying_kwargs = {\n",
    "    'plotting_config': {'should_use_linear_track_geometry': True, \n",
    "                        't_start': t_start, 't_delta': t_delta, 't_end': t_end,\n",
    "                        }\n",
    "}\n",
    "_out_graphics_dict = curr_active_pipeline.display('_display_3d_interactive_tuning_curves_plotter', active_session_configuration_context=global_epoch_context,\n",
    "                                            active_config_modifiying_kwargs=active_config_modifiying_kwargs,\n",
    "                                            params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                           )\n",
    "ipcDataExplorer = _out_graphics_dict['ipcDataExplorer'] # InteractivePlaceCellTuningCurvesDataExplorer \n",
    "p = _out_graphics_dict['plotter']\n",
    "pane = _out_graphics_dict['pane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=global_epoch_context) # , computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}]\n",
    "ipspikesDataExplorer = _out['ipspikesDataExplorer']\n",
    "p = _out['plotter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "iplapsDataExplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "\n",
    "an_image_file_path = Path('an_image.png').resolve()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_image_plotter', active_session_configuration_context=global_epoch_context, image_file=an_image_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ce93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_config in curr_active_pipeline.active_configs.items():\n",
    "    print(f'a_config.plotting_config.should_use_linear_track_geometry: {a_config.plotting_config.should_use_linear_track_geometry}')\n",
    "    a_config.plotting_config.should_use_linear_track_geometry = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d560b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "\n",
    "_out = TemplateDebugger.init_templates_debugger(track_templates) # , included_any_context_neuron_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1323cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "\n",
    "\n",
    "_out = batch_perform_all_plots(curr_active_pipeline=curr_active_pipeline, enable_neptune=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 2D matrix\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import pv\n",
    "\n",
    "matrix = np.random.rand(10, 10)\n",
    "\n",
    "# Coordinates\n",
    "x, y = np.meshgrid(np.arange(matrix.shape[1]), np.arange(matrix.shape[0]))\n",
    "z = matrix.flatten()\n",
    "\n",
    "# Colors based on recency of updates (for example purposes, random values)\n",
    "colors = np.random.rand(matrix.size)\n",
    "\n",
    "# Create the plotter\n",
    "plotter = pv.Plotter()\n",
    "\n",
    "# Add points (dots)\n",
    "points = np.column_stack((x.flatten(), y.flatten(), z))\n",
    "point_cloud = pv.PolyData(points)\n",
    "point_cloud['colors'] = colors\n",
    "plotter.add_mesh(point_cloud, render_points_as_spheres=True, point_size=10, scalars='colors', cmap='viridis')\n",
    "\n",
    "# Add stems\n",
    "for i in range(len(z)):\n",
    "    line = pv.Line([x.flatten()[i], y.flatten()[i], 0], [x.flatten()[i], y.flatten()[i], z[i]])\n",
    "    plotter.add_mesh(line, color='black')\n",
    "\n",
    "# Show plot\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23611eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot.display_function_items\n",
    "\n",
    "# '_display_directional_template_debugger'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "directional_laps_overview = curr_active_pipeline.display(display_function='_display_directional_laps_overview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ee6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pic_placefields = curr_active_pipeline.display('_display_1d_placefields', long_LR_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pic_placefields_short_LR = curr_active_pipeline.display('_display_1d_placefields', short_LR_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c334080",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f93040",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd15f5",
   "metadata": {},
   "source": [
    "# 🎨 2024-04-23 - 3D Posterior Plot\n",
    "<!-- t_delta -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba7ac95",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer\n",
    "\n",
    "curr_active_pipeline.prepare_for_display()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_interactive_custom_data_explorer', active_session_configuration_context=global_epoch_context,\n",
    "                                    params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                    )\n",
    "iplapsDataExplorer: InteractiveCustomDataExplorer = _out['iplapsDataExplorer']\n",
    "pActiveInteractiveLapsPlotter = _out['plotter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "pActiveInteractiveLapsPlotter[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ad7178",
   "metadata": {},
   "outputs": [],
   "source": [
    "pActiveInteractiveLapsPlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "iplapsDataExplorer.active_config.plotting_config.subplots_shape # '1|5'\n",
    "iplapsDataExplorer.active_config.plotting_config.plotter_type # 'BackgroundPlotter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots_shape_str: str = '1|5'\n",
    "subplots_shape_arr_strs = subplots_shape_str.split('|')\n",
    "\n",
    "subplots_shape = [int(k) for k in subplots_shape_arr_strs]\n",
    "subplots_shape\n",
    "\n",
    "total_n_plots: int = np.prod(subplots_shape)\n",
    "if total_n_plots > 1:\n",
    "    iplapsDataExplorer.active_config.plotting_config.plotter_type = 'BackgroundPlotter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iplapsDataExplorer.p.\n",
    "\n",
    "p = iplapsDataExplorer.p[0,0]\n",
    "p\n",
    "# p = self.p[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_global = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=global_epoch_context) # , config_override_kwargs={'plotting_config': {'should_use_linear_track_geometry': True}}\n",
    "# ipspikesDataExplorer = _out_global['ipspikesDataExplorer']\n",
    "# p = _out_global['plotter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: active_config\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "active_config_modifiying_kwargs = {\n",
    "    'plotting_config': {'should_use_linear_track_geometry': True, \n",
    "                        't_start': t_start, 't_delta': t_delta, 't_end': t_end,\n",
    "                        }\n",
    "}\n",
    "_out_global = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=global_epoch_context,\n",
    "                                            active_config_modifiying_kwargs=active_config_modifiying_kwargs,\n",
    "                                            params_kwargs=dict(enable_historical_spikes=False, enable_recent_spikes=False, should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                           )\n",
    "ipspikesDataExplorer = _out_global['ipspikesDataExplorer']\n",
    "p = _out_global['plotter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k, v in active_config_modifiying_kwargs.items():\n",
    "    curr_subdict = active_config.get(k, {})\n",
    "    for sub_k, sub_v in v.items():\n",
    "        try:\n",
    "            curr_subdict[sub_k] = sub_v # apply the update\n",
    "        except TypeError as err:\n",
    "            # TypeError: 'PlottingConfig' object does not support item assignment\n",
    "            setattr(curr_subdict, sub_k, sub_v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27140db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_config.plotting_config.should_use_linear_track_geometry\n",
    "active_config.plotting_config.t_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.time_animations import TrackConfigurationTimeAnimationRoutine\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "custom_track_animatior: TrackConfigurationTimeAnimationRoutine = TrackConfigurationTimeAnimationRoutine(t_start=t_start, t_delta=t_delta, t_end=t_end, \n",
    "        long_maze_bg=ipspikesDataExplorer.plots['long_maze_bg'], short_maze_bg=ipspikesDataExplorer.plots['short_maze_bg'], debug_print=True,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveSliderWrapper import InteractiveSliderWrapper\n",
    "\n",
    "# interactive_plotter = ipspikesDataExplorer.ui.interactive_plotter # PhoInteractivePlotter\n",
    "\n",
    "active_timestamp_slider_wrapper: InteractiveSliderWrapper = ipspikesDataExplorer.ui.interactive_plotter.interface_properties.active_timestamp_slider_wrapper # InteractiveSliderWrapper \n",
    "active_timestamp_slider_wrapper.curr_value # 17659.517659\n",
    "active_timestamp_slider_wrapper.curr_index # 17659\n",
    "\n",
    "\n",
    "curr_i: int = int(active_timestamp_slider_wrapper.curr_index)\n",
    "active_window_sample_indicies = np.squeeze(ipspikesDataExplorer.params.pre_computed_window_sample_indicies[curr_i,:]) # Get the current precomputed indicies for this curr_i\n",
    "\n",
    "## Spike Plotting:\n",
    "# Get the times that fall within the current plot window:\n",
    "curr_time_fixedSegments = ipspikesDataExplorer.t[active_window_sample_indicies] # New Way\n",
    "t_start = curr_time_fixedSegments[0]\n",
    "t_stop = curr_time_fixedSegments[-1]\n",
    "\n",
    "# \n",
    "t_start, t_stop\n",
    "# custom_track_animatior.on_update_current_window(t_start=t_start, t_stop=t_stop)\n",
    "# curr_index\n",
    "active_timestamp_slider_wrapper.slider_obj.SetEnabled(False) # hide the typical timestamp slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_one_step_decoder = deepcopy(global_results.pf2D_Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _update_nearest_decoded_most_likely_position_callback, _conn = add_nearest_decoded_position_indicator_circle(self, active_one_step_decoder, _debug_print = False)\n",
    "\n",
    "_update_nearest_decoded_most_likely_position_callback, _conn = ipspikesDataExplorer.add_nearest_decoded_position_indicator_circle(active_one_step_decoder=active_one_step_decoder, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryPyVistaPlotter\n",
    "\n",
    "## plots a decoder posterior viewer with two sliders: one for epoch_idx and another for epoch_time_bin_idx within that epoch\n",
    "active_one_step_decoder = deepcopy(global_results.pf2D_Decoder) # just used for position binning info\n",
    "# a_result: DecodedFilterEpochsResult = deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'])\n",
    "a_result: DecodedFilterEpochsResult = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'])\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = ipspikesDataExplorer.add_decoded_posterior_bars(a_result=a_result,\n",
    "                                                                                                                         xbin=active_one_step_decoder.xbin, xbin_centers=active_one_step_decoder.xbin_centers, ybin=active_one_step_decoder.ybin, ybin_centers=active_one_step_decoder.ybin_centers,\n",
    "                                                                                                                         enable_plot_all_time_bins_in_epoch_mode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.params.curr_view_window_length_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79651414",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.clear_all_added_decoded_posterior_plots()\n",
    "ipspikesDataExplorer.p.clear_slider_widgets() # does not actually clear the added sliders\n",
    "ipspikesDataExplorer.on_slider_update_mesh(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ipspikesDataExplorer.params.curr_view_window_length_samples # 299\n",
    "ipspikesDataExplorer.params.curr_view_window_length_samples = 60.0 * 5.0 * ipspikesDataExplorer.active_session.position.sampling_rate # 5 minutes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_interactions.widgets import RangeSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acebce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipspikesDataExplorer.add_grid_bin_bounds_box(\n",
    "ipspikesDataExplorer.on_slider_update_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f59bafd",
   "metadata": {},
   "source": [
    "# 🖼️🎨 2024-02-28 - WE gotta see the replays on the 3D track. Or the 2D track.\n",
    "2024-04-28 - This is working in both 3D and 2D!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ad549",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: directional_laps_results, global_replays, decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "# global_pf1D\n",
    "# long_replays\n",
    "# direction_max_indices = ripple_all_epoch_bins_marginals_df[['P_Long', 'P_Short']].values.argmax(axis=1)\n",
    "# track_identity_max_indices = ripple_all_epoch_bins_marginals_df[['P_Long', 'P_Short']].values.argmax(axis=1)\n",
    "\n",
    "## How do I get the replays?\n",
    "# long_replay_df: pd.DataFrame = long_replays.to_dataframe() ## These work.\n",
    "# global_replay_df: pd.DataFrame = global_replays.to_dataframe() ## These work.\n",
    "# global_replay_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1D version:\n",
    "## INPUTS: directional_laps_results, decoder_ripple_filter_epochs_decoder_result_dict\n",
    "xbin = deepcopy(directional_laps_results.get_decoders()[0].xbin)\n",
    "xbin_centers = deepcopy(directional_laps_results.get_decoders()[0].xbin_centers)\n",
    "ybin_centers = None\n",
    "ybin = None\n",
    "\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "# a_decoded_filter_epochs_decoder_result_dict\n",
    "\n",
    "## 1D:\n",
    "a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long_LR'] # 1D\n",
    "\n",
    "## OUTPUTS: a_decoded_filter_epochs_decoder_result_dict, xbin_centers, ybin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31cdc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2D version:\n",
    "from neuropy.analyses.placefields import PfND\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BayesianPlacemapPositionDecoder\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_lap_and_ripple_epochs_decoding_for_decoder\n",
    "\n",
    "## INPUTS: long_results, short_results\n",
    "# long_one_step_decoder_2D\n",
    "\n",
    "long_one_step_decoder_2D, short_one_step_decoder_2D  = [results_data.get('pf2D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "one_step_decoder_dict_2D: Dict[str, BayesianPlacemapPositionDecoder] = dict(zip(('long', 'short'), (long_one_step_decoder_2D, short_one_step_decoder_2D)))\n",
    "long_pf2D = long_results.pf2D\n",
    "# short_pf2D = short_results.pf2D\n",
    "\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "xbin_centers = deepcopy(long_pf2D.xbin_centers)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "ybin_centers = deepcopy(long_pf2D.ybin_centers)\n",
    "\n",
    "## OUTPUTS: one_step_decoder_dict_2D, xbin_centers, ybin_centers\n",
    "\n",
    "## INPUTS: one_step_decoder_dict_2D\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "pos_bin_size: Tuple[float, float] = list(one_step_decoder_dict_2D.values())[0].pos_bin_size\n",
    "\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "\n",
    "## Decode epochs for the two decoders ('long', 'short'):\n",
    "LS_decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {}\n",
    "LS_decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {}\n",
    "\n",
    "for a_name, a_decoder in one_step_decoder_dict_2D.items():\n",
    "    LS_decoder_laps_filter_epochs_decoder_result_dict[a_name], LS_decoder_ripple_filter_epochs_decoder_result_dict[a_name] = _compute_lap_and_ripple_epochs_decoding_for_decoder(a_decoder, curr_active_pipeline, desired_laps_decoding_time_bin_size=laps_decoding_time_bin_size, desired_ripple_decoding_time_bin_size=ripple_decoding_time_bin_size)\n",
    "\n",
    "# LS_decoder_ripple_filter_epochs_decoder_result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e591738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2D:\n",
    "# Choose the ripple epochs to plot:\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(LS_decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long'] # 2D\n",
    "# Choose the laps epochs to plot:\n",
    "# a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(LS_decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# a_decoded_filter_epochs_decoder_result_dict\n",
    "\n",
    "\n",
    "# a_result: DecodedFilterEpochsResult = LS_decoder_laps_filter_epochs_decoder_result_dict['long'] # 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryMatplotlibPlotter\n",
    "\n",
    "## INPUTS: a_result: DecodedFilterEpochsResult, an_epoch_idx: int = 18\n",
    "# e.g. `a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long_LR']`\n",
    "\n",
    "# a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long_LR'] # 1D\n",
    "\n",
    "## Convert to plottable posteriors\n",
    "# an_epoch_idx: int = 0\n",
    "\n",
    "# valid_aclus = deepcopy(decoder_aclu_peak_location_df_merged.aclu.unique())\n",
    "num_filter_epochs: int = a_result.num_filter_epochs\n",
    "a_decoded_traj_plotter = DecodedTrajectoryMatplotlibPlotter(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers)\n",
    "fig, axs, laps_pages = a_decoded_traj_plotter.plot_decoded_trajectories_2d(global_session, curr_num_subplots=8, active_page_index=0, plot_actual_lap_lines=False, use_theoretical_tracks_instead=True)\n",
    "\n",
    "integer_slider = a_decoded_traj_plotter.plot_epoch_with_slider_widget(an_epoch_idx=6)\n",
    "integer_slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f60583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(laps_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps[0].remove()\n",
    "\n",
    "# an_ax.remove(heatmaps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_ax = axs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plotActors, data_dict = plot_3d_stem_points(pCustom, active_epoch_placefields2D.ratemap.xbin, active_epoch_placefields2D.ratemap.ybin, active_epoch_placefields2D.ratemap.occupancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4627224",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_plot(value=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9cfc42",
   "metadata": {},
   "source": [
    "## add to 3D plotter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12058a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryPyVistaPlotter\n",
    "from pyphoplacecellanalysis.Pho3D.PyVista.graphs import plot_3d_stem_points, plot_3d_binned_bars\n",
    "\n",
    "curr_active_pipeline.prepare_for_display()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_interactive_custom_data_explorer', active_session_configuration_context=global_epoch_context,\n",
    "                                    params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                    )\n",
    "iplapsDataExplorer: InteractiveCustomDataExplorer = _out['iplapsDataExplorer']\n",
    "pActiveInteractiveLapsPlotter = _out['plotter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b011ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## INPUTS: a_result, xbin_centers, ybin_centers, iplapsDataExplorer\n",
    "# a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = DecodedTrajectoryPyVistaPlotter(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, p=iplapsDataExplorer.p)\n",
    "# a_decoded_trajectory_pyvista_plotter.build_ui()\n",
    "# a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = iplapsDataExplorer.add_decoded_posterior_bars(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, enable_plot_all_time_bins_in_epoch_mode=True)\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = iplapsDataExplorer.add_decoded_posterior_bars(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, enable_plot_all_time_bins_in_epoch_mode=False, active_plot_fn=plot_3d_stem_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cd81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = iplapsDataExplorer.add_decoded_posterior_bars(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, enable_plot_all_time_bins_in_epoch_mode=False, active_plot_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf0e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "iplapsDataExplorer.clear_all_added_decoded_posterior_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968821ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d6646",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_plot_fn = a_decoded_trajectory_pyvista_plotter.data_dict['plot_3d_binned_bars[55.63197815967686]']['update_plot_fn']\n",
    "# update_plot_fn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_posterior_p_x_given_n, n_epoch_timebins = a_decoded_trajectory_pyvista_plotter._perform_get_curr_posterior(a_result=a_result, an_epoch_idx=a_decoded_trajectory_pyvista_plotter.curr_epoch_idx, time_bin_index=np.arange(a_decoded_trajectory_pyvista_plotter.curr_n_time_bins))\n",
    "# np.shape(a_posterior_p_x_given_n)\n",
    "\n",
    "\n",
    "a_posterior_p_x_given_n, n_epoch_timebins = a_decoded_trajectory_pyvista_plotter.get_curr_posterior(an_epoch_idx=a_decoded_trajectory_pyvista_plotter.curr_epoch_idx, time_bin_index=np.arange(a_decoded_trajectory_pyvista_plotter.curr_n_time_bins))\n",
    "np.shape(a_posterior_p_x_given_n)\n",
    "\n",
    "n_epoch_timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9878ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = a_decoded_trajectory_pyvista_plotter.plotActors['plot_3d_binned_bars[49.11980797704307]']\n",
    "# v['main'].remove()\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter.p.remove_actor(v['main'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6dc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho3D.PyVista.graphs import clear_3d_binned_bars_plots\n",
    "\n",
    "clear_3d_binned_bars_plots(p=a_decoded_trajectory_pyvista_plotter.p, plotActors=a_decoded_trajectory_pyvista_plotter.plotActors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.plotActors_CenterLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.perform_update_plot_epoch_time_bin_range(value=None) # select all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e721a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.perform_clear_existing_decoded_trajectory_plots()\n",
    "iplapsDataExplorer.p.update()\n",
    "iplapsDataExplorer.p.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bin_index = np.arange(a_decoded_trajectory_pyvista_plotter.curr_n_time_bins)\n",
    "type(time_bin_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7059eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.slider_epoch.RemoveAllObservers()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch.Off()\n",
    "# a_decoded_trajectory_pyvista_plotter.slider_epoch.FastDelete()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch = None\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin.RemoveAllObservers()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin.Off()\n",
    "# a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin.FastDelete()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin = None\n",
    "iplapsDataExplorer.p.clear_slider_widgets()\n",
    "iplapsDataExplorer.p.update()\n",
    "iplapsDataExplorer.p.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66de9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecoderRenderingPyVistaMixin\n",
    "\n",
    "(plotActors, data_dict), (plotActors_CenterLabels, data_dict_CenterLabels) = DecoderRenderingPyVistaMixin.perform_plot_posterior_bars(iplapsDataExplorer.p, xbin=xbin, ybin=ybin, xbin_centers=xbin_centers, ybin_centers=ybin_centers,\n",
    "                                               posterior_p_x_given_n=a_posterior_p_x_given_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ab8473",
   "metadata": {},
   "source": [
    "# Other Misc Plotting Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_directional_template_debugger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_template_debugger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_track_template_pf1Ds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_two_step_decoder_prediction_error_2D', global_epoch_context, variable_name='p_x_given_n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_plot_most_likely_position_comparisons', global_epoch_context) # , variable_name='p_x_given_n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddebd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d805c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_display_directional_laps_overview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_display_directional_merged_pfs'\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=False, plot_long_directional=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47076a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_display_1d_placefield_occupancy'\n",
    "'_display_placemaps_pyqtplot_2D'\n",
    " '_display_2d_placefield_occupancy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481df233",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_2d_placefield_occupancy', global_any_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_grid_bin_bounds_validation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbe6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_out = curr_active_pipeline.display('_display_running_and_replay_speeds_over_time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58951b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import add_rectangular_selector, add_range_selector\n",
    "\n",
    "\n",
    "# epoch_name = global_any_name\n",
    "epoch_name = short_epoch_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = computation_result.computation_config['pf_params'].grid_bin_bounds\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n",
    "            \n",
    "fig, ax = computation_result.computed_data.pf2D.plot_occupancy(identifier_details_list=[epoch_name], active_context=epoch_context) \n",
    "\n",
    "# rect_selector, set_extents, reset_extents = add_rectangular_selector(fig, ax, initial_selection=grid_bin_bounds) # (24.82, 257.88), (125.52, 149.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b862a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.peak_location_representing import compute_placefield_center_of_mass_positions\n",
    "\n",
    "\n",
    "epoch_name = global_any_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = deepcopy(computation_result.computation_config['pf_params'].grid_bin_bounds)\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_pf2D.xbin\n",
    "long_pf2D.ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0416d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage # used for `compute_placefield_center_of_masses`\n",
    "from neuropy.utils.mixins.peak_location_representing import compute_occupancy_center_of_mass_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6352663",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_x_center_dict # {'long_LR': 162.99271603199625, 'long_RL': 112.79866056603696, 'short_LR': 138.45611791646, 'short_RL': 130.78889937230684}\n",
    "\n",
    "occupancy_mask_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.visited_occupancy_mask, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_mask_x_center_dict # {'long_LR': 135.66781520875904, 'long_RL': 130.0042755113645, 'short_LR': 133.77996864296085, 'short_RL': 143.21920147195175}\n",
    "\n",
    "\n",
    "# {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb029d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "\n",
    "# masked_nonzero_occupancy = deepcopy(long_pf2D.nan_never_visited_occupancy)\n",
    "\n",
    "masked_nonzero_occupancy = deepcopy(long_pf2D.visited_occupancy_mask)\n",
    "\n",
    "# occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin)\n",
    "occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(masked_nonzero_occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin) # array([127.704, 145.63])\n",
    "occupancy_CoM_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf2D.nan_never_visited_occupancy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4caa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict# '_display_grid_bin_bounds_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f963a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting on 2024-02-06 to display the LR/RL directions instead of the All/Long/Short pfs:\n",
    "def _display_directional_merged_pfs(owning_pipeline_reference, global_computation_results, computation_results, active_configs, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "                                    plot_all_directions=True, plot_long_directional=False, plot_short_directional=False, **kwargs):\n",
    "    \"\"\" Plots the merged pseduo-2D pfs/ratemaps. Plots: All-Directions, Long-Directional, Short-Directional in seperate windows. \n",
    "    \n",
    "    History: this is the Post 2022-10-22 display_all_pf_2D_pyqtgraph_binned_image_rendering-based method:\n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array, display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow \n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import LayoutScrollability\n",
    "\n",
    "    defer_render = kwargs.pop('defer_render', False)\n",
    "    directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "    active_merged_pf_plots_data_dict = {} #empty dict\n",
    "    \n",
    "    if plot_all_directions:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='All-Directions', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.all_directional_pf1D_Decoder.pf # all-directions\n",
    "    if plot_long_directional:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Long-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.long_directional_pf1D_Decoder.pf # Long-only\n",
    "    if plot_short_directional:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Short-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.short_directional_pf1D_Decoder.pf # Short-only\n",
    "\n",
    "    out_plots_dict = {}\n",
    "    \n",
    "    for active_context, active_pf_2D in active_merged_pf_plots_data_dict.items():\n",
    "        # figure_format_config = {} # empty dict for config\n",
    "        figure_format_config = {'scrollability_mode': LayoutScrollability.NON_SCROLLABLE} # kwargs # kwargs as default figure_format_config\n",
    "        out_all_pf_2D_pyqtgraph_binned_image_fig: BasicBinnedImageRenderingWindow  = display_all_pf_2D_pyqtgraph_binned_image_rendering(active_pf_2D, figure_format_config) # output is BasicBinnedImageRenderingWindow\n",
    "    \n",
    "        # Set the window title from the context\n",
    "        out_all_pf_2D_pyqtgraph_binned_image_fig.setWindowTitle(f'{active_context.get_description()}')\n",
    "        out_plots_dict[active_context] = out_all_pf_2D_pyqtgraph_binned_image_fig\n",
    "\n",
    "        # Tries to update the display of the item:\n",
    "        names_list = [v for v in list(out_all_pf_2D_pyqtgraph_binned_image_fig.plots.keys()) if v not in ('name', 'context')]\n",
    "        for a_name in names_list:\n",
    "            # Adjust the size of the text for the item by passing formatted text\n",
    "            a_plot: pg.PlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem # PlotItem \n",
    "            # no clue why 2 is a good value for this...\n",
    "            a_plot.titleLabel.setMaximumHeight(2)\n",
    "            a_plot.layout.setRowFixedHeight(0, 2)\n",
    "            \n",
    "\n",
    "        if not defer_render:\n",
    "            out_all_pf_2D_pyqtgraph_binned_image_fig.show()\n",
    "\n",
    "    return out_plots_dict\n",
    "\n",
    "\n",
    "_display_directional_merged_pfs(curr_active_pipeline, curr_active_pipeline.global_computation_results, computation_results, active_configs, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "                                    plot_all_directions=True, plot_long_directional=False, plot_short_directional=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfeb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "# _out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=True, plot_long_directional=False, plot_short_directional=False)\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs') # scrollable_figure=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7268a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs_marginals') # scrollable_figure=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e434945",
   "metadata": {},
   "source": [
    "# 2023-12-18 - Simpily detect bimodal cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd3ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.peak_location_representing import ContinuousPeakLocationRepresentingMixin\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from scipy.signal import find_peaks\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# curr_active_pipeline.display('_display_1d_placefields', 'maze1_any', sortby=None)\n",
    "\n",
    "# active_ratemap = deepcopy(long_pf1D.ratemap)\n",
    "active_ratemap: Ratemap = deepcopy(long_LR_pf1D.ratemap)\n",
    "peaks_dict, aclu_n_peaks_dict, peaks_results_df = active_ratemap.compute_tuning_curve_modes(height=0.2, width=None)\n",
    "\n",
    "\n",
    "## INPUTS: track_templates\n",
    "included_columns = ['pos', 'peak_heights'] # the columns of interest that you want in the final dataframe.\n",
    "included_columns_renamed = dict(zip(included_columns, ['peak', 'peak_height']))\n",
    "decoder_peaks_results_dfs = [a_decoder.pf.ratemap.get_tuning_curve_peak_df(height=0.2, width=None) for a_decoder in (track_templates.long_LR_decoder, track_templates.long_RL_decoder, track_templates.short_LR_decoder, track_templates.short_RL_decoder)]\n",
    "prefix_names = [f'{a_decoder_name}_' for a_decoder_name in track_templates.get_decoder_names()]\n",
    "all_included_columns = ['aclu', 'series_idx', 'subpeak_idx'] + included_columns # Used to filter out the unwanted columns from the output\n",
    "\n",
    "# [['aclu', 'series_idx', 'subpeak_idx', 'pos']]\n",
    "\n",
    "# rename_list_fn = lambda a_prefix: {'pos': f\"{a_prefix}pos\"}\n",
    "rename_list_fn = lambda a_prefix: {a_col_name:f\"{a_prefix}{included_columns_renamed[a_col_name]}\" for a_col_name in included_columns}\n",
    "\n",
    "# column_names = [f'{a_decoder_name}_peak' for a_decoder_name in track_templates.get_decoder_names()]\n",
    "\n",
    "# dataFrames = decoder_peaks_results_dfs\n",
    "# names = self.get_decoder_names()\n",
    "\n",
    "# rename 'pos' column in each dataframe and then reduce to perform cumulative outer merge\n",
    "result_df = decoder_peaks_results_dfs[0][all_included_columns].rename(columns=rename_list_fn(prefix_names[0]))\n",
    "for df, a_prefix in zip(decoder_peaks_results_dfs[1:], prefix_names[1:]):\n",
    "    result_df = pd.merge(result_df, df[all_included_columns].rename(columns=rename_list_fn(a_prefix)), on=['aclu', 'series_idx', 'subpeak_idx'], how='outer')\n",
    "\n",
    "# result = reorder_columns(result, column_name_desired_index_dict=dict(zip(['Long_LR_evidence', 'Long_RL_evidence', 'Short_LR_evidence', 'Short_RL_evidence'], np.arange(4)+4)))\n",
    "\n",
    "## Move the \"height\" columns to the end\n",
    "# list(filter(lambda column: column.endswith('_peak_heights'), result.columns))\n",
    "# result_df = reorder_columns(result_df, column_name_desired_index_dict=dict(zip(list(filter(lambda column: column.endswith('_peak_heights'), result_df.columns)), np.arange(len(result_df.columns)-4, len(result_df.columns)))))\n",
    "# result_df\n",
    "\n",
    "# print(list(result.columns))\n",
    "\n",
    "## Move the \"height\" columns to the end\n",
    "result_df: pd.DataFrame = reorder_columns_relative(result_df, column_names=list(filter(lambda column: column.endswith('_peak_heights'), result_df.columns)), relative_mode='end').sort_values(['aclu', 'series_idx', 'subpeak_idx']).reset_index(drop=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a292dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually Excluded endcap aclus:\n",
    "IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43')\n",
    "excluded_endcap_aclus: NDArray = np.array(list(set([40, 60, 85, 102, 52, 6] + [83, 60, 52, 102, 40] + [59, 67, 95, 28, 101] + [14, 15, 87, 71] + [43, 84, 87, 19, 33, 51, 53])))\n",
    "excluded_endcap_aclus\n",
    "\n",
    "\n",
    "np.array([  6,  14,  15,  19,  28,  33,  40,  43,  51,  52,  53,  59,  60,  67,  71,  83,  84,  85,  87,  95, 101, 102])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0fdee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_peaks_dict_dict, decoder_aclu_n_peaks_dict_dict, decoder_peaks_results_df_dict = track_templates.get_decoders_tuning_curve_modes()\n",
    "decoder_aclu_n_peaks_dict_dict\n",
    "# decoder_peaks_results_df_dict\n",
    "# decoder_peaks_dict_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f49ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aclu = 51\n",
    "\n",
    "{k:v[test_aclu] for k, v in decoder_aclu_n_peaks_dict_dict.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_results_df = track_templates.get_decoders_aclu_peak_location_df().sort_values(['aclu', 'series_idx', 'subpeak_idx']).reset_index(drop=True) ## Does not seem to merge entries as I would expect via intution. It keeps LR/RL peaks distinct and leaves pd.NA values for the entries.\n",
    "peaks_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c29838",
   "metadata": {},
   "outputs": [],
   "source": [
    "aclu_n_peaks_dict: Dict = peaks_results_df.groupby(['aclu']).agg(subpeak_idx_count=('subpeak_idx', 'count')).reset_index().set_index('aclu').to_dict()['subpeak_idx_count'] # number of peaks (\"models\" for each aclu)\n",
    "aclu_n_peaks_dict\n",
    "\n",
    "# peaks_results_df = peaks_results_df.groupby(['aclu']).agg(subpeak_idx_count=('subpeak_idx', 'count')).reset_index()\n",
    "\n",
    "# peaks_results_df[peaks_results_df.aclu == 5]\n",
    "# peaks_results_df.aclu.value_counts()\n",
    "\n",
    "aclu_n_peaks_dict[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e14bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_ratemap.n_neurons\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze1_any', included_unit_neuron_IDs=active_ratemap.neuron_ids, sortby=np.arange(active_ratemap.n_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aclu_n_peaks_dict\n",
    "unimodal_only_aclus = np.array(list(unimodal_peaks_dict.keys()))\n",
    "unimodal_only_aclus\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze1_any', included_unit_neuron_IDs=unimodal_only_aclus, sortby=np.arange(active_ratemap.n_neurons))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c9e39",
   "metadata": {},
   "source": [
    "# 🖼️🎨 2024-02-08 - `PhoPaginatedMultiDecoderDecodedEpochsWindow` - Plot Ripple Metrics like Radon Transforms, WCorr, Simple Pearson, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf989bf6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import ensure_dataframe\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import RadonTransformPlotDataProvider\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "decoder_ripple_filter_epochs_decoder_result_dict = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }')\n",
    "\n",
    "#  ripple_decoding_time_bin_size = 0.025 \n",
    "# 0.025\n",
    "\n",
    "## OUTPUTS: filtered_decoder_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b7dab",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "## INPUTS: directional_decoders_epochs_decode_result, decoder_ripple_filter_epochs_decoder_result_dict\n",
    "## UPDATES: filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "\n",
    "## filter the epochs by something and only show those:\n",
    "# INPUTS: filtered_epochs_df\n",
    "# filtered_ripple_simple_pf_pearson_merged_df = filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(active_epochs_df[['start', 'stop']].to_numpy())\n",
    "decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "## Update the `decoder_ripple_filter_epochs_decoder_result_dict` with the included epochs:\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "# print(f\"any_good_selected_epoch_times.shape: {any_good_selected_epoch_times.shape}\") # (142, 2)\n",
    "\n",
    "pre_cols = {a_name:set(a_result.filter_epochs.columns) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()}\n",
    "\n",
    "# 🟪 2024-02-29 - `compute_pho_heuristic_replay_scores`\n",
    "filtered_decoder_filter_epochs_decoder_result_dict, _out_new_scores = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "## 2024-03-08 - Also constrain the user-selected ones (just to try it):\n",
    "decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline, track_templates=track_templates)\n",
    "# ## Constrain again now by the user selections\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(any_good_selected_epoch_times) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()}\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "## Instead, add in the 'is_user_annotated_epoch' column instead of filtering\n",
    "## INPUTS: any_good_selected_epoch_times\n",
    "num_user_selected_times: int = len(any_good_selected_epoch_times)\n",
    "print(f'num_user_selected_times: {num_user_selected_times}')\n",
    "any_good_selected_epoch_indicies = None\n",
    "print(f'adding user annotation column!')\n",
    "\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "\n",
    "## OUT: filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "# ## specifically long_LR\n",
    "# filter_epochs: pd.DataFrame = deepcopy(ensure_dataframe(filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs))\n",
    "\n",
    "## OUTPUTS: filtered_epochs_df\n",
    "# filtered_epochs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b0d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_decoder_decoded_epochs_result.filter_epochs\n",
    "a_decoder_decoded_epochs_result: DecodedFilterEpochsResult = decoder_ripple_filter_epochs_decoder_result_dict['long_LR']\n",
    "num_filter_epochs: int = a_decoder_decoded_epochs_result.num_filter_epochs\n",
    "active_epoch_idx: int = 6 #28\n",
    "active_captured_single_epoch_result: SingleEpochDecodedResult = a_decoder_decoded_epochs_result.get_result_for_epoch(active_epoch_idx=active_epoch_idx)\n",
    "most_likely_position_indicies = deepcopy(active_captured_single_epoch_result.most_likely_position_indicies)\n",
    "most_likely_position_indicies = np.squeeze(most_likely_position_indicies)\n",
    "t_bin_centers = deepcopy(active_captured_single_epoch_result.time_bin_container.centers)\n",
    "t_bin_indicies = np.arange(len(np.squeeze(most_likely_position_indicies)))\n",
    "# most_likely_position_indicies\n",
    "p_x_given_n = deepcopy(active_captured_single_epoch_result.marginal_x.p_x_given_n)\n",
    "# p_x_given_n_image = active_captured_single_epoch_result.get_posterior_as_image(skip_img_normalization=False, export_grayscale=True)\n",
    "# p_x_given_n_image = img_data_to_greyscale(p_x_given_n)\n",
    "\n",
    "# active_captured_single_epoch_result.epoch_info_tuple # EpochTuple(Index=28, start=971.8437469999772, stop=983.9541530000279, label='28', duration=12.110406000050716, lap_id=29, lap_dir=1, score=0.36769430044232587, velocity=1.6140523749028528, intercept=1805.019565924132, speed=1.6140523749028528, wcorr=-0.9152062701244238, P_decoder=0.6562437078530542, pearsonr=-0.7228173157676305, travel=0.0324318935144031, coverage=0.19298245614035087, jump=0.0005841121495327102, sequential_correlation=16228.563177472019, monotonicity_score=16228.563177472019, laplacian_smoothness=16228.563177472019, longest_sequence_length=22, longest_sequence_length_ratio=0.4583333333333333, direction_change_bin_ratio=0.19148936170212766, congruent_dir_bins_ratio=0.574468085106383, total_congruent_direction_change=257.92556950947574, total_variation=326.1999849678664, integral_second_derivative=7423.7044320722935, stddev_of_diff=8.368982188902695)\n",
    "\n",
    "p_x_given_n\n",
    "# p_x_given_n_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd98310",
   "metadata": {},
   "source": [
    "### 2024-05-09 - get the most-likely decoder for each epoch using the sequenceless probabilities and used this to selected the appopriate column for each of the heuristic measures.\n",
    "Modifies `extracted_merged_scores_df`, adding \"*_BEST\" columns for each specified heuristic score column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f4853",
   "metadata": {
    "tags": [
     "PROMISING"
    ]
   },
   "outputs": [],
   "source": [
    "extracted_merged_scores_df: pd.DataFrame =  directional_decoders_epochs_decode_result.build_complete_all_scores_merged_df()\n",
    "\n",
    "ripple_weighted_corr_merged_df = deepcopy(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df)\n",
    "\n",
    "## Need 'best_decoder_index':... actually 'most_likely_decoder_index'\n",
    "\n",
    "# best_decoder_index = deepcopy(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.filter_epochs['best_decoder_index']) # hope this is correct and not just like the best wcorr or something\n",
    "best_decoder_index = deepcopy(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df['most_likely_decoder_index'])\n",
    "\n",
    "new_heuristic_checking_columns = ['total_variation', 'integral_second_derivative', 'stddev_of_diff', 'score'] # , 'integral_second_derivative', 'stddev_of_diff', 'score'\n",
    "# best_decoder_names = [['long_LR', 'long_RL', 'short_LR', 'short_RL'][an_idx] for an_idx in best_decoder_index]\n",
    "## Example: extracted_merged_scores_df[['total_variation_long_LR', 'total_variation_long_RL', 'total_variation_short_LR', 'total_variation_short_RL']]\n",
    "for a_score_col in new_heuristic_checking_columns:\n",
    "    curr_score_col_decoder_col_names = [f\"{a_score_col}_{a_decoder_name}\" for a_decoder_name in ['long_LR', 'long_RL', 'short_LR', 'short_RL']]\n",
    "    # print(f'curr_score_col_decoder_col_names: {curr_score_col_decoder_col_names}')\n",
    "    # extracted_merged_scores_df\n",
    "    _final_out = [extracted_merged_scores_df[curr_score_col_decoder_col_names].to_numpy()[epoch_idx, a_decoder_idx] for epoch_idx, a_decoder_idx in zip(np.arange(np.shape(extracted_merged_scores_df)[0]), best_decoder_index.to_numpy())]\n",
    "    extracted_merged_scores_df[f\"{a_score_col}_BEST\"] = _final_out # extracted_merged_scores_df[curr_score_col_decoder_col_names].to_numpy()[best_decoder_index]\n",
    "\n",
    "extracted_merged_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fdcf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow, DecodedEpochSlicesPaginatedFigureController, EpochSelectionsObject, ClickActionCallbacks\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.PaginationCtrl.PaginationControlWidget import PaginationControlWidget, PaginationControlWidgetState\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.Resources import GuiResources, ActionIcons, silx_resources_rc\n",
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "app, paginated_multi_decoder_decoded_epochs_window, pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=filtered_decoder_filter_epochs_decoder_result_dict,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# decoder_decoded_epochs_result_dict=filtered_ripple_simple_pf_pearson_merged_df\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=high_wcorr_only_filtered_decoder_filter_epochs_decoder_result_dict,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# epochs_name='ripple',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdecoder_decoded_epochs_result_dict=decoder_laps_filter_epochs_decoder_result_dict,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tepochs_name='laps',\n",
    "                                                                                                included_epoch_indicies=None, debug_print=False,\n",
    "                                                                                                params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 10,\n",
    "                                                                                                    'scrollable_figure': False,\n",
    "                                                                                                    # 'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': False,\n",
    "                                                                                                    'should_suppress_callback_exceptions': False,\n",
    "                                                                                                    # 'build_fn': 'insets_view',\n",
    "                                                                                                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7526ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70be19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.remove_data_overlays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27447e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp_out_selections = paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a13967",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp_out_selections = paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations(source='diba_evt_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed829e59",
   "metadata": {},
   "source": [
    "## array_as_image export:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6effae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import build_attached_raster_viewer_widget\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=filtered_epochs_df) ## BEST\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=filtered_ripple_simple_pf_pearson_merged_df) # original\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=extracted_merged_scores_df)\n",
    "\n",
    "# all_directional_laps_filter_epochs_decoder_result_value\n",
    "# laps_spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=5)\n",
    "laps_spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=5)\n",
    "# laps_filter_epochs = ensure_dataframe(deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)) \n",
    "_out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=laps_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=filtered_laps_simple_pf_pearson_merged_df) ## LAPS\n",
    "\n",
    "# _out_ripple_rasters: RankOrderRastersDebugger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1915a0fe",
   "metadata": {},
   "source": [
    "## Export Last-Clicked Epoch Raster and Posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9188ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack\n",
    "from PIL import Image, ImageOps, ImageFilter # for export_array_as_image\n",
    "\n",
    "# Get the clicked epoch from the _out_ripple_rasters GUI _____________________________________________________________ #\n",
    "active_epoch_tuple = deepcopy(_out_ripple_rasters.active_epoch_tuple)\n",
    "# active_epoch_dict = {k:getattr(active_epoch_tuple, k) for k in ['start', 'stop', 'ripple_idx', 'Index']} # , 'session_name', 'time_bin_size', 'delta_aligned_start_t' {'start': 1161.0011335673044, 'stop': 1161.274357107468, 'session_name': '2006-6-09_1-22-43', 'time_bin_size': 0.025, 'delta_aligned_start_t': 131.68452480540145}\n",
    "active_epoch_dict = {k:getattr(active_epoch_tuple, k) for k in ['start', 'stop', 'Index']} # , 'session_name', 'time_bin_size', 'delta_aligned_start_t' {'start': 1161.0011335673044, 'stop': 1161.274357107468, 'session_name': '2006-6-09_1-22-43', 'time_bin_size': 0.025, 'delta_aligned_start_t': 131.68452480540145}\n",
    "\n",
    "# clicked_epoch = np.array([169.95631618227344, 170.15983607806265])\n",
    "# clicked_epoch = np.array([91.57839279191103, 91.857145929])\n",
    "print(f'clicked_epoch: {active_epoch_dict}')\n",
    "clicked_epoch = np.array([active_epoch_dict['start'], active_epoch_dict['stop']])\n",
    "# OUTPUTS: clicked_epoch\n",
    "print(f'clicked_epoch: {clicked_epoch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045d7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export Marginal Pseudo2D posteriors and rasters for middle-clicked epochs:\n",
    "# root_export_path = Path(r\"E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Pho-Kamran-Meetings\\2024-05-01 - Pseudo2D Again\\array_as_image\").resolve() # Apogee\n",
    "# root_export_path = Path('/media/halechr/MAX/cloud/University of Michigan Dropbox/Pho Hale/Pho Diba Paper 2023/array_as_image').resolve() # Lab\n",
    "root_export_path = Path(r\"E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Pho-Kamran-Meetings\\2024-09-25 - Time bin considerations\\array_as_image\").resolve() # Apogee\n",
    "# epoch_id_identifier_str='ripple'\n",
    "epoch_id_identifier_str='lap'\n",
    "\n",
    "desired_width = 2048\n",
    "desired_height = 720\n",
    "# desired_height = None\n",
    "\n",
    "## Session-specific folder:\n",
    "context_specific_root_export_path = root_export_path.joinpath(curr_context.get_description(separator='_')).resolve()\n",
    "context_specific_root_export_path.mkdir(exist_ok=True)\n",
    "assert context_specific_root_export_path.exists()\n",
    "\n",
    "# Get the clicked epoch from the _out_ripple_rasters GUI _____________________________________________________________ #\n",
    "active_epoch_tuple = deepcopy(_out_ripple_rasters.active_epoch_tuple)\n",
    "# active_epoch_dict = {k:getattr(active_epoch_tuple, k) for k in ['start', 'stop', 'ripple_idx', 'Index']} # , 'session_name', 'time_bin_size', 'delta_aligned_start_t' {'start': 1161.0011335673044, 'stop': 1161.274357107468, 'session_name': '2006-6-09_1-22-43', 'time_bin_size': 0.025, 'delta_aligned_start_t': 131.68452480540145}\n",
    "active_epoch_dict = {k:getattr(active_epoch_tuple, k) for k in ['start', 'stop', 'Index']} # , 'session_name', 'time_bin_size', 'delta_aligned_start_t' {'start': 1161.0011335673044, 'stop': 1161.274357107468, 'session_name': '2006-6-09_1-22-43', 'time_bin_size': 0.025, 'delta_aligned_start_t': 131.68452480540145}\n",
    "\n",
    "\n",
    "# clicked_epoch = np.array([169.95631618227344, 170.15983607806265])\n",
    "# clicked_epoch = np.array([91.57839279191103, 91.857145929])\n",
    "print(f'clicked_epoch: {active_epoch_dict}')\n",
    "clicked_epoch = np.array([active_epoch_dict['start'], active_epoch_dict['stop']])\n",
    "# OUTPUTS: clicked_epoch\n",
    "print(f'clicked_epoch: {clicked_epoch}')\n",
    "\n",
    "# Epoch-specific folder:\n",
    "# ripple_specific_folder: Path = context_specific_root_export_path.joinpath(f\"ripple_{active_epoch_dict['ripple_idx']}\").resolve()\n",
    "# ripple_specific_folder: Path = context_specific_root_export_path.joinpath(f\"ripple_{active_epoch_dict['Index']}\").resolve()\n",
    "ripple_specific_folder: Path = context_specific_root_export_path.joinpath(f\"lap_{active_epoch_dict['Index']}\").resolve()\n",
    "ripple_specific_folder.mkdir(exist_ok=True)\n",
    "assert ripple_specific_folder.exists()\n",
    "file_uri_from_path(ripple_specific_folder)\n",
    "fullwidth_path_widget(a_path=ripple_specific_folder, file_name_label=\"lap_specific_folder:\")\n",
    "\n",
    "# clicked_epoch: {'start': 105.40014315512963, 'stop': 105.56255971186329, 'ripple_idx': 8, 'Index': 8}\n",
    "# clicked_epoch: [105.4 105.563]\n",
    "# ripple_8\n",
    "\n",
    "\n",
    "# clicked_epoch: {'start': 1085.0796108391369, 'stop': 1085.1836594259366, 'ripple_idx': 240, 'Index': 240}\n",
    "# clicked_epoch: [1085.08 1085.18]\n",
    "# ripple_240\n",
    "\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Export Rasters:                                                                                                      #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "# Save out the actual raster-plots ___________________________________________________________________________________ #\n",
    "_out_rasters_save_paths = _out_ripple_rasters.save_figure(export_path=ripple_specific_folder,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   width=desired_width,\n",
    "                                                        #    height=desired_height,\n",
    "                                                          )\n",
    "# _out_rasters_save_paths\n",
    "\n",
    "# OUTPUTS: ripple_specific_folder, _out_rasters_save_paths\n",
    "out_image_save_tuple_dict = PosteriorExporting._test_export_marginals_for_figure(directional_merged_decoders_result=directional_merged_decoders_result,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#   filtered_decoder_filter_epochs_decoder_result_dict=filtered_decoder_filter_epochs_decoder_result_dict, #ripple\n",
    "                                                                                    filtered_decoder_filter_epochs_decoder_result_dict=decoder_laps_filter_epochs_decoder_result_dict, ## laps\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  clicked_epoch=clicked_epoch,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  context_specific_root_export_path=context_specific_root_export_path, ripple_specific_folder=ripple_specific_folder,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  epoch_id_identifier_str=epoch_id_identifier_str, debug_print=False, desired_width=desired_width, desired_height=desired_height)\n",
    "# out_image_save_tuple_dict\n",
    "\n",
    "## INPUTS: _out_rasters_save_paths, out_image_save_tuple_dict[-1]\n",
    "\n",
    "# Open the images\n",
    "_raster_imgs = [Image.open(i) for i in _out_rasters_save_paths]\n",
    "# Open the images\n",
    "_posterior_imgs = [Image.open(i) for i in list(out_image_save_tuple_dict[-1].values())]\n",
    "\n",
    "# _raster_imgs\n",
    "# _posterior_imgs\n",
    "\n",
    "\n",
    "# _out_all_decoders_stacks = []\n",
    "# for a_raster_path, (a_decoder_name, a_posterior_path) in zip(_out_rasters_save_paths, out_image_save_tuple_dict[-1]):\n",
    "# for a_raster_img, a_posterior_img in zip(_raster_imgs, _posterior_imgs):\n",
    "\t\n",
    "# _out_hstack = horizontal_image_stack([vertical_image_stack([a_posterior_img, a_raster_img], padding=5, v_overlap=50) for a_raster_img, a_posterior_img in zip(_raster_imgs, _posterior_imgs)], padding=5)\n",
    "_out_all_decoders_posteriors_and_rasters_stack_image = horizontal_image_stack([vertical_image_stack([a_posterior_img, a_raster_img], padding=0) for a_raster_img, a_posterior_img in zip(_raster_imgs, _posterior_imgs)], padding=0) # no overlap\n",
    "_out_all_decoders_posteriors_and_rasters_stack_image\n",
    "\n",
    "# _out_all_decoders_posteriors_and_rasters_stack_image = horizontal_image_stack([vertical_image_stack([a_posterior_img, a_raster_img], padding=0, v_overlap=a_posterior_img.size[-1]) for a_raster_img, a_posterior_img in zip(_raster_imgs, _posterior_imgs)], padding=5) # posterior is inset to the top of the raster (raster image is taller).\n",
    "# _out_all_decoders_posteriors_and_rasters_stack_image\n",
    "\n",
    "## Save merged image:\n",
    "_sub_img_path = _out_rasters_save_paths[0].parent.resolve().joinpath(f'all_decoders_posteriors_and_rasters_stack_image.png').resolve()\n",
    "_out_all_decoders_posteriors_and_rasters_stack_image.save(_sub_img_path) # Save image to file\n",
    "print(f'saved image to: \"{_sub_img_path.as_posix()}\"')\n",
    "# _out_save_tuples.append((_out_all_decoders_posteriors_and_rasters_stack_image, _sub_img_path))\n",
    "\n",
    "# \t_raster_imgs = [Image.open(i) for i in a_raster_path]\n",
    "#     # _out_vstack = vertical_image_stack(_raster_imgs, padding=5)\n",
    "#     # _out_vstack\n",
    "\n",
    "# # Open the images\n",
    "# _raster_imgs = [Image.open(i) for i in _out_rasters_save_paths]\n",
    "# # _out_vstack = vertical_image_stack(_raster_imgs, padding=5)\n",
    "# # _out_vstack\n",
    "# _out_hstack = horizontal_image_stack(_raster_imgs, padding=5)\n",
    "# _out_hstack\n",
    "\n",
    "# _out_hstack = horizontal_image_stack(_raster_imgs, padding=5)\n",
    "# _out_hstack\n",
    "\n",
    "# _out_hstack_posteriors = horizontal_image_stack(_posterior_imgs, padding=5)\n",
    "# _out_hstack_posteriors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e74d5",
   "metadata": {},
   "source": [
    "## Test aligning time bin grid between rasters and posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df79d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import _extract_matplotlib_ax_xticks, _apply_xticks_to_pyqtgraph_plotitem\n",
    "\n",
    "# _out_ripple_rasters.active_epoch_tuple\n",
    "for a_decoder_name, a_render_plots_container in _out_ripple_rasters.plots['all_separate_plots'].items():\n",
    "    # a_render_plots_container['grid']\n",
    "    plot_item = a_render_plots_container['root_plot']\n",
    "    # Access the x-axis\n",
    "    x_axis = plot_item.getAxis('bottom')\n",
    "    # Define custom ticks at desired x-values\n",
    "    # Each tick is a tuple of (position, label)\n",
    "    custom_ticks = [(pos, str(pos)) for pos in x_grid_positions]\n",
    "    # Set the custom ticks\n",
    "    # The setTicks method accepts a list of tick lists, one for each tick level\n",
    "    x_axis.setTicks([custom_ticks])\n",
    "    # Enable the grid and ensure it aligns with ticks\n",
    "    plot_item.showGrid(x=True, y=True, alpha=0.5)\n",
    "\n",
    "\t# 'long_RL': RenderPlots({...})\n",
    "\t# ['root_plot']\n",
    "\t# 'grid', 'scatter_plot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381feacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tick_positions, tick_label_texts = _extract_matplotlib_ax_xticks(ax)\n",
    "# Create a list of tuples for ticks: (position, label)\n",
    "custom_ticks = list(zip(tick_positions, tick_label_texts))\n",
    "\n",
    "_apply_xticks_to_pyqtgraph_plotitem(plot_item, custom_ticks=custom_ticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f935b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    # v.params.enable_radon_transform_info = False\n",
    "    # v.params.enable_weighted_correlation_info = False\n",
    "    # v._subfn_clear_selectability_rects()\n",
    "    # v.try_get_clicked_epoch\n",
    "    # v.current_page_idx\n",
    "    \n",
    "    included_page_data_indicies, (curr_page_active_filter_epochs, curr_page_epoch_labels, curr_page_time_bin_containers, curr_page_posterior_containers) = v.plots_data.paginator.get_page_data(page_idx=v.current_page_idx)\n",
    "    a_binning_container = deepcopy(curr_page_time_bin_containers[0]) # BinningContainer \n",
    "    curr_epoch_bin_edges: NDArray = deepcopy(a_binning_container.edges)\n",
    "    # curr_epoch_bin_edges\n",
    "    \n",
    "    ## Get the plot to modify on the raster_plot_widget\n",
    "    a_render_plots_container = _out_ripple_rasters.plots['all_separate_plots'][k] # RenderPlots\n",
    "    plot_item = a_render_plots_container['root_plot']\n",
    "    \n",
    "    # Define custom ticks at desired x-values\n",
    "    # Each tick is a tuple of (position, label)\n",
    "    # custom_ticks = [(pos, str(pos)) for pos in curr_epoch_bin_edges]\n",
    "    custom_ticks = [(pos, '') for pos in curr_epoch_bin_edges]\n",
    "    \n",
    "    _apply_xticks_to_pyqtgraph_plotitem(plot_item=plot_item, custom_ticks=custom_ticks)\n",
    "    \n",
    "    \n",
    "    # v.plots_data['epoch_slices'] #.dynamically_added_attributes\n",
    "    # epoch_durations = np.squeeze(np.diff(v.plots_data.epoch_slices, axis=1))\n",
    "    # global_max_epoch_duration: float = np.max(epoch_durations)\n",
    "    # global_max_epoch_duration\n",
    "    # v.plots\n",
    "    \n",
    "# paginated_multi_decoder_decoded_epochs_window.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e379220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the x-axis\n",
    "x_axis = plot_item.getAxis('bottom')\n",
    "\n",
    "# Define custom ticks at desired x-values\n",
    "# Each tick is a tuple of (position, label)\n",
    "custom_ticks = [(pos, str(pos)) for pos in x_grid_positions]\n",
    "\n",
    "# Set the custom ticks\n",
    "# The setTicks method accepts a list of tick lists, one for each tick level\n",
    "x_axis.setTicks([custom_ticks])\n",
    "\n",
    "# Enable the grid and ensure it aligns with ticks\n",
    "plot_item.showGrid(x=True, y=True, alpha=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f8d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.binning_helpers import BinningContainer\n",
    "\n",
    "\n",
    "for k, v in filtered_decoder_filter_epochs_decoder_result_dict.items():\n",
    "    # v: DecodedFilterEpochsResult\n",
    "    a_binning_container: BinningContainer = v.time_bin_containers[0]\n",
    "    a_binning_container.center_info.step\n",
    "    # v.params.enable_radon_transform_info = False\n",
    "    # v.params.enable_weighted_correlation_info = False\n",
    "    # v._subfn_clear_selectability_rects()\n",
    "    # v.try_get_clicked_epoch\n",
    "    # v.current_page_idx\n",
    "    # v.plots\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd8a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_merged_decoders_result # all_directional_ripple_filter_epochs_decoder_result, ripple_track_identity_marginals_tuple\n",
    "\n",
    "all_directional_ripple_filter_epochs_decoder_result: DecodedFilterEpochsResult = deepcopy(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result) # DecodedFilterEpochsResult\n",
    "# all_directional_ripple_filter_epochs_decoder_result.filter_epochs\n",
    "# all_directional_ripple_filter_epochs_decoder_result.get_result_for_epoch(\n",
    "# len(all_directional_ripple_filter_epochs_decoder_result.marginal_y_list)\n",
    "# 'p_x_given_n'\n",
    "\n",
    "# len(directional_merged_decoders_result.ripple_track_identity_marginals_tuple) # 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo2D_decoder #: BasePositionDecoder\n",
    "\n",
    "# pseudo2D_decoder.P_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306cd759",
   "metadata": {},
   "source": [
    "### Resume misc `paginated_multi_decoder_decoded_epochs_window` manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85200305",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.plotData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac1262",
   "metadata": {},
   "source": [
    "### Exploring adding buttons to button bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced85ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "from attrs import asdict, astuple\n",
    "from pyphocorehelpers.gui.Qt.ExceptionPrintingSlot import pyqtExceptionPrintingSlot\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import build_programmatic_buttons, ProgrammaticButtonConfig\n",
    "\n",
    "global_thin_button_bar_widget: ThinButtonBarWidget = paginated_multi_decoder_decoded_epochs_window.global_thin_button_bar_widget\n",
    "\n",
    "## INPUT: global_thin_button_bar_widget\n",
    "button_config_list = [\n",
    "#  dict(icon_path=':/png/gui/icons/document-open.png', name=\"OpenFile\"),\n",
    "#  dict(icon_path=':/png/gui/icons/document-save.png', name=\"SaveFile\"),\n",
    "#  dict(icon_path=':/png/gui/icons/crosshair.png', name=\"Crosshairs\"),\n",
    "#  dict(icon_path=':/png/gui/icons/crop.png', name=\"Crop\"),\n",
    "#  dict(icon_path=':/png/gui/icons/selected.png', name=\"Selections\"),\n",
    "#  dict(icon_path=':/png/gui/icons/view-raw.png', name=\"CopyAsArray\"),\n",
    " dict(icon_path=':/png/gui/icons/view-refresh.png', name=\"Refresh\", callback=(lambda self, *args, **kwargs: paginated_multi_decoder_decoded_epochs_window.refresh_current_page())), ## captures: paginated_multi_decoder_decoded_epochs_window\n",
    " dict(icon_path=':/png/gui/icons/nxdata-create.png', name=\"AddDataOverlays\", callback=(lambda self, *args, **kwargs: paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict))), ## captures: paginated_multi_decoder_decoded_epochs_window, decoder_laps_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict\n",
    " dict(icon_path=':/png/gui/icons/mask-clear-all.png', name=\"RemoveDataOverlays\", callback=(lambda self, *args, **kwargs: paginated_multi_decoder_decoded_epochs_window.remove_data_overlays())), ## captures: paginated_multi_decoder_decoded_epochs_window\n",
    " dict(icon_path=':/png/gui/icons/document-print.png', name=\"PrintUserAnnotations\", callback=(lambda self, *args, **kwargs: paginated_multi_decoder_decoded_epochs_window.print_user_annotations())), ## captures: paginated_multi_decoder_decoded_epochs_window\n",
    " dict(icon_path=':/png/gui/icons/image-select-erase.png', name=\"LoadUserAnnotations\", callback=(lambda self, *args, **kwargs: paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations())), ## captures: paginated_multi_decoder_decoded_epochs_window\n",
    "   \n",
    "\n",
    "]\n",
    "button_config_dict = {v['name']:v for v in button_config_list}\n",
    "\n",
    "new_buttons_config_dict, new_buttons_dict = build_programmatic_buttons(global_thin_button_bar_widget, button_config_dict=button_config_dict, clear_all_existing=True)\n",
    "\n",
    "# _tmp_out_selections = paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations()\n",
    "# global_thin_button_bar_widget.horizontalLayout_ButtonContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f65ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.global_thin_button_bar_widget\n",
    "\n",
    "# paginated_multi_decoder_decoded_epochs_window.pagination_controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe42bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_paginator_controller_widget.\n",
    "global_thin_button_bar_widget.horizontalLayout.removeWidget(global_paginator_controller_widget)\n",
    "global_paginator_controller_widget.setParent(None)\n",
    "global_paginator_controller_widget.deleteLater()\n",
    "global_paginator_controller_widget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d75397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.ComboBoxMixins import build_combo_box\n",
    "\n",
    "new_combo_box = build_combo_box(label='Format', options=['Numpy','Png', 'Svg'])\n",
    "\n",
    "global_thin_button_bar_widget.horizontalLayout.addWidget(new_combo_box) # add the pagination control widget\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2815939",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_thin_button_bar_widget.label_message = \"\\n\\t\".join(np.arange(80).astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b66b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "txtLineEdit = global_thin_button_bar_widget.ui.txtLineEdit # PyQt5.QtWidgets.QLineEdit\n",
    "txtLineEdit.toolTip()\n",
    "txtLineEdit.text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a19c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtCore import Qt\n",
    "\n",
    "line_edit = txtLineEdit\n",
    "full_text: str = \"\\n\".join(np.arange(80).astype(str))\n",
    "txtLineEdit.setToolTip(full_text)\n",
    "\n",
    "fm = line_edit.fontMetrics()\n",
    "available_width = int(round(line_edit.width() * 0.8))  - 2  # Subtracting a small margin\n",
    "elided_text = fm.elidedText(full_text, Qt.ElideRight, available_width)\n",
    "line_edit.setText(elided_text)\n",
    "print(f'fm: {fm}')\n",
    "print(f'available_width: {available_width}')\n",
    "print(f'elided_text: {elided_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d170fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "txtLineEdit.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d997feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_thin_button_bar_widget.clear_all_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484098e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_buttons_dict[ 'RemoveDataOverlays'].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2615d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_btn.pressed.disconnect()\n",
    "a_btn.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed5481",
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(global_thin_button_bar_widget, a_fn_name)(global_thin_button_bar_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb4485",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dummy_btn_config.on_click_fn()\n",
    "a_dummy_btn_config.fn_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c6d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_thin_button_bar_widget.clear_all_buttons()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.perform_update_titles_from_context(page_idx=page_idx, included_page_data_indicies=included_page_data_indicies)\n",
    "update_titles(self, window_title: str, suptitle: str = None)\n",
    "\n",
    "\n",
    "def update_titles(self, window_title: str, suptitle: str = None):\n",
    "    \"\"\" sets the suptitle and window title for the figure \"\"\"\n",
    "    if suptitle is None:\n",
    "        suptitle = window_title # same as window title\n",
    "    # Set the window title:\n",
    "    self.ui.mw.setWindowTitle(window_title)\n",
    "    self.ui.mw.fig.suptitle(suptitle, wrap=True) # set the plot suptitle\n",
    "    self.ui.mw.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46868c2c",
   "metadata": {},
   "source": [
    "### Custom click callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad5dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import ClickActionCallbacks\n",
    "\n",
    "is_enabled = True\n",
    "for a_name, a_pagination_controller in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    # a_pagination_controller.params.debug_print = True    \n",
    "    print(f\"a_pagination_controller.params['on_middle_click_item_callbacks']: {a_pagination_controller.params['on_middle_click_item_callbacks']}\")\n",
    "    print(f\"a_pagination_controller.params['on_secondary_click_item_callbacks']: {a_pagination_controller.params.get('on_secondary_click_item_callbacks', {})}\")\n",
    "    a_pagination_controller.params.should_suppress_callback_exceptions = False\n",
    "    \n",
    "    if not a_pagination_controller.params.has_attr('on_middle_click_item_callbacks'):\n",
    "        a_pagination_controller.params['on_middle_click_item_callbacks'] = {}\n",
    "        \n",
    "    if not a_pagination_controller.params.has_attr('on_secondary_click_item_callbacks'):\n",
    "        a_pagination_controller.params['on_secondary_click_item_callbacks'] = {}\n",
    "        \n",
    "    a_pagination_controller.params['on_secondary_click_item_callbacks'] = {}\n",
    "    \n",
    "    if is_enabled:\n",
    "        # a_pagination_controller.params.on_middle_click_item_callbacks['copy_click_time_to_clipboard_callback'] = ClickActionCallbacks.copy_click_time_to_clipboard_callback\n",
    "        # a_pagination_controller.params.on_secondary_click_item_callbacks['copy_click_time_to_clipboard_callback'] = ClickActionCallbacks.copy_click_time_to_clipboard_callback\n",
    "        a_pagination_controller.params.on_secondary_click_item_callbacks['copy_axis_image_to_clipboard_callback'] = ClickActionCallbacks.copy_axis_image_to_clipboard_callback\n",
    "        \n",
    "    else:\n",
    "        # a_pagination_controller.params.on_middle_click_item_callbacks.pop('copy_click_time_to_clipboard_callback', None)\n",
    "        # a_pagination_controller.params.on_secondary_click_item_callbacks.pop('copy_click_time_to_clipboard_callback', None)\n",
    "        a_pagination_controller.params.on_secondary_click_item_callbacks.pop('copy_axis_image_to_clipboard_callback', None)\n",
    "        \n",
    "    # a_pagination_controller.params.on_secondary_click_item_callbacks.pop('copy_epoch_times_to_clipboard_callback', None)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# paginated_multi_decoder_decoded_epochs_window.params.on_middle_click_item_callbacks['copy_axis_image_to_clipboard_callback'] = ClickActionCallbacks.copy_axis_image_to_clipboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## printing the callback values don't seem to work until after `paginated_multi_decoder_decoded_epochs_window.add_data_overlays(...)` is called.\n",
    "# paginated_multi_decoder_decoded_epochs_window.enable_middle_click_selected_epoch_times_to_clipboard(is_enabled=False)\n",
    "paginated_multi_decoder_decoded_epochs_window.enable_middle_click_selected_epoch_times_to_clipboard(is_enabled=True)\n",
    "\n",
    "# clicked_epoch = np.array([132.51138943410479, 132.79100273095537])\n",
    "\n",
    "# clicked_epoch = np.array([149.95935746072792, 150.25439218967222])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e3bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_epoch_start_stop_time = [488.296 488.484]\n",
    "start_t = 488.29642327222973\n",
    "found_IDX = 24\n",
    "\n",
    "# ripple_idx=80, ripple_start_t=488.29642327222973\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_attributes(short_name=None, tags=['callback'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2024-04-29 17:16', related_items=[])\n",
    "def an_alt_clicked_epoch_callback(self, event, clicked_ax, clicked_data_index, clicked_epoch_is_selected, clicked_epoch_start_stop_time):\n",
    "    \"\"\" called when the user middle-clicks an epoch \n",
    "    \n",
    "    captures: _out_ripple_rasters\n",
    "    \"\"\"\n",
    "    print(f'an_alt_clicked_epoch_callback(clicked_data_index: {clicked_data_index}, clicked_epoch_is_selected: {clicked_epoch_is_selected}, clicked_epoch_start_stop_time: {clicked_epoch_start_stop_time})')\n",
    "    if clicked_epoch_start_stop_time is not None:\n",
    "        if len(clicked_epoch_start_stop_time) == 2:\n",
    "            start_t, end_t = clicked_epoch_start_stop_time\n",
    "            print(f'start_t: {start_t}')\n",
    "            _out_ripple_rasters.programmatically_update_epoch_IDX_from_epoch_start_time(start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enable programmatically updating the rasters viewer to the clicked epoch index when middle clicking on a posterior.\n",
    "@function_attributes(short_name=None, tags=['callback'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2024-04-29 17:16', related_items=[])\n",
    "def an_alt_clicked_epoch_callback(self, event, clicked_ax, clicked_data_index, clicked_epoch_is_selected, clicked_epoch_start_stop_time):\n",
    "    \"\"\" called when the user middle-clicks an epoch \n",
    "    \n",
    "    captures: _out_ripple_rasters\n",
    "    \"\"\"\n",
    "    print(f'an_alt_clicked_epoch_callback(clicked_data_index: {clicked_data_index}, clicked_epoch_is_selected: {clicked_epoch_is_selected}, clicked_epoch_start_stop_time: {clicked_epoch_start_stop_time})')\n",
    "    if clicked_epoch_start_stop_time is not None:\n",
    "        if len(clicked_epoch_start_stop_time) == 2:\n",
    "            start_t, end_t = clicked_epoch_start_stop_time\n",
    "            print(f'start_t: {start_t}')\n",
    "            _out_ripple_rasters.programmatically_update_epoch_IDX_from_epoch_start_time(start_t)\n",
    "\n",
    "\n",
    "for a_name, a_pagination_controller in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    # a_pagination_controller.params.debug_print = True\n",
    "    if not a_pagination_controller.params.has_attr('on_middle_click_item_callbacks'):\n",
    "        a_pagination_controller.params['on_middle_click_item_callbacks'] = {}    \n",
    "    a_pagination_controller.params.on_middle_click_item_callbacks['an_alt_clicked_epoch_callback'] = an_alt_clicked_epoch_callback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5fa30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "\n",
    "a_name = 'long_RL'\n",
    "a_pagination_controller = paginated_multi_decoder_decoded_epochs_window.pagination_controllers[a_name]\n",
    "a_controlled_widget = a_pagination_controller.ui.mw # MatplotlibTimeSynchronizedWidget\n",
    "\n",
    "thin_button_bar_widget: ThinButtonBarWidget = a_controlled_widget.ui.thin_button_bar_widget\n",
    "# thin_button_bar_widget.label_message = \"<controlled>\"\n",
    "# thin_button_bar_widget.txtLineEdit\n",
    "# thin_button_bar_widget.ui.txtLineEdit.setText('test')\n",
    "# thin_button_bar_widget.ui.txtLineEdit.text\n",
    "\n",
    "# thin_button_bar_widget.parent().update()\n",
    "# a_controlled_widget.update()\n",
    "# print_keys_if_possible('a_pagination_controller.ui', a_pagination_controller.ui, max_depth=2)\n",
    "# thin_button_bar_widget.label_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019fbe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: a_pagination_controller\n",
    "a_decoder_decoded_epochs_result: DecodedFilterEpochsResult = a_pagination_controller.plots_data.filter_epochs_decoder_result\n",
    "\n",
    "active_epoch_data_idx: int = 28\n",
    "print(f'active_epoch_data_idx: {active_epoch_data_idx}')\n",
    "active_captured_single_epoch_result: SingleEpochDecodedResult = a_decoder_decoded_epochs_result.get_result_for_epoch(active_epoch_idx=active_epoch_data_idx)\n",
    "active_captured_single_epoch_result\n",
    "\n",
    "## Outputs: active_captured_single_epoch_result\n",
    "\n",
    "# filter_epochs_decoder_result.filter_epochs\n",
    "# filter_epochs_decoder_result.p_x_given_n_list["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431df389",
   "metadata": {},
   "outputs": [],
   "source": [
    "included_page_data_indicies, (curr_page_active_filter_epochs, curr_page_epoch_labels, curr_page_time_bin_containers, curr_page_posterior_containers) = a_pagination_controller.plots_data.paginator.get_page_data(page_idx=a_pagination_controller.current_page_idx)\n",
    "\n",
    "# for i, curr_ax in enumerate(self.plots.axs):\n",
    "    \n",
    "curr_page_rel_idx: int = 0\n",
    "curr_slice_idx: int = included_page_data_indicies[curr_page_rel_idx]\n",
    "curr_epoch_slice = curr_page_active_filter_epochs[curr_page_rel_idx]\n",
    "curr_time_bin_container = curr_page_time_bin_containers[curr_page_rel_idx]\n",
    "curr_posterior_container = curr_page_posterior_containers[curr_page_rel_idx]\n",
    "curr_time_bins = curr_time_bin_container.centers\n",
    "curr_posterior = curr_posterior_container.p_x_given_n\n",
    "curr_most_likely_positions = curr_posterior_container.most_likely_positions_1D\n",
    "\n",
    "curr_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081fcc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_pagination_controller.get_total_pages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe4653",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a_name, a_pagination_controller) in enumerate(paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items()):\n",
    "    print(f'i: {i}, a_name: {a_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654374c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81780963",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.show_message(\"test message\", durationMs=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca820df",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.remove_data_overlays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289385ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6097ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get radon transform data:\n",
    "a_pagination_controller = pagination_controller_dict['long_LR']\n",
    "radon_transform_data = a_pagination_controller.plots_data['radon_transform_data']\n",
    "radon_transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30830fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120293e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_selections_dict = paginated_multi_decoder_decoded_epochs_window.save_selections()\n",
    "# paginated_multi_decoder_decoded_epochs_window.ui.print = print\n",
    "_annotations = paginated_multi_decoder_decoded_epochs_window.print_user_annotations()\n",
    "_annotations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d82308",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination_controller_dict['long_LR'].params.xbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f785638",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.remove_data_overlays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ee5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3435812",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.params.xbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd64912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show crosshair at cursor position\n",
    "plt.connect('motion_notify_event', lambda event: plt.gcf().gca().format_coord(event.xdata, event.ydata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c382b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5e9ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_keys_if_possible('paginated_multi_decoder_decoded_epochs_window', paginated_multi_decoder_decoded_epochs_window.ui, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a14372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.widgets.toast_notification_widget import ToastWidget, ToastShowingWidgetMixin\n",
    "# paginated_multi_decoder_decoded_epochs_window.ui._contents.windows\n",
    "\n",
    "for a_name, a_window in paginated_multi_decoder_decoded_epochs_window.ui._contents.windows.items():\n",
    "    message = 'This is a toast message!'\n",
    "    a_window.toast.show_message(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_epoch = np.array([1316.0564141790383, 1316.2703788694926])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1ff44",
   "metadata": {},
   "source": [
    "### Attached raster viewer widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c265cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import build_attached_raster_viewer_widget\n",
    "\n",
    "_out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=filtered_ripple_simple_pf_pearson_merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2865a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.export_decoder_pagination_controller_figure_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf5b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(_out_ripple_rasters) # RankOrderRastersDebugger\n",
    "# root_plots_dict: Dict[str, pg.PlotItem] = _out_ripple_rasters.root_plots_dict\n",
    "# root_plots_dict\n",
    "\n",
    "rasters_output_path = Path(r\"C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\PhoDibaPaper2024Book\\FIGURES\").resolve()\n",
    "assert rasters_output_path.exists()\n",
    "example_replay_output_folder = rasters_output_path.joinpath('example_replay_2').resolve()\n",
    "example_replay_output_folder.mkdir(parents=False, exist_ok=True)\n",
    "_out_ripple_rasters.save_figure(export_path=example_replay_output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f3ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625daf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = _out_ripple_rasters.ui.root_dockAreaWindow\n",
    "# win.setWindowTitle(f'Debug Directional Template Rasters <Controlled by DecodedEpochSlices window>')\n",
    "win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae668b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_ripple_rasters.setWindowTitle(f'Debug Directional Template Rasters <Controlled by DecodedEpochSlices window>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to set identical low and high xlims makes transformation singular; automatically expanding. Is this what is causing the white posteriors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ddc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window.pagination_controllers['long_LR'].params.posterior_heatmap_imshow_kwargs = dict(vmin=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23369f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# paginated_multi_decoder_decoded_epochs_window.update_params(posterior_heatmap_imshow_kwargs = dict(vmin=0.0))\n",
    "\n",
    "paginated_multi_decoder_decoded_epochs_window.update_params(enable_per_epoch_action_buttons=True)\n",
    "paginated_multi_decoder_decoded_epochs_window.refresh_current_page()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.get_children_props('params')\n",
    "# paginated_multi_decoder_decoded_epochs_window.get_children_props('plots')\n",
    "# paginated_multi_decoder_decoded_epochs_window.get_children_props('plots.fig')\n",
    "paginated_multi_decoder_decoded_epochs_window.get_children_props('plots.fig')\n",
    "# paginated_multi_decoder_decoded_epochs_window.get_children_props('params.posterior_heatmap_imshow_kwargs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ca528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window# AttributeError: 'PhoPaginatedMultiDecoderDecodedEpochsWindow' object has no attribute 'params'\n",
    "\n",
    "paginated_multi_decoder_decoded_epochs_window.pagination_controllers['long_LR'].params.should_suppress_callback_exceptions = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a19394",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.jump_to_page(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea69a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f136d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2150f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    # v.params.enable_radon_transform_info = False\n",
    "    # v.params.enable_weighted_correlation_info = False\n",
    "    v._subfn_clear_selectability_rects()\n",
    "    \n",
    "# paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_ctrlr in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    a_ctrlr.perform_update_selections(defer_render=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009775d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with Ctx(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [[785.7379401021171, 785.9232737672282]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [[427.4610240198672, 427.55720829055645]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [[833.3391086903866, 833.4508065531263]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [[491.7975491596153, 492.17844624456484], [940.0164351915009, 940.2191870877286]]\n",
    "\n",
    "# with Ctx(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [array([785.738, 785.923])]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [array([427.461, 427.557])]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [array([833.339, 833.451])]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [array([491.798, 492.178]), array([940.016, 940.219])]\n",
    "\n",
    "# with Ctx(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [[785.7379401021171, 785.9232737672282]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [[427.4610240198672, 427.55720829055645]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [[833.3391086903866, 833.4508065531263]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [[491.7975491596153, 492.17844624456484], [940.0164351915009, 940.2191870877286]]\n",
    "\n",
    "# with Ctx(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [[208.356, 208.523], [693.842, 693.975], [954.574, 954.679]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [[224.037, 224.312]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [[145.776, 146.022], [198.220, 198.582], [220.041, 220.259], [511.570, 511.874], [865.238, 865.373]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [[191.817, 192.100], [323.147, 323.297]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-paginated_multi_decoder_decoded_epochs_window_page.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    paginated_multi_decoder_decoded_epochs_window.jump_to_page(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f513296",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.jump_to_page(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98478063",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.get_decoder_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec6078",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    # v.params.enable_radon_transform_info = False\n",
    "    # v.params.enable_weighted_correlation_info = False\n",
    "    v.params.enable_radon_transform_info = True\n",
    "    v.params.enable_weighted_correlation_info = True\n",
    "    v.params.debug_enabled = True\n",
    "\n",
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    print(f'decoder[{k}]:')\n",
    "    v.params.name\n",
    "    # v.params.on_render_page_callbacks\n",
    "    # v.params.enable_radon_transform_info\n",
    "    len(v.plots_data.radon_transform_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ff3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7cc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b447b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.refresh_current_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec3540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sub_subfn_wrapped_in_brackets(s: str, bracket_strings = (\"[\", \"]\")) -> str:\n",
    "        return bracket_strings[0] + s + bracket_strings[1]\n",
    "    \n",
    "def _sub_subfn_format_nested_list(arr, precision:int=3, num_sep=\", \", array_sep=', ') -> str:\n",
    "    \"\"\"\n",
    "    Converts a nested list of floats into a single string,\n",
    "    with each float formatted to the specified precision.\n",
    "    \n",
    "    arr = np.array([[491.798, 492.178], [940.016, 940.219]])\n",
    "    _sub_subfn_format_nested_list(arr)\n",
    "\n",
    "    >> '[[491.798, 492.178], [940.016, 940.219]]'\n",
    "\n",
    "    arr = np.array([[785.738, 785.923]])\n",
    "    _sub_subfn_format_nested_list(arr)\n",
    "    >> '[[785.738, 785.923]]'\n",
    "    \"\"\"\n",
    "    return _sub_subfn_wrapped_in_brackets(array_sep.join([_sub_subfn_wrapped_in_brackets(num_sep.join([f\"{num:.{precision}f}\" for num in row])) for row in arr]))\n",
    "    \n",
    "# arr = np.array([[491.798, 492.178], [940.016, 940.219]])\n",
    "arr = np.array([[785.738, 785.923]])\n",
    "_sub_subfn_format_nested_list(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f0ab5d",
   "metadata": {},
   "source": [
    "### 2024-02-29 3pm - Get the active user-annotated epoch times from the `paginated_multi_decoder_decoded_epochs_window` and use these to filter `filtered_ripple_simple_pf_pearson_merged_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c982e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inputs: paginated_multi_decoder_decoded_epochs_window, filtered_ripple_simple_pf_pearson_merged_df\n",
    "any_good_selected_epoch_times = deepcopy(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times)\n",
    "any_good_selected_epoch_indicies = deepcopy(paginated_multi_decoder_decoded_epochs_window.find_data_indicies_from_epoch_times(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1f903",
   "metadata": {},
   "source": [
    "## 🔶 2024-03-01 - Get the active user-annotated epoch times from the `UserAnnotationsManager` and use these to filter `filtered_ripple_simple_pf_pearson_merged_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc751d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.misc import numpyify_array\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.epoch import EpochsAccessor\n",
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "## Get from UserAnnotations directly instead of the intermediate viewer\n",
    "\n",
    "## # inputs: any_good_selected_epoch_times, any_good_selected_epoch_times, any_good_selected_epoch_indicies \n",
    "\n",
    "decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline, track_templates=track_templates)\n",
    "# any_good_selected_epoch_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(any_good_selected_epoch_times)\n",
    "# any_good_selected_epoch_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.find_data_indicies_from_epoch_times(any_good_selected_epoch_times)\n",
    "# any_good_selected_epoch_indicies\n",
    "# Add user-selection columns to df\n",
    "a_df = deepcopy(filtered_ripple_simple_pf_pearson_merged_df)\n",
    "# a_df = deepcopy(ripple_weighted_corr_merged_df)\n",
    "a_df['is_user_annotated_epoch'] = False\n",
    "# any_good_selected_epoch_indicies = a_df.epochs.find_data_indicies_from_epoch_times(any_good_selected_epoch_times)\n",
    "any_good_selected_epoch_indicies = find_data_indicies_from_epoch_times(a_df, np.squeeze(any_good_selected_epoch_times[:,0]), t_column_names=['ripple_start_t',])\n",
    "# any_good_selected_epoch_indicies = find_data_indicies_from_epoch_times(a_df, any_good_selected_epoch_times, t_column_names=['ripple_start_t',])\n",
    "any_good_selected_epoch_indicies\n",
    "# a_df['is_user_annotated_epoch'] = np.isin(a_df.index.to_numpy(), any_good_selected_epoch_indicies)\n",
    "a_df['is_user_annotated_epoch'].loc[any_good_selected_epoch_indicies] = True # Here's another .iloc issue! Changing to .loc\n",
    "a_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DecoderDecodedEpochsResult.filter_epochs_dfs_by_annotation_times(curr_active_pipeline, any_good_selected_epoch_times, ripple_decoding_time_bin_size, filtered_ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dee7b3",
   "metadata": {},
   "source": [
    "### 2024-02-29 - 4pm - Filter the events for those meeting wcorr criteria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed7e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_wcorr_threshold: float = 0.33\n",
    "min_wcorr_diff_threshold: float = 0.2\n",
    "\n",
    "is_included_large_wcorr_diff = np.any((df[['wcorr_abs_diff']].abs() > min_wcorr_diff_threshold), axis=1)\n",
    "is_included_high_wcorr = np.any((df[['long_best_wcorr', 'short_best_wcorr']].abs() > min_wcorr_threshold), axis=1)\n",
    "\n",
    "df = df[is_included_high_wcorr]\n",
    "df\n",
    "\n",
    "# delta_aligned_start_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fc554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifts the absolute times to delta-relative values, as would be needed to draw on a 'delta_aligned_start_t' axis:\n",
    "delta_relative_t_start, delta_relative_t_delta, delta_relative_t_end = np.array([earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end]) - t_delta\n",
    "delta_relative_t_start, delta_relative_t_delta, delta_relative_t_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['_wcorr_y_col'] = df['long_best_wcorr'].abs()\n",
    "df['_wcorr_y_col_y_diff_col'] = df['long_best_wcorr'].abs() - df['short_best_wcorr'].abs()\n",
    "# df.plot.scatter(x='ripple_start_t', y='wcorr_y_col')\n",
    "df.plot.scatter(x='delta_aligned_start_t', y='_wcorr_y_col_y_diff_col')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5438dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['pearsonr_long_abs'] = df['long_best_pf_peak_x_pearsonr'].abs()\n",
    "# df['pearsonr_short_abs'] = df['short_best_pf_peak_x_pearsonr'].abs()\n",
    "# df['pearsonr_diff'] = df['long_best_pf_peak_x_pearsonr'].abs() - df['short_best_pf_peak_x_pearsonr'].abs()\n",
    "\n",
    "# df.plot.scatter(x='delta_aligned_start_t', y='pearsonr_long_abs')\n",
    "# df.plot.scatter(x='delta_aligned_start_t', y='pearsonr_short_abs')\n",
    "df.plot.scatter(x='delta_aligned_start_t', y='pearsonr_abs_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f951c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271d716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02556ea",
   "metadata": {},
   "source": [
    "### Add utility footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3888f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, get_utility_dock_colors\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "\n",
    "\n",
    "def _add_utility_footer(paginated_multi_decoder_decoded_epochs_window):\n",
    "    ui = paginated_multi_decoder_decoded_epochs_window.ui._contents\n",
    "    # ui.dock_widgets\n",
    "    # ui.dock_configs\n",
    "\n",
    "\n",
    "    ## Build the utility controls at the bottom:\n",
    "    ctrls_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=get_utility_dock_colors, showCloseButton=True, orientation='horizontal')\n",
    "\n",
    "    button_bar_height = 21\n",
    "    ctrls_button_bar_widget = ThinButtonBarWidget()\n",
    "    ctrls_button_bar_widget.setObjectName(\"ctrls_button_bar\")\n",
    "    # Set the background color to blue with 40% opacity (RGBA)\n",
    "    ctrls_button_bar_widget.setStyleSheet(\"background-color: rgba(0, 0, 255, 102);\")\n",
    "\n",
    "    ctrl_layout = pg.LayoutWidget()\n",
    "    ctrl_layout.addWidget(ctrls_button_bar_widget, row=1, rowspan=1, col=1, colspan=2)\n",
    "    ctrl_widgets_dict = dict(ctrls_widget=ctrls_button_bar_widget)\n",
    "    # Set the background color to green with 40% opacity (RGBA)\n",
    "    ctrl_layout.setStyleSheet(\"background-color: rgba(0, 255, 10, 102);\")\n",
    "\n",
    "    # ctrl_layout.setSizePolicy(\n",
    "\n",
    "    def onCopySelectionsClicked():\n",
    "        print(f'onCopySelectionsClicked()')\n",
    "        saved_selections_contexts_dict = paginated_multi_decoder_decoded_epochs_window.print_user_annotations()\n",
    "\n",
    "    ctrl_widgets_dict['copy_selection_connection'] = ctrls_button_bar_widget.sigCopySelections.connect(onCopySelectionsClicked)\n",
    "\n",
    "    ui.dock_widgets['bottom_controls'] = paginated_multi_decoder_decoded_epochs_window.add_display_dock(identifier='bottom_controls', widget=ctrl_layout, dockSize=(600, button_bar_height), dockAddLocationOpts=['bottom'], display_config=ctrls_dock_config, autoOrientation=False)\n",
    "    # ui.dock_widgets['bottom_controls'][1].hideTitleBar()\n",
    "    ui.dock_widgets['bottom_controls']\n",
    "\n",
    "    button_bar_height = 21\n",
    "\n",
    "    a_layout = ui.dock_widgets['bottom_controls'][0]\n",
    "    a_layout.size()\n",
    "    a_layout.setContentsMargins(0,0,0,0)\n",
    "    a_layout.setFixedHeight(21)\n",
    "    ui.dock_widgets['bottom_controls'][1].size()\n",
    "    ui.dock_widgets['bottom_controls'][1].setContentsMargins(0,0,0,0)\n",
    "    ui.dock_widgets['bottom_controls'][1].setStyleSheet(\"background-color: rgba(255, 10, 10, 102);\") # RED\n",
    "\n",
    "    # ui.dock_widgets['bottom_controls'][1].hideTitleBar()\n",
    "    # ui.dock_widgets['bottom_controls'][1].size\n",
    "\n",
    "    return ctrl_layout, ctrls_dock_config, ui\n",
    "\n",
    "\n",
    "ctrl_layout, ctrls_dock_config, ui = _add_utility_footer(paginated_multi_decoder_decoded_epochs_window=new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd6823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window=new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window\n",
    "ui = paginated_multi_decoder_decoded_epochs_window.ui._contents\n",
    "\n",
    "layout_widget, dock_item = ui.dock_widgets['bottom_controls']\n",
    "layout_widget.size()\n",
    "# Set the background color to light grey\n",
    "layout_widget.setStyleSheet(\"background-color: red;\")\n",
    "\n",
    "# layout_widget.setBackgroundColor('black')\n",
    "layout_widget.setAutoFillBackground(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3add584",
   "metadata": {},
   "outputs": [],
   "source": [
    " ui.dock_widgets['bottom_controls'][1].size()\n",
    " ui.dock_widgets['bottom_controls'][1].setFixedHeight(21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b47e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.dock_widgets['bottom_controls'][1].children()\n",
    "# [<pyphoplacecellanalysis.External.pyqtgraph.dockarea.DockDrop.DropAreaOverlay object at 0x00000175C7D24820>,\n",
    "#  <PyQt5.QtWidgets.QGridLayout object at 0x00000175C7D248B0>,\n",
    "#  <pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock.DockLabel object at 0x00000175C7D24E50>,\n",
    "#  <PyQt5.QtWidgets.QWidget object at 0x00000175C7D245E0>,\n",
    "#  <pyphoplacecellanalysis.External.pyqtgraph.dockarea.DockDrop.DropAreaOverlay object at 0x00000175C7D24B80>]\n",
    "\n",
    "ui.dock_widgets['bottom_controls'][1].layout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_item.showTitleBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_item.setOrientation('horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17726a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_item.setContentsMargins(0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d91d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_widget.setContentsMargins(0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.dock_widgets['bottom_controls'][0].resize(600, 21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39be52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.find_display_dock('bottom_controls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.remove_display_dock('bottom_controls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "\n",
    "## Set epoch annotations from selections epochs \n",
    "annotations_man = UserAnnotationsManager()\n",
    "user_annotations = annotations_man.get_user_annotations()\n",
    "new_selections_dict = paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations(user_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf471332",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_selections_objs_dict = {a_name:EpochSelectionsObject(epoch_times=a_selections_values) for a_name, a_selections_values in loaded_selections_dict.items()}\n",
    "loaded_selections_objs_dict\n",
    "\n",
    "## Select just the selected epoch times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_selections_context_dict = {a_name:v.figure_ctx.adding_context_if_missing(user_annotation='selections') for a_name, v in saved_selections_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d312d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.print_user_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ee6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the excessively long plot titles?\n",
    "# root_dockAreaWindow.update\n",
    "pagination_controller_dict = paginated_multi_decoder_decoded_epochs_window.pagination_controllers\n",
    "all_widgets = {a_decoder_name:a_pagination_controller.ui.mw for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_windows = {a_decoder_name:a_pagination_controller.ui.mw.window() for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_plots = {a_decoder_name:a_pagination_controller.plots for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_plots_data = {a_decoder_name:a_pagination_controller.plots_data for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_params = {a_decoder_name:a_pagination_controller.params for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_current_page_idx = {a_decoder_name:a_pagination_controller.current_page_idx for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_current_page_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cfebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_separate_plots\n",
    "\n",
    "all_separate_weighted_corr_plots = {a_decoder_name:a_pagination_controller.plots.get('weighted_corr', {}) for a_decoder_name, a_pagination_controller in pagination_controller_dict.items()}\n",
    "all_separate_weighted_corr_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.ui.print = self.private_print # builtins.print # the print function to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69313c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import EpochsAccessor\n",
    "\n",
    "# MLM\n",
    "# {a_name:a_ctrlr.params.is_selected for a_name, a_ctrlr in root_dockAreaWindow.pagination_controllers.items()}\n",
    "# {a_name:a_ctrlr.selected_epoch_times for a_name, a_ctrlr in root_dockAreaWindow.pagination_controllers.items()}\n",
    "\n",
    "any_good_selected_epoch_times: NDArray = paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times # drops duplicate rows (present in multiple decoders), and sorts them ascending\n",
    "# any_good_selected_epoch_times\n",
    "# Only at the decoder-level\n",
    "any_good_epoch_idxs_list = [a_ctrlr.find_data_indicies_from_epoch_times(any_good_selected_epoch_times) for a_name, a_ctrlr in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items()]\n",
    "any_good_epoch_idxs: NDArray = any_good_epoch_idxs_list[0]\n",
    "any_good_epoch_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29282203",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531db971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filtered_ripple_simple_pf_pearson_merged_df.epochs.find_data_indicies_from_epoch_times(any_good_selected_epoch_times)\n",
    "# filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(any_good_selected_epoch_times)\n",
    "\n",
    "found_data_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.find_data_indicies_from_epoch_times(epoch_times=any_good_selected_epoch_times)\n",
    "df = filtered_ripple_simple_pf_pearson_merged_df.epochs._obj.iloc[found_data_indicies].copy().reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a78ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ripple_simple_pf_pearson_merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1677479",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_selected_ripple_simple_pf_pearson_merged_df = filtered_ripple_simple_pf_pearson_merged_df.iloc[any_good_epoch_idxs, :].reset_index(drop=True)\n",
    "hand_selected_ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d400bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand_selected_ripple_simple_pf_pearson_merged_df['best_decoder_index']\n",
    "\n",
    "is_most_likely_long = (hand_selected_ripple_simple_pf_pearson_merged_df['P_Long'] >= 0.5)\n",
    "# is_most_likely_long\n",
    "\n",
    "long_likely_hand_selected_ripple_simple_pf_pearson_merged_df = hand_selected_ripple_simple_pf_pearson_merged_df[is_most_likely_long]\n",
    "long_likely_hand_selected_ripple_simple_pf_pearson_merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d33190",
   "metadata": {},
   "source": [
    "## 🖼️🎨 Plot laps to compare between decoders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4873ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import add_laps_groundtruth_information_to_dataframe\n",
    "\n",
    "# decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs # looks like 'lap_dir' column is wrong\n",
    "updated_laps_dfs_dict = {}\n",
    "\n",
    "## Update the .filter_epochs:\n",
    "for k, v in decoder_laps_filter_epochs_decoder_result_dict.items():\n",
    "    updated_laps_dfs_dict[k] = Epoch(add_laps_groundtruth_information_to_dataframe(curr_active_pipeline=curr_active_pipeline, result_laps_epochs_df=ensure_dataframe(v.filter_epochs)))\n",
    "    decoder_laps_filter_epochs_decoder_result_dict[k].filter_epochs =  updated_laps_dfs_dict[k]\n",
    "\n",
    "# updated_laps_dfs_dict['long_LR']\n",
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_app, laps_paginated_multi_decoder_decoded_epochs_window, laps_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                            decoder_decoded_epochs_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epochs_name='laps', included_epoch_indicies=None, \n",
    "    params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': False, \n",
    "    # 'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': True, 'enable_weighted_correlation_info': False,\n",
    "    'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': True, 'enable_weighted_correlation_info': True,\n",
    "    # 'disable_y_label': True,\n",
    "    # 'isPaginatorControlWidgetBackedMode': True,\n",
    "    # 'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "    # 'debug_print': True,\n",
    "    'max_subplots_per_page': 10,\n",
    "    'scrollable_figure': True,\n",
    "    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "    'use_AnchoredCustomText': False,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec05d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "\n",
    "## INPUTS: decoder_laps_filter_epochs_decoder_result_dict\n",
    "\n",
    "## Highlight the correct ones:\n",
    "# {k:Epoch(add_laps_groundtruth_information_to_dataframe(curr_active_pipeline=curr_active_pipeline, result_laps_epochs_df=ensure_dataframe(v.filter_epochs))) for k, v in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "\n",
    "## Select the true laps by emulating user_annotations:\n",
    "filter_epochs = ensure_dataframe(deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)) \n",
    "# filter_epochs\n",
    "\n",
    "decoder_name_idx_map = {'long_LR': 0, 'long_RL': 1, 'short_LR': 2, 'short_RL': 3} \n",
    "selections_dict = {}\n",
    "figure_ctx_dict = laps_paginated_multi_decoder_decoded_epochs_window.figure_ctx_dict\n",
    "loaded_selections_context_dict = {a_name:a_figure_ctx.adding_context_if_missing(user_annotation='selections') for a_name, a_figure_ctx in figure_ctx_dict.items()}\n",
    "\n",
    "for a_name, an_idx in decoder_name_idx_map.items():\n",
    "    a_selections_context = loaded_selections_context_dict[a_name]\n",
    "    selections_dict[a_selections_context] = filter_epochs[filter_epochs['true_decoder_index'] == an_idx][['start', 'stop']].to_numpy()\n",
    "\n",
    "\n",
    "## Clearing the existing selection rects and them having them rebuilt when the selection is updated fixes them being shifted.\n",
    "for k, v in laps_pagination_controller_dict.items():\n",
    "    v._subfn_clear_selectability_rects()\n",
    "\n",
    "# _tmp_out_selections = laps_paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations(user_annotations=selections_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6607cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e364cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.remove_data_overlays(defer_refresh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.remov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clearing the existing selection rects and them having them rebuilt when the selection is updated fixes them being shifted.\n",
    "for k, v in laps_pagination_controller_dict.items():\n",
    "    v._subfn_clear_selectability_rects()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5675f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b603bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f847f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1556870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(decoder_laps_filter_epochs_decoder_result_dict.keys())\n",
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the figure from the axes:\n",
    "a_fig = ax.get_figure()\n",
    "a_fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_controlling_pagination_controller = laps_paginated_multi_decoder_decoded_epochs_window.contents.pagination_controllers['long_LR'] # DecodedEpochSlicesPaginatedFigureController\n",
    "a_pagination_controller_figure_widget = paginator_controller_widget = a_controlling_pagination_controller.ui.mw # MatplotlibTimeSynchronizedWidget\n",
    "paginator_controller_widget = a_controlling_pagination_controller.ui.mw.ui.paginator_controller_widget # PaginationControlWidget\n",
    "# paginator_controller_widget\n",
    "a_pagination_controller_figure_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92048bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = a_controlling_pagination_controller.plots.axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_figure().canvas.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47481538",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_rectangles_dict = a_controlling_pagination_controller.plots.get('selection_rectangles_dict', None)\n",
    "selection_rectangles_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa452e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_controlling_pagination_controller.plots.fig.canvas.draw_idle()\n",
    "# a_controlling_pagination_controller.plots.fig.canvas.draw()\n",
    "# paginator_controller_widget.update()\n",
    "a_pagination_controller_figure_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72db1753",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator_controller_widget.go_to_page(3)\n",
    "# paginator_controller_widget.jump_to_page(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635fbe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_controlling_pagination_controller.ui.mw.ui.paginator_controller_widget.jump_to_page\n",
    "\n",
    "new_obj.plots_data.paginator\n",
    "new_obj.params.active_identifying_figure_ctx\n",
    "new_obj.on_paginator_control_widget_jump_to_page(page_idx=0)\n",
    "new_obj.ui.connections['paginator_controller_widget_jump_to_page']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c54dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, extant_plots in a_plots['weighted_corr'].items():\n",
    "    extant_wcorr_text = extant_plots.get('wcorr_text', None)\n",
    "    # extant_wcorr_text = extant_plots.pop('wcorr_text', None)\n",
    "    print(f'extant_wcorr_text: {extant_wcorr_text}')\n",
    "    # plot the radon transform line on the epoch:\n",
    "    if (extant_wcorr_text is not None):\n",
    "        # already exists, clear the existing ones. \n",
    "        # Let's assume we want to remove the 'Quadratic' line (line2)\n",
    "        print(f'removing extant text object at index: {i}.')\n",
    "        # extant_wcorr_text.remove()\n",
    "        extant_wcorr_text.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b7e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_pagination_controller in pagination_controller_dict.items():\n",
    "    display_context = a_pagination_controller.params.get('active_identifying_figure_ctx', IdentifyingContext())\n",
    "\n",
    "    # Get context for current page of items:\n",
    "    current_page_idx: int = int(a_pagination_controller.current_page_idx)\n",
    "    a_paginator = a_pagination_controller.paginator\n",
    "    total_num_pages = int(a_paginator.num_pages)\n",
    "    page_context = display_context.overwriting_context(page=current_page_idx, num_pages=total_num_pages)\n",
    "    print(page_context)\n",
    "\n",
    "    ## Get the figure/axes:\n",
    "    a_plots = a_pagination_controller.plots # RenderPlots\n",
    "    a_plot_data = a_pagination_controller.plots_data\n",
    "\n",
    "    a_params = a_pagination_controller.params\n",
    "    a_params.skip_plotting_measured_positions\n",
    "\n",
    "    figs = a_plots.fig\n",
    "    axs = a_plots.axs\n",
    "\n",
    "    # # with mpl.rc_context({'figure.figsize': (8.4, 4.8), 'figure.dpi': '220', 'savefig.transparent': True, 'ps.fonttype': 42, }):\n",
    "    # with mpl.rc_context({'figure.figsize': (16.8, 4.8), 'figure.dpi': '420', 'savefig.transparent': True, 'ps.fonttype': 42, }):\n",
    "    #     curr_active_pipeline.output_figure(final_context=page_context, fig=figs, write_vector_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d32342",
   "metadata": {},
   "source": [
    "## 💾 Export Paginated Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.export_all_pages(curr_active_pipeline)\n",
    "# paginated_multi_decoder_decoded_epochs_window.export_all_pages(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be8a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.export_decoder_pagination_controller_figure_page(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd2637",
   "metadata": {},
   "source": [
    "## 🔷🎨 Single Decoder Version (`DecodedEpochSlicesPaginatedFigureController`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d880d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import _subfn_update_decoded_epoch_slices\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController # `plot_decoded_epoch_slices_paginated`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import WeightedCorrelationPaginatedPlotDataProvider\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import DecodedPositionsPlotDataProvider, DecodedAndActualPositionsPlotData\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import perform_plot_1D_single_most_likely_position_curve\n",
    "\n",
    "# Inputs: epochs_name, decoder_ripple_filter_epochs_decoder_result_dict, curr_active_pipeline\n",
    "# epochs_name = 'ripple'\n",
    "epochs_name = 'laps'\n",
    "\n",
    "(a_name, a_decoder) = tuple(track_templates.get_decoders_dict().items())[0]\n",
    "\n",
    "# a_decoder_decoded_epochs_result = decoder_ripple_filter_epochs_decoder_result_dict[a_name]\n",
    "\n",
    "# a_decoder_decoded_epochs_result = decoder_ripple_filter_epochs_decoder_result_dict[a_name]\n",
    "a_decoder_decoded_epochs_result = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict[a_name]) ## FILTERED\n",
    "\n",
    "_out_pagination_controller = DecodedEpochSlicesPaginatedFigureController.init_from_decoder_data(active_filter_epochs=a_decoder_decoded_epochs_result.filter_epochs,\n",
    "                                                                                    filter_epochs_decoder_result= a_decoder_decoded_epochs_result,\n",
    "                                                                                    xbin=a_decoder.xbin, global_pos_df=curr_active_pipeline.sess.position.df,\n",
    "                                                                                    a_name=f'DecodedEpochSlices[{a_name}]', active_context=curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs=epochs_name, decoder=a_name),\n",
    "                                                                                    max_subplots_per_page=32,\n",
    "                                                                                    params_kwargs={'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, 'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': True, #'enable_radon_transform_info': True, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    'enable_radon_transform_info': True, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 32,\n",
    "                                                                                                    'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': True,\n",
    "                                                                                                    'disable_toolbar': False,\n",
    "                                                                                                    # 'build_fn': 'insets_view',\n",
    "                                                                                    }, \n",
    "                                                                                    # disable_toolbar=False\n",
    "                                                                                    )\n",
    "\n",
    "_out_pagination_controller.params.should_suppress_callback_exceptions = False\n",
    "_out_pagination_controller.add_data_overlays(a_decoder_decoded_epochs_result)\n",
    "_tmp_out_selections = _out_pagination_controller.restore_selections_from_user_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c780e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = _out_pagination_controller.plots.fig\n",
    "# fig.toolbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f46ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(_out_pagination_controller)\n",
    "\n",
    "_out_pagination_controller.plot_widget._buildUI_setup_statusbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff74414",
   "metadata": {},
   "source": [
    "single_epoch_field_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e429a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on_selected_epochs_changed\n",
    "\n",
    "active_captured_single_epoch_result: SingleEpochDecodedResult = a_decoder_decoded_epochs_result.get_result_for_epoch(active_epoch_idx=3)\n",
    "\n",
    "def get_selected_posterior_on_secondary_clicked_callback(self, event, clicked_ax, clicked_data_index, clicked_epoch_is_selected, clicked_epoch_start_stop_time):\n",
    "    \"\"\" called when the user alt-clicks an epoch \n",
    "    \n",
    "    captures: active_captured_single_epoch_result\n",
    "    \"\"\"\n",
    "    global active_captured_single_epoch_result\n",
    "    if self.params.debug_print:\n",
    "        print(f'get_selected_posterior_on_secondary_clicked_callback(clicked_data_index: {clicked_data_index}, clicked_epoch_is_selected: {clicked_epoch_is_selected}, clicked_epoch_start_stop_time: {clicked_epoch_start_stop_time})')\n",
    "    if clicked_epoch_start_stop_time is not None:\n",
    "        if len(clicked_epoch_start_stop_time) == 2:\n",
    "            start_t, end_t = clicked_epoch_start_stop_time\n",
    "            # print(f'start_t: {start_t}')\n",
    "            clicked_data_index: int = _out_pagination_controller.find_data_indicies_from_epoch_times(epoch_times=np.array([start_t, end_t]))[0]\n",
    "            if self.params.debug_print:\n",
    "                print(f'\\tclicked_data_index: {clicked_data_index}')            \n",
    "            active_captured_single_epoch_result = a_decoder_decoded_epochs_result.get_result_for_epoch(active_epoch_idx=clicked_data_index)\n",
    "            if self.params.debug_print:\n",
    "                print(f'\\tactive_captured_single_epoch_result.epoch_info_tuple: {active_captured_single_epoch_result.epoch_info_tuple}')\n",
    "                print(f'\\tdone.')\n",
    "\n",
    "\n",
    "# BEGIN FUNCTION BODY ________________________________________________________________________________________________ #\n",
    "if not _out_pagination_controller.params.has_attr('on_middle_click_item_callbacks'):\n",
    "    _out_pagination_controller.params['on_middle_click_item_callbacks'] = {}\n",
    "\n",
    "_out_pagination_controller.params.on_middle_click_item_callbacks['get_selected_posterior_on_secondary_clicked_callback'] = get_selected_posterior_on_secondary_clicked_callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoder_decoded_epochs_result.active_filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a619872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import get_array_as_image\n",
    "\n",
    "posterior_image = active_captured_single_epoch_result.get_posterior_as_image(desired_width=2048)\n",
    "posterior_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "{i:col for i, col in enumerate(a_decoder_decoded_epochs_result.active_filter_epochs.columns)}\n",
    "\n",
    "column_indicies = np.arange(12, 19)\n",
    "column_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b8451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_pagination_controller.params.debug_print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc81f8",
   "metadata": {},
   "source": [
    "## 2024-04-30 Heuristic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21abb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *position_relative\": mapped between the ends of the track, 0.0 to 1.0\n",
    "most_likely_position_relative = (np.squeeze(active_captured_single_epoch_result.most_likely_position_indicies) / float(active_captured_single_epoch_result.n_xbins-1))\n",
    "most_likely_position_relative\n",
    "\n",
    "\n",
    "plt.hlines([0], colors='k', xmin=active_captured_single_epoch_result.time_bin_edges[0], xmax=active_captured_single_epoch_result.time_bin_edges[-1])\n",
    "plt.step(active_captured_single_epoch_result.time_bin_container.centers[1:], np.diff(most_likely_position_relative))\n",
    "plt.scatter(active_captured_single_epoch_result.time_bin_container.centers, most_likely_position_relative, color='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c52d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.Qt import QtGui, QtCore, QtWidgets\n",
    "# from pyphoplacecellanalysis.External.pyqtgraph.parametertree.parameterTypes.file import popupFilePicker\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.widgets.FileDialog import FileDialog\n",
    "\n",
    "from silx.gui import qt\n",
    "from silx.gui.dialog.ImageFileDialog import ImageFileDialog\n",
    "from silx.gui.dialog.DataFileDialog import DataFileDialog\n",
    "import silx.io\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import saveFile\n",
    "\n",
    "app = pg.mkQApp('silx_testing')\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc644214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from silx.gui.plot import Plot2D\n",
    "\n",
    "matrix = np.random.rand(10, 10)  # Example 2D matrix\n",
    "plot = Plot2D()\n",
    "plot.addImage(matrix, colormap=\"viridis\", vmin=0, vmax=1)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "\n",
    "HeuristicReplayScoring.bin_wise_track_coverage_score_fn(a_result=a_decoder_decoded_epochs_result, an_epoch_idx=active_captured_single_epoch_result.epoch_data_index, a_decoder_track_length=170.0)\n",
    "\n",
    "# np.diff(active_captured_single_epoch_result.most_likely_position_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = _out_pagination_controller.plots.axs[0]\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d52d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.format_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f28b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ascending sequences of most-likely positions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def format_coord(x, y):\n",
    "    col = round(x)\n",
    "    row = round(y)\n",
    "    nrows, ncols = X.shape\n",
    "    if 0 <= col < ncols and 0 <= row < nrows:\n",
    "        z = X[row, col]\n",
    "        return f'x={x:1.4f}, y={y:1.4f}, z={z:1.4f}'\n",
    "    else:\n",
    "        return f'x={x:1.4f}, y={y:1.4f}'\n",
    "\n",
    "\n",
    "ax.format_coord = format_coord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de603c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_pagination_controller.plot_widget.setStatusTip('LONG STATUS TIP TEST')\n",
    "\n",
    "_out_pagination_controller.plot_widget.update_status('LONG STATUS TIP TEST')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b187c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_pagination_controller.plots.radon_transform\n",
    "fig = _out_pagination_controller.plots.fig\n",
    "\n",
    "# plt.subplots_adjust(left=0.15, right=0.85, top=0.9, bottom=0.1)\n",
    "# Adjust the margins using subplots_adjust\n",
    "fig.subplots_adjust(left=0.15, right=0.85, bottom=0.15, top=0.85)\n",
    "\n",
    "# Adjust the margins using the Figure object\n",
    "# fig.set_tight_layout(dict(rect=[0.1, 0.2, 0.8, 0.8]))\n",
    "# fig.tight_layout(dict(rect=[0.1, 0.2, 0.8, 0.8]))\n",
    "# fig.tight_layout(pad=1.0, rect=[0.1, 0.1, 0.8, 0.8])\n",
    "_out_pagination_controller.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9643ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a_name, a_decoder) = tuple(track_templates.get_decoders_dict().items())[0]\n",
    "a_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d1a25",
   "metadata": {},
   "source": [
    "## 🔷🎨 2024-03-06 - Uni Page Scrollable Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "single_page_app, single_page_paginated_multi_decoder_decoded_epochs_window, single_page_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                                                                                                decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                included_epoch_indicies=None, debug_print=False,\n",
    "                                                                                                params_kwargs={'skip_plotting_most_likely_positions': False, 'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                               'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                                # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                                # 'disable_y_label': True,\n",
    "                                                                                                                'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                                'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                                # 'debug_print': True,\n",
    "                                                                                                                'max_subplots_per_page': 64,\n",
    "                                                                                                                'scrollable_figure': True,\n",
    "                                                                                                                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2565e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_page_paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "_tmp_out_selections = single_page_paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90abee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for curr_results_obj: LeaveOneOutDecodingAnalysisResult object\n",
    "num_filter_epochs:int = curr_results_obj.active_filter_epochs.n_epochs\n",
    "\n",
    "# `active_filter_epochs_df` native columns approach\n",
    "active_filter_epochs_df = curr_results_obj.active_filter_epochs.to_dataframe().copy()\n",
    "assert np.isin(['score', 'velocity', 'intercept', 'speed'], active_filter_epochs_df.columns).all()\n",
    "epochs_linear_fit_df = active_filter_epochs_df[['score', 'velocity', 'intercept', 'speed']].copy() # get the `epochs_linear_fit_df` as a subset of the filter epochs df\n",
    "# epochs_linear_fit_df approach\n",
    "assert curr_results_obj.all_included_filter_epochs_decoder_result.num_filter_epochs == np.shape(epochs_linear_fit_df)[0]\n",
    "\n",
    "num_filter_epochs:int = curr_results_obj.all_included_filter_epochs_decoder_result.num_filter_epochs # curr_results_obj.num_filter_epochs\n",
    "try:\n",
    "    time_bin_containers: List[BinningContainer] = deepcopy(curr_results_obj.time_bin_containers)\n",
    "except AttributeError as e:\n",
    "    # AttributeError: 'LeaveOneOutDecodingAnalysisResult' object has no attribute 'time_bin_containers' is expected when `curr_results_obj: LeaveOneOutDecodingAnalysisResult - for Long/Short plotting`\n",
    "    time_bin_containers: List[BinningContainer] = deepcopy(curr_results_obj.all_included_filter_epochs_decoder_result.time_bin_containers) # for curr_results_obj: LeaveOneOutDecodingAnalysisResult - for Long/Short plotting\n",
    "\n",
    "radon_transform_data = RadonTransformPlotDataProvider._subfn_build_radon_transform_plotting_data(active_filter_epochs_df=active_filter_epochs_df,\n",
    "            num_filter_epochs = num_filter_epochs, time_bin_containers = time_bin_containers, radon_transform_column_names=['score', 'velocity', 'intercept', 'speed'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fa458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _display_long_and_short_stacked_epoch_slices\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out_dict = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', save_figure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f3190",
   "metadata": {},
   "source": [
    "## Other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = _out_pagination_controller.plots['radon_transform'][7]\n",
    "extant_line = _out['line'] # matplotlib.lines.Line2D\n",
    "extant_line.linestyle = 'none'\n",
    "# extant_line.draw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e00165",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(curr_active_pipeline.filtered_contexts.keys())) # ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Converting between decoder names and filtered epoch names:\n",
    "# {'long':'maze1', 'short':'maze2'}\n",
    "# {'LR':'odd', 'RL':'even'}\n",
    "long_LR_name, short_LR_name, long_RL_name, short_RL_name = ['maze1_odd', 'maze2_odd', 'maze1_even', 'maze2_even']\n",
    "decoder_name_to_session_context_name: Dict[str,str] = dict(zip(track_templates.get_decoder_names(), (long_LR_name, long_RL_name, short_LR_name, short_RL_name))) # {'long_LR': 'maze1_odd', 'long_RL': 'maze1_even', 'short_LR': 'maze2_odd', 'short_RL': 'maze2_even'}\n",
    "session_context_to_decoder_name: Dict[str,str] = dict(zip((long_LR_name, long_RL_name, short_LR_name, short_RL_name), track_templates.get_decoder_names())) # {'maze1_odd': 'long_LR', 'maze1_even': 'long_RL', 'maze2_odd': 'short_LR', 'maze2_even': 'short_RL'}\n",
    "\n",
    "decoder_name_to_session_context_name\n",
    "session_context_to_decoder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5896f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_num_slices: int = _out_pagination_controller.params.active_num_slices\n",
    "single_plot_fixed_height: float = _out_pagination_controller.params.single_plot_fixed_height\n",
    "all_plots_height: float = _out_pagination_controller.params.all_plots_height\n",
    "print(f'all_plots_height: {all_plots_height}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad67f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fed6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PendingNotebookCode import _add_maze_id_to_epochs\n",
    "\n",
    "\n",
    "## Add new weighted correlation results as new columns in existing filter_epochs df:\n",
    "active_filter_epochs = long_results_obj.active_filter_epochs\n",
    "# Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "active_filter_epochs = _add_maze_id_to_epochs(active_filter_epochs, short_session.t_start)\n",
    "active_filter_epochs._df['weighted_corr_LONG'] = epoch_long_weighted_corr_results[:,0]\n",
    "active_filter_epochs._df['weighted_corr_SHORT'] = epoch_short_weighted_corr_results[:,0]\n",
    "active_filter_epochs._df['weighted_corr_spearman_LONG'] = epoch_long_weighted_corr_results[:,1]\n",
    "active_filter_epochs._df['weighted_corr_spearman_SHORT'] = epoch_short_weighted_corr_results[:,1]\n",
    "\n",
    "\n",
    "active_filter_epochs\n",
    "active_filter_epochs.to_dataframe()\n",
    "## plot the `weighted_corr_LONG` over time\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=active_num_rows, sharex=True, sharey=sharey, figsize=figsize)\n",
    "\n",
    "## Weighted Correlation during replay epochs:\n",
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_LONG', title='weighted_corr during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_SHORT', xlabel='Replay Epoch Time', ylabel='Weighted Correlation', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line\n",
    "## Weighted Spearman Correlation during replay epochs:\n",
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_spearman_LONG', title='weighted_spearman_corr during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='weighted_corr_spearman_SHORT', xlabel='Replay Epoch Time', ylabel='Weighted Spearman Correlation', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line\n",
    "_out_ax = active_filter_epochs._df.plot.scatter(x='start', y='score_LONG', title='Radon Transform Score during replay events', marker=\"s\",  s=5, label=f'Long', alpha=0.8)\n",
    "active_filter_epochs._df.plot.scatter(x='start', y='score_SHORT', xlabel='Replay Epoch Time', ylabel='Replay Radon Transform Score', ax=_out_ax, marker=\"s\", c='r', s=5, label=f'Short', alpha=0.8)\n",
    "_out_ax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe3e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1e967",
   "metadata": {},
   "source": [
    "## TODO 2024-02-15 8pm - Add in to previous result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd539a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "\n",
    "# (laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df)\n",
    "# (laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df)\n",
    "laps_simple_pf_pearson_merged_df\n",
    "# laps_radon_transform_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57565cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_lap_epochs_dict = dict(zip((long_LR_name, long_RL_name, short_LR_name, short_RL_name), (long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj)))\n",
    "directional_active_lap_pf_results_dicts = TrialByTrialActivity.directional_compute_trial_by_trial_correlation_matrix(active_pf_dt=active_pf_dt, directional_lap_epochs_dict=directional_lap_epochs_dict, included_neuron_IDs=any_decoder_neuron_IDs)\n",
    "\n",
    "decoder_aclu_peak_location_df_merged = deepcopy(track_templates.get_directional_pf_maximum_peaks_dfs(drop_aclu_if_missing_long_or_short=False))\n",
    "# decoder_aclu_peak_location_df_merged[np.isin(decoder_aclu_peak_location_df_merged['aclu'], both_included_neuron_stats_df.aclu.to_numpy())]\n",
    "decoder_aclu_peak_location_df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74381521",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result: TrialByTrialActivity = directional_active_lap_pf_results_dicts['long_LR']\n",
    "# a_result.sp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8421fd1a",
   "metadata": {},
   "source": [
    "# 💾 2024-03-04 - Export `DecoderDecodedEpochsResult` CSVs with user annotations for epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae0ae73",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "_, _, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "filtered_valid_epoch_times = filtered_epochs_df[['start', 'stop']].to_numpy()\n",
    "\n",
    "## 2024-03-08 - Also constrain the user-selected ones (just to try it):\n",
    "decoder_user_selected_epoch_times_dict, any_user_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline, track_templates=track_templates)\n",
    "\n",
    "a_result_dict = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "# {a_name:ensure_dataframe(a_result.filter_epochs) for a_name, a_result in a_result_dict.items()}\n",
    "\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=True)\n",
    "\n",
    "# 🟪 2024-02-29 - `compute_pho_heuristic_replay_scores`\n",
    "directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict, _out_new_scores = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "\n",
    "## Merge the heuristic columns into the wcorr df columns for exports\n",
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "\n",
    "# {a_name:DecoderDecodedEpochsResult.try_add_is_user_annotated_epoch_column(ensure_dataframe(a_result.filter_epochs), any_good_selected_epoch_times=filtered_valid_epoch_times) for a_name, a_result in a_result_dict.items()}\n",
    "\n",
    "for a_name, a_result in a_result_dict.items():\n",
    "    # a_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=True)\n",
    "\n",
    "    ## Merge the heuristic columns into the wcorr df columns for exports\n",
    "    # directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    a_wcorr_result = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict[a_name]\n",
    "    \n",
    "    # did_update_user_annotation_col = DecoderDecodedEpochsResult.try_add_is_user_annotated_epoch_column(ensure_dataframe(a_result.filter_epochs), any_good_selected_epoch_times=any_user_selected_epoch_times, t_column_names=None)\n",
    "    # print(f'did_update_user_annotation_col: {did_update_user_annotation_col}')\n",
    "    # did_update_is_valid = DecoderDecodedEpochsResult.try_add_is_valid_epoch_column(ensure_dataframe(a_result.filter_epochs), any_good_selected_epoch_times=filtered_valid_epoch_times, t_column_names=None)\n",
    "    # print(f'did_update_is_valid: {did_update_is_valid}')\n",
    "\n",
    "# ['start',]\n",
    "\n",
    "a_result_dict = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "\n",
    "# {a_name:ensure_dataframe(a_result.filter_epochs) for a_name, a_result in a_result_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pathlib import Path\n",
    "\n",
    "# 💾 export_csvs\n",
    "\n",
    "# BATCH_DATE_TO_USE: str = f'{get_now_day_str()}_APOGEE' # TODO: Change this as needed, templating isn't actually doing anything rn.\n",
    "\n",
    "known_collected_outputs_paths = [Path(v).resolve() for v in ('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs', '/Users/pho/Dropbox (University of Michigan)/MED-DibaLabDropbox/Data/Pho/Outputs/output/collected_outputs', '/home/halechr/cloud/turbo/Data/Output/collected_outputs', '/home/halechr/FastData/gen_scripts/', '/home/halechr/FastData/collected_outputs/', 'output/gen_scripts/')]\n",
    "collected_outputs_path = find_first_extant_path(known_collected_outputs_paths)\n",
    "assert collected_outputs_path.exists(), f\"collected_outputs_path: '{collected_outputs_path}' does not exist! Is the right computer's config commented out above?\"\n",
    "print(f'collected_outputs_path: \"{collected_outputs_path}\"')\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline, track_templates=track_templates)\n",
    "print(f'\\tComputation complete. Exporting .CSVs...')\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "_, _, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "filtered_valid_epoch_times = filtered_epochs_df[['start', 'stop']].to_numpy()\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_output_csv_paths = directional_decoders_epochs_decode_result.export_csvs(parent_output_path=collected_outputs_path.resolve(), active_context=active_context, session_name=curr_session_name, curr_session_t_delta=t_delta,\n",
    "                                                                              user_annotation_selections={'ripple': any_good_selected_epoch_times},\n",
    "                                                                              valid_epochs_selections={'ripple': filtered_valid_epoch_times})\n",
    "\n",
    "print(f'\\t\\tsuccessfully exported directional_decoders_epochs_decode_result to {collected_outputs_path}!')\n",
    "_output_csv_paths_info_str: str = '\\n'.join([f'{a_name}: \"{file_uri_from_path(a_path)}\"' for a_name, a_path in _output_csv_paths.items()])\n",
    "# print(f'\\t\\t\\tCSV Paths: {_output_csv_paths}\\n')\n",
    "print(f'\\t\\t\\tCSV Paths: {_output_csv_paths_info_str}\\n')\n",
    "\n",
    "# {'laps_weighted_corr_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(laps_weighted_corr_merged_df)_tbin-0.025.csv'),\n",
    "#  'ripple_weighted_corr_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(ripple_weighted_corr_merged_df)_tbin-0.025.csv'),\n",
    "#  'laps_simple_pf_pearson_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(laps_simple_pf_pearson_merged_df)_tbin-0.025.csv'),\n",
    "#  'ripple_simple_pf_pearson_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(ripple_simple_pf_pearson_merged_df)_tbin-0.025.csv')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b77273",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffc939",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88335249",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_good_selected_epoch_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7420982",
   "metadata": {},
   "source": [
    "# 2024-03-04 - Filter out the epochs based on the criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.utils.mixins.time_slicing import add_epochs_id_identity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, required_min_percentage_of_active_cells=0.333333, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "filtered_epochs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68233f",
   "metadata": {},
   "source": [
    "# 🟢 2024-03-27 - Look at active set cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.HDF5_representable import HDFConvertableEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import TruncationCheckingResults\n",
    "\n",
    "\n",
    "## long_short_endcap_analysis:\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "truncation_checking_aclus_dict, jonathan_firing_rate_analysis_result.neuron_replay_stats_df = truncation_checking_result.build_truncation_checking_aclus_dict(neuron_replay_stats_df=jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "\n",
    "frs_index_inclusion_magnitude:float = 0.5\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "\n",
    "## Unrefined:\n",
    "# neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=frs_index_inclusion_magnitude)\n",
    "\n",
    "## Refine the LxC/SxC designators using the firing rate index metric:\n",
    "\n",
    "## Get global `long_short_fr_indicies_analysis`:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_short_fr_indicies_df = long_short_fr_indicies_analysis_results['long_short_fr_indicies_df']\n",
    "jonathan_firing_rate_analysis_result.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=frs_index_inclusion_magnitude)\n",
    "\n",
    "neuron_replay_stats_df, *exclusivity_tuple = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=frs_index_inclusion_magnitude)\n",
    "# short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = exclusivity_tuple\n",
    "exclusivity_aclus_tuple = [v.track_exclusive_aclus for v in exclusivity_tuple]\n",
    "exclusivity_aclus_dict = dict(zip(['short_exclusive', 'long_exclusive', 'BOTH', 'EITHER', 'XOR', 'NEITHER'], exclusivity_aclus_tuple))\n",
    "any_aclus = union_of_arrays(*exclusivity_aclus_tuple)\n",
    "exclusivity_aclus_dict['any'] = any_aclus\n",
    "refined_exclusivity_aclus_tuple = [v.get_refined_track_exclusive_aclus() for v in exclusivity_tuple]\n",
    "neuron_replay_stats_df: pd.DataFrame = HDFConvertableEnum.convert_dataframe_columns_for_hdf(neuron_replay_stats_df)\n",
    "\n",
    "# These keys exhaustively span all aclus:\n",
    "exhaustive_key_names = ['short_exclusive', 'long_exclusive', 'BOTH', 'NEITHER']\n",
    "assert np.all(any_aclus == union_of_arrays(*[exclusivity_aclus_dict[k] for k in exhaustive_key_names]))\n",
    "exhaustive_key_dict = {k:v for k, v in exclusivity_aclus_dict.items() if k in exhaustive_key_names}\n",
    "\n",
    "\n",
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_any_aclus = np.array([  3,   4,   5,   7,  10,  11,  13,  14,  15,  17,  23,  24,  25,  26,  31,  32,  33,  34,  45,  49,  50,  51,  52,  54,  55,  58,  61,  64,  68,  69,  70,  71,  73,  74,  75,  76,  78,  81,  82,  83,  84,  85,  87,  90,  92,  93,  96,  97, 102, 109])\n",
    "old_appearing_aclus = np.array([ 4, 11, 13, 23, 52, 58, 87])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af361ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_aclus = union_of_arrays(*[v for v in truncation_checking_aclus_dict.values() if len(v) > 0])\n",
    "any_aclus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520650ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.analyses.placefields import PfND\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import perform_sweep_lap_groud_truth_performance_testing, _perform_variable_time_bin_lap_groud_truth_performance_testing\n",
    "\n",
    "# desired_laps_decoding_time_bin_size: float = 0.75\n",
    "desired_laps_decoding_time_bin_size: float = 0.5\n",
    "\n",
    "## INPUTS: exclusivity_aclus_tuple, desired_laps_decoding_time_bin_size: float\n",
    "# short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = exclusivity_aclus_tuple\n",
    "# included_neuron_ids_list = [short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset]\n",
    "\n",
    "# included_neuron_ids_list = [*exclusivity_aclus_tuple]\n",
    "\n",
    "## INPUTS: truncation_checking_aclus_dict\n",
    "included_neuron_ids_list = list(truncation_checking_aclus_dict.values())\n",
    "row_names = list(truncation_checking_aclus_dict.keys())\n",
    "\n",
    "_output_tuples_list = perform_sweep_lap_groud_truth_performance_testing(curr_active_pipeline, \n",
    "                                                                        included_neuron_ids_list=included_neuron_ids_list,\n",
    "                                                                        desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_size)\n",
    "\n",
    "percent_laps_correctness_df: pd.DataFrame = pd.DataFrame.from_records([complete_decoded_context_correctness_tuple.percent_correct_tuple for (a_directional_merged_decoders_result, result_laps_epochs_df, complete_decoded_context_correctness_tuple) in _output_tuples_list],\n",
    "                          columns=(\"track_ID_correct\", \"dir_correct\", \"complete_correct\"), index=row_names)\n",
    "percent_laps_correctness_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb00384",
   "metadata": {},
   "source": [
    "# 2024-03-29 - Rigorous Decoder Performance assessment\n",
    "Quantify cell contributions to decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9715a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs: all_directional_pf1D_Decoder, alt_directional_merged_decoders_result\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestLapsSplitting, CustomDecodeEpochsResult, decoder_name, epoch_split_key, get_proper_global_spikes_df\n",
    "\n",
    "## INPUTS: directional_laps_results, track_templates, directional_laps_results\n",
    "\n",
    "## Split the lap epochs into training and test periods.\n",
    "##### Ideally we could test the lap decoding error by sampling randomly from the time bins and omitting 1/6 of time bins from the placefield building (effectively the training data). These missing bins will be used as the \"test data\" and the decoding error will be computed by decoding them and subtracting the actual measured position during these bins.\n",
    "\n",
    "# ### Get the laps to train on\n",
    "# training_data_portion: float = 9.0/10.0\n",
    "# test_data_portion: float = 1.0 - training_data_portion # test data portion is 1/6 of the total duration\n",
    "# print(f'training_data_portion: {training_data_portion}, test_data_portion: {test_data_portion}')\n",
    "\n",
    "# decoders_dict = deepcopy(track_templates.get_decoders_dict())\n",
    "\n",
    "# # debug_output_hdf5_file_path = Path('output', 'laps_train_test_split.h5').resolve()\n",
    "# debug_output_hdf5_file_path = None\n",
    "\n",
    "# # (train_epochs_dict, test_epochs_dict), train_lap_specific_pf1D_Decoder_dict, split_train_test_lap_specific_configs = TrainTestLapsSplitting.compute_train_test_split_laps_decoders(directional_laps_results, track_templates, training_data_portion=training_data_portion,\n",
    "# #                                                                                                                                                              debug_output_hdf5_file_path=debug_output_hdf5_file_path, debug_plot=False, debug_print=True)  # type: Tuple[Tuple[Dict[str, Any], Dict[str, Any]], Dict[str, BasePositionDecoder], Any]\n",
    "\n",
    "# train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = train_lap_specific_pf1D_Decoder_dict\n",
    "\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestSplitResult\n",
    "\n",
    "directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "if directional_train_test_split_result is None:\n",
    "    ## recompute\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_train_test_split'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "    directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data['TrainTestSplit']\n",
    "    assert directional_train_test_split_result is not None, f\"faiiled even after recomputation\"\n",
    "\n",
    "training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "print(f'training_data_portion: {training_data_portion}, test_data_portion: {test_data_portion}')\n",
    "\n",
    "test_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "train_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict\n",
    "\n",
    "# OUTPUTS: train_test_split_laps_df_dict\n",
    "\n",
    "# Tuple[Tuple[Dict, Dict], Dict[str, BasePositionDecoder], Dict]\n",
    "\n",
    "# OUTPUTS: test_epochs_dict, train_epochs_dict, train_lap_specific_pf1D_Decoder_dict\n",
    "\n",
    "# ## Get test epochs:\n",
    "# train_epoch_names: List[str] = [k for k in train_test_split_laps_df_dict.keys() if k.endswith('_train')]\n",
    "# test_epoch_names: List[str] = [k for k in train_test_split_laps_df_dict.keys() if k.endswith('_test')]\n",
    "# train_lap_specific_pf1D_Decoder_dict: Dict[str,BasePositionDecoder] = {k.split('_train', maxsplit=1)[0]:split_train_test_lap_specific_pf1D_Decoder_dict[k] for k in train_epoch_names} # the `k.split('_train', maxsplit=1)[0]` part just gets the original key like 'long_LR'\n",
    "# test_epochs_dict: Dict[str,Epoch] = {k.split('_test', maxsplit=1)[0]:v for k,v in train_test_split_laps_epoch_obj_dict.items() if k.endswith('_test')} # the `k.split('_test', maxsplit=1)[0]` part just gets the original key like 'long_LR'\n",
    "\n",
    "# a_training_test_split_laps_epoch_obj_dict[a_training_test_names[0]].to_hdf('output/laps_train_test_split.h5', f'{a_train_epoch_name}/laps_training_df')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d0456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _do_custom_decode_epochs_dict\n",
    "\n",
    "active_laps_decoding_time_bin_size: float = 0.75\n",
    "\n",
    "global_spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe()).dropna(subset=['lap']) # computation_result.sess.position.to_dataframe()\n",
    "\n",
    "# Dict[epoch_split_key, Dict[decoder_name, CustomDecodeEpochsResult]]\n",
    "\n",
    "## INPUTS: flat_epochs_to_decode_dict, active_laps_decoding_time_bin_size\n",
    "## Decoding of the test epochs (what matters):\n",
    "test_decoder_results_dict: Dict[decoder_name, CustomDecodeEpochsResult] = _do_custom_decode_epochs_dict(global_spikes_df=global_spikes_df, global_measured_position_df=global_measured_position_df,\n",
    "                                                                                                                                 pf1D_Decoder_dict=train_lap_specific_pf1D_Decoder_dict,\n",
    "                                                                                                                                 epochs_to_decode_dict=test_epochs_dict, \n",
    "                                                                                                                                 decoding_time_bin_size=active_laps_decoding_time_bin_size,\n",
    "                                                                                                                                 decoder_and_epoch_keys_independent=False)\n",
    "\n",
    "\n",
    "# flat_epochs_to_decode_dict = {f'{k}_train':v for k,v in train_epochs_dict.items()} | {f'{k}_test':v for k,v in test_epochs_dict.items()} # (train_epochs_dict, test_epochs_dict)\n",
    "# final_decoder_results_dict: Dict[epoch_split_key, Dict[decoder_name, CustomDecodeEpochsResult]] = _do_custom_decode_epochs_dict(curr_active_pipeline,\n",
    "#                                                                                                                                  pf1D_Decoder_dict=train_lap_specific_pf1D_Decoder_dict,\n",
    "#                                                                                                                                  epochs_to_decode_dict=flat_epochs_to_decode_dict,\n",
    "#                                                                                                                                  decoding_time_bin_size=active_laps_decoding_time_bin_size,\n",
    "#                                                                                                                                  decoder_and_epoch_keys_independent=True) # epochs_to_decode_dict.keys(): ['long_LR_train', 'long_RL_train', 'short_LR_train', 'short_RL_train', 'long_LR_test', 'long_RL_test', 'short_LR_test', 'short_RL_test']\n",
    "# matched_decoder_epochs_final_decoder_results_dict: Dict[decoder_name, CustomDecodeEpochsResult] = {k:v[k.replace('_train', '').replace('_test', '')] for k, v in final_decoder_results_dict.items()} # flatten down to only the matching decoder\n",
    "# matched_decoder_epochs_final_decoder_results_dict\n",
    "# print(list(matched_decoder_epochs_final_decoder_results_dict.keys())) # ['long_LR_train', 'long_RL_train', 'short_LR_train', 'short_RL_train', 'long_LR_test', 'long_RL_test', 'short_LR_test', 'short_RL_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e034df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import compute_weighted_correlations\n",
    "\n",
    "## INPUTS: test_decoder_results_dict\n",
    "train_decoded_results_dict: Dict[str, DecodedFilterEpochsResult] = {k:v.decoder_result for k, v in test_decoder_results_dict.items()}\n",
    "\n",
    "weighted_corr_data_dict = compute_weighted_correlations(train_decoded_results_dict, debug_print=True)\n",
    "weighted_corr_data_dict\n",
    "train_decoded_wcorr_df = pd.concat(weighted_corr_data_dict)\n",
    "train_decoded_wcorr_df\n",
    "# a_decoded_measured_diff_df: pd.DataFrame = test_decoder_results_dict['long_LR'].measured_decoded_position_comparion.decoded_measured_diff_df\n",
    "train_decoded_measured_diff_df_dict: Dict[str, pd.DataFrame] = {k:v.measured_decoded_position_comparion.decoded_measured_diff_df for k, v in test_decoder_results_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce176e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot\n",
    "import seaborn as sns\n",
    "\n",
    "plot_key: str = 'err_cm'\n",
    "\n",
    "# Plot each list as a separate time series\n",
    "plt.figure(figsize=(10, 6))\n",
    "for key, value in train_decoded_measured_diff_df_dict.items():\n",
    "    # sns.lineplot(x=range(len(value)), y=value, label=key)\n",
    "    _out_line = sns.lineplot(data=value, x='t', y=plot_key, label=key)\n",
    "    _out_scatter = sns.scatterplot(data=value, x='t', y=plot_key) # no `, label=key` because we only want one entry in the legend\n",
    "\n",
    "plt.xlabel('lap_center_t (sec)')\n",
    "plt.ylabel('mean_error [cm]')\n",
    "plt.title('LAp Decoding Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10117f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epochs_dict = {k:Epoch(ensure_dataframe(v.measured_decoded_position_comparion.decoded_measured_diff_df)) for k, v in test_decoder_results_dict.items()}\n",
    "active_epochs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epochs_dict = {k:Epoch(ensure_dataframe(v)) for k, v in train_decoded_measured_diff_df_dict.items()}\n",
    "active_epochs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8f168",
   "metadata": {},
   "source": [
    "# 2024-04-03 - Time-bin effect on lap decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import make_class\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function\n",
    "\n",
    "return_full_decoding_results: bool = True\n",
    "desired_laps_decoding_time_bin_size = np.linspace(start=0.030, stop=1.0, num=4)\n",
    "\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, False)\n",
    "custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_size,\n",
    "                                                                        use_single_time_bin_per_epoch=[False],\n",
    "                                                                        minimum_event_duration=[desired_laps_decoding_time_bin_size[-1]])\n",
    "\n",
    "\n",
    "_across_session_results_extended_dict = {}\n",
    "## Combine the output of `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                save_hdf=True, save_csvs=True,\n",
    "                                                # desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=4),\n",
    "                                                custom_all_param_sweep_options=custom_all_param_sweep_options, # directly provide the parameter sweeps\n",
    "                                                )\n",
    "if return_full_decoding_results:\n",
    "    # with `return_full_decoding_results == True`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_full_directional_merged_decoders_result = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    # validate the result:\n",
    "    # {k:v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size for k,v in output_full_directional_merged_decoders_result.items()}\n",
    "    # assert np.all([np.isclose(dict(k)['desired_shared_decoding_time_bin_size'], v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size) for k,v in output_full_directional_merged_decoders_result.items()]), f\"the desired time_bin_size in the parameters should match the one used that will appear in the decoded result\"\n",
    "\n",
    "\n",
    "else:\n",
    "    # with `return_full_decoding_results == False`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    output_full_directional_merged_decoders_result = None\n",
    "\n",
    "(several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da04be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d97fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _show_sweep_result\n",
    "\n",
    "## INPUTS: output_full_directional_merged_decoders_result\n",
    "\n",
    "\n",
    "## RUN\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe()).dropna(subset=['lap']) # computation_result.sess.position.to_dataframe()\n",
    "# sweep_key_name: str=\"desired_shared_decoding_time_bin_size\"\n",
    "sweep_key_name: str=\"desired_laps_decoding_time_bin_size\"\n",
    "_out_pagination_controller, (all_swept_measured_positions_dfs_dict, all_swept_decoded_positions_df_dict, all_swept_decoded_measured_diff_df_dict) = _show_sweep_result(output_full_directional_merged_decoders_result, global_measured_position_df=global_measured_position_df,\n",
    "                                                                                                                                                        xbin=long_results_obj.original_1D_decoder.xbin,\n",
    "                                                                                                                                                        active_context=curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='laps', decoder='all_dir'),\n",
    "                                                                                                                                                        sweep_params_idx=2, sweep_key_name=sweep_key_name, max_subplots_per_page=4)\n",
    "# _out_pagination_controller\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed630cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_laps_decoding_time_bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e8f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Context Mask - provides additional information about an Identifying context, like whether a certain component of it should print:\n",
    "# has tags like 'print_debug', 'print_session', 'print_across_sessions'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75b5597",
   "metadata": {},
   "source": [
    "### Plot Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b205de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.plotly_templates import PlotlyHelpers\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms_across_sessions, plot_stacked_histograms\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_helper_save_figures, _helper_build_figure, plotly_pre_post_delta_scatter, plot_across_sessions_scatter_results\n",
    "from PIL import Image\n",
    "from pyphocorehelpers.programming_helpers import copy_image_to_clipboard\n",
    "from pyphocorehelpers.Filesystem.path_helpers import sanitize_filename_for_Windows\n",
    "\n",
    "# fig_size_kwargs = {'width': 1650, 'height': 480}\n",
    "resolution_multiplier = 1\n",
    "# fig_size_kwargs = {'width': resolution_multiplier*1650, 'height': resolution_multiplier*480}\n",
    "fig_size_kwargs = {'width': resolution_multiplier*1920, 'height': resolution_multiplier*480}\n",
    "is_dark_mode, template = PlotlyHelpers.get_plotly_template(is_dark_mode=False)\n",
    "pio.templates.default = template\n",
    "\n",
    "# figure_export_path = Path(r'E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Presentations\\2024-05-30 - Pho iNAV Poster\\Figures').resolve()\n",
    "# figure_export_path = Path('/Users/pho/Dropbox (Personal)/Active/Kamran Diba Lab/Presentations/2024-05-30 - Pho iNAV Poster/Figures').resolve()\n",
    "# assert figure_export_path.exists()\n",
    "\n",
    "figures_folder = Path('output').resolve()\n",
    "\n",
    "def save_plotly(a_fig, a_fig_context):\n",
    "    \"\"\" \n",
    "    captures: TODAY_DAY_DATE, figures_folder, neptuner_run\n",
    "    \"\"\"\n",
    "    fig_save_path: Path = figures_folder.joinpath('_'.join([BATCH_DATE_TO_USE, sanitize_filename_for_Windows(a_fig_context.get_description())])).resolve()\n",
    "    figure_out_paths = {'.html': fig_save_path.with_suffix('.html'), '.png': fig_save_path.with_suffix('.png')}\n",
    "    a_fig.write_html(figure_out_paths['.html'])\n",
    "    display(fullwidth_path_widget(figure_out_paths['.html'], file_name_label='.html'))\n",
    "    # print(file_uri_from_path(figure_out_paths['.html']))\n",
    "    a_fig.write_image(figure_out_paths['.png'])\n",
    "    # print(file_uri_from_path(figure_out_paths['.png']))\n",
    "    display(fullwidth_path_widget(figure_out_paths['.png'], file_name_label='.png'))\n",
    "        \n",
    "    return figure_out_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: wcorr_ripple_shuffle_all_df, all_shuffles_only_best_decoder_wcorr_df, custom_suffix\n",
    "\n",
    "histogram_bins = 25\n",
    "num_sessions = 1\n",
    "# plot_var_name: str = 'abs_best_wcorr'\n",
    "# plot_var_name: str = 'wcorr_z_long'\n",
    "# plot_var_name: str = 'wcorr_long_LR'\n",
    "plot_var_name: str = 'wcorr_long_RL'\n",
    "\n",
    "# plot_y_zero: float = 0.5\n",
    "plot_y_zero: float = 0.0\n",
    "\n",
    "concatenated_ripple_df = deepcopy(wcorr_ripple_shuffle_all_df)\n",
    "desired_ripple_decoding_time_bin_size: float = wcorr_shuffle_results.wcorr_ripple_shuffle.all_templates_decode_kwargs['desired_ripple_decoding_time_bin_size']\n",
    "print(f'{desired_ripple_decoding_time_bin_size = }')\n",
    "concatenated_ripple_df['time_bin_size'] = desired_ripple_decoding_time_bin_size\n",
    "display(concatenated_ripple_df)\n",
    "if 'delta_aligned_start_t' not in concatenated_ripple_df.columns:\n",
    "    concatenated_ripple_df['delta_aligned_start_t'] = concatenated_ripple_df['start'] - t_delta\n",
    "\n",
    "# px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'color':\"is_user_annotated_epoch\", 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': plot_var_name, 'title': f\"'{plot_var_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "#\n",
    "# hist_kwargs = dict(color=\"time_bin_size\")\n",
    "hist_kwargs = dict(color=\"is_user_annotated_epoch\") # , histnorm='probability density'\n",
    "hist_kwargs.pop('color')\n",
    "\n",
    "# px_scatter_kwargs['color'] = 'custom_replay_name'\n",
    "# hist_kwargs['color'] = 'custom_replay_name'\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "new_fig_ripples, new_fig_ripples_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=plot_var_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(t_start, 0.0, (t_end-t_delta)), legend_title_text=None, is_dark_mode=is_dark_mode)\n",
    "\n",
    "new_fig_ripples = new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "_extras_output_dict = {}\n",
    "if is_dark_mode:\n",
    "    _extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=plot_y_zero, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "else:\n",
    "    _extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=plot_y_zero, line=dict(color=\"rgba(0.2,0.2,0.2,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "new_fig_ripples_context = new_fig_ripples_context.adding_context_if_missing(num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=plot_var_name)\n",
    "figure_out_paths = save_plotly(a_fig=new_fig_ripples, a_fig_context=new_fig_ripples_context)\n",
    "new_fig_ripples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histogram_for_z_scores\n",
    "\n",
    "# selected_epoch_index = None\n",
    "# a_decoder_idx = None\n",
    "\n",
    "selected_epoch_index = 0\n",
    "a_decoder_idx = 0\n",
    "\n",
    "if (selected_epoch_index is None) and (a_decoder_idx is None):\n",
    "    _single_epoch_all_shuffles_wcorr_arr = deepcopy(wcorr_ripple_shuffle.all_shuffles_wcorr_array)\n",
    "    _single_epoch_real_wcorr: float = wcorr_ripple_shuffle.real_decoder_ripple_weighted_corr_arr \n",
    "    a_single_decoder_epoch_z_scored_values: NDArray = wcorr_ripple_shuffle.compute_z_transformed_scores(_single_epoch_all_shuffles_wcorr_arr)\n",
    "    a_single_decoder_epoch_z_score: float = wcorr_ripple_shuffle.compute_z_score(_single_epoch_all_shuffles_wcorr_arr, _single_epoch_real_wcorr)\n",
    "    title = f\"histogram_for_z_scores - all decoders, all epochs\"\n",
    "    title_suffix=f': all decoders, all epochs'\n",
    "\n",
    "else: \n",
    "    _single_epoch_all_shuffles_wcorr_arr = wcorr_ripple_shuffle.all_shuffles_wcorr_array[:, selected_epoch_index, a_decoder_idx]\n",
    "    _single_epoch_real_wcorr: float = wcorr_ripple_shuffle.real_decoder_ripple_weighted_corr_arr[selected_epoch_index, a_decoder_idx]\n",
    "    a_single_decoder_epoch_z_scored_values: NDArray = wcorr_ripple_shuffle.compute_z_transformed_scores(_single_epoch_all_shuffles_wcorr_arr)\n",
    "    a_single_decoder_epoch_z_score: float = wcorr_ripple_shuffle.compute_z_score(_single_epoch_all_shuffles_wcorr_arr, _single_epoch_real_wcorr)\n",
    "    title = f\"histogram_for_z_scores - decoder[{a_decoder_idx}], epoch[{selected_epoch_index}]\"\n",
    "    title_suffix=f': decoder[{a_decoder_idx}], epoch[{selected_epoch_index}]'\n",
    "\n",
    "print(f'np.shape(_single_epoch_all_shuffles_wcorr_arr): {np.shape(_single_epoch_all_shuffles_wcorr_arr)}') # (n_shuffles, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b75810",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'a_single_decoder_epoch_z_score: {a_single_decoder_epoch_z_score}')\n",
    "fig = plt.figure(num=title, clear=True)\n",
    "# List of z-scored values\n",
    "z_scores = a_single_decoder_epoch_z_scored_values\n",
    "plot_histogram_for_z_scores(z_scores, title_suffix=title_suffix)\n",
    "plt.axvline(a_single_decoder_epoch_z_score, color='red', linestyle='--', linewidth=2, label='Actual Value')\n",
    "\n",
    "# plot_histogram_for_z_scores(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d6d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df_dict['ripple_WCorrShuffle_df']['export_date'] = get_now_rounded_time_str()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcorr_ripple_shuffle.plot_histogram_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec84c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcorr_ripple_shuffle.plot_histogram_figure(a_decoder_idx=2, selected_epoch_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3961cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of z-scored values\n",
    "all_shuffles_wcorr_array = deepcopy(wcorr_ripple_shuffle.all_shuffles_wcorr_array)\n",
    "(_out_p, _out_p_dict), (_out_shuffle_wcorr_ZScore_LONG, _out_shuffle_wcorr_ZScore_SHORT), (total_n_shuffles_more_extreme_than_real_df, total_n_shuffles_more_extreme_than_real_dict), all_shuffles_wcorr_array = wcorr_ripple_shuffle.post_compute()\n",
    "## OUTPUTS: all_shuffles_wcorr_array, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fbc814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_shuffle_wcorr_ZScore_LONG\n",
    "all_shuffles_wcorr_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standalone save\n",
    "standalone_pkl_filename: str = f'{get_now_rounded_time_str()}_standalone_wcorr_ripple_shuffle_data_only_{wcorr_ripple_shuffle.n_completed_shuffles}.pkl' \n",
    "standalone_pkl_filepath = curr_active_pipeline.get_output_path().joinpath(standalone_pkl_filename).resolve() # Path(\"W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\2024-05-30_0925AM_standalone_wcorr_ripple_shuffle_data_only_1100.pkl\")\n",
    "print(f'saving to \"{standalone_pkl_filepath}\"...')\n",
    "wcorr_ripple_shuffle.save_data(standalone_pkl_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3441a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: wcorr_ripple_shuffle\n",
    "standalone_mat_filename: str = f'{get_now_rounded_time_str()}_standalone_all_shuffles_wcorr_array.mat' \n",
    "standalone_mat_filepath = curr_active_pipeline.get_output_path().joinpath(standalone_mat_filename).resolve() # r\"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\2024-06-03_0400PM_standalone_all_shuffles_wcorr_array.mat\"\n",
    "wcorr_ripple_shuffle.save_data_mat(filepath=standalone_mat_filepath, **{'session': curr_active_pipeline.get_session_context().to_dict()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = datetime.now() - timedelta(days=3)\n",
    "# wcorr_ripple_shuffle.discover_load_and_append_shuffle_data_from_directory(save_directory=curr_active_pipeline.get_output_path().resolve(), debug_print=True)\n",
    "# wcorr_ripple_shuffle.discover_load_and_append_shuffle_data_from_directory(save_directory=curr_active_pipeline.get_output_path().resolve(), with_data_name='standalone_wcorr_ripple_shuffle_data_only', debug_print=True)\n",
    "wcorr_ripple_shuffle.discover_load_and_append_shuffle_data_from_directory(save_directory=curr_active_pipeline.get_output_path().resolve(), with_data_name='standalone_wcorr_ripple_shuffle_data_only', newer_than=yesterday, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94572934",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_context = curr_active_pipeline.get_session_context()\n",
    "session_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=IdentifyingContext._get_session_context_keys())\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "export_files_dict = wcorr_ripple_shuffle.export_csvs(parent_output_path=collected_outputs_path.resolve(), active_context=active_context, session_name=session_name, curr_active_pipeline=curr_active_pipeline)\n",
    "export_files_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5966cf23",
   "metadata": {},
   "source": [
    "### Find clicked index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e823ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times\n",
    "\n",
    "# clicked_epoch = np.array([[149.95935746072792, 150.25439218967222]]).T\n",
    "# clicked_epoch = np.atleast_2d(np.array([637.7847819341114, 638.1821449307026])).T\n",
    "# clicked_epoch = np.atleast_2d(np.array([105.400, 638.1821449307026])).T\n",
    "clicked_epoch = np.atleast_2d(np.array([105.40014315512963, 105.56255971186329])).T\n",
    "# clicked_epoch\n",
    "clicked_epoch_start_times = clicked_epoch[0, :]\n",
    "# clicked_epoch_start_times\n",
    "# clicked_epoch_start_times = np.array([637.7847819341114,])\n",
    "selected_epoch_indicies = find_data_indicies_from_epoch_times(wcorr_ripple_shuffle.filtered_epochs_df, epoch_times=np.squeeze(clicked_epoch_start_times), t_column_names=['start',], atol=0.001, not_found_action='skip_index', debug_print=False)\n",
    "# selected_epoch_indicies\n",
    "\n",
    "assert len(selected_epoch_indicies) > 0\n",
    "\n",
    "selected_epoch_index: int = selected_epoch_indicies[0]\n",
    "print(f'selected_epoch_index: {selected_epoch_index}')\n",
    "print(f'{clicked_epoch_start_times = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97546452",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_decoder_ripple_wcorr_df.iloc[selected_epoch_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_decoder_ripple_wcorr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e8acdd",
   "metadata": {},
   "source": [
    "# 2024-06-03 - Plot decoded wcorr shuffle z-values using `PhoPaginatedMultiDecoderDecodedEpochsWindow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.decoders import wcorr\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# REAL wcorr for other\n",
    "# ==================================================================================================================== #\n",
    "active_spikes_df = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "alt_directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = deepcopy(directional_merged_decoders_result)\n",
    "\n",
    "## Filter the epochs by minimum duration:\n",
    "replay_epochs_df: pd.DataFrame = deepcopy(filtered_epochs_df)\n",
    "desired_ripple_decoding_time_bin_size: float = alt_directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "minimum_event_duration: float = 2.0 * float(alt_directional_merged_decoders_result.ripple_decoding_time_bin_size)\n",
    "print(f'{desired_ripple_decoding_time_bin_size = }, {minimum_event_duration = }')\n",
    "\n",
    "all_templates_decode_kwargs = dict(desired_ripple_decoding_time_bin_size=desired_ripple_decoding_time_bin_size,\n",
    "                    override_replay_epochs_df=replay_epochs_df, ## Use the filtered epochs\n",
    "                    use_single_time_bin_per_epoch=False, minimum_event_duration=minimum_event_duration)\n",
    "\n",
    "(real_directional_merged_decoders_result, real_decoder_ripple_filter_epochs_decoder_result_dict), real_decoder_ripple_weighted_corr_arr = WCorrShuffle.build_real_result(track_templates=track_templates, directional_merged_decoders_result=alt_directional_merged_decoders_result, active_spikes_df=active_spikes_df, all_templates_decode_kwargs=all_templates_decode_kwargs)\n",
    "real_decoder_ripple_filter_epochs_decoder_result_dict : Dict[str, DecodedFilterEpochsResult] = deepcopy(real_decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "real_decoder_ripple_filter_epochs_decoder_result_dict\n",
    "# real_decoder_ripple_weighted_corr_arr\n",
    "\n",
    "# real_directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = deepcopy(directional_merged_decoders_result)\n",
    "# # real_output_alt_directional_merged_decoders_result, (real_decoder_laps_filter_epochs_decoder_result_dict, real_decoder_ripple_filter_epochs_decoder_result_dict) = _try_all_templates_decode(spikes_df=deepcopy(curr_active_pipeline.sess.spikes_df), a_directional_merged_decoders_result=real_directional_merged_decoders_result, shuffled_decoders_dict=real_directional_merged_decoders_result.all_directional_decoder_dict, **a_sweep_dict)\n",
    "# real_output_alt_directional_merged_decoders_result, (real_decoder_laps_filter_epochs_decoder_result_dict, real_decoder_ripple_filter_epochs_decoder_result_dict) = cls._try_all_templates_decode(spikes_df=active_spikes_df, a_directional_merged_decoders_result=real_directional_merged_decoders_result, shuffled_decoders_dict=track_templates.get_decoders_dict(), \n",
    "#                                                                                                                                                                                             skip_merged_decoding=True, **all_templates_decode_kwargs)\n",
    "# real_decoder_ripple_weighted_corr_df_dict = compute_weighted_correlations(decoder_decoded_epochs_result_dict=deepcopy(real_decoder_ripple_filter_epochs_decoder_result_dict))\n",
    "# real_decoder_ripple_weighted_corr_dict = {k:v['wcorr'].to_numpy() for k, v in real_decoder_ripple_weighted_corr_df_dict.items()}\n",
    "# real_decoder_ripple_weighted_corr_df = pd.DataFrame(real_decoder_ripple_weighted_corr_dict) ## (n_epochs, 4)\n",
    "# real_decoder_ripple_weighted_corr_arr = real_decoder_ripple_weighted_corr_df.to_numpy()\n",
    "# print(f'real_decoder_ripple_weighted_corr_arr: {np.shape(real_decoder_ripple_weighted_corr_arr)}')\n",
    "# real_directional_merged_decoders_result\n",
    "\n",
    "# real_output_alt_directional_merged_decoders_result, (real_decoder_laps_filter_epochs_decoder_result_dict, real_decoder_ripple_filter_epochs_decoder_result_dict) = WCorrShuffle._try_all_templates_decode(spikes_df=active_spikes_df, a_directional_merged_decoders_result=real_directional_merged_decoders_result, shuffled_decoders_dict=track_templates.get_decoders_dict(), \n",
    "#                                                                                                                                                                                             skip_merged_decoding=True, **all_templates_decode_kwargs)\n",
    "# real_decoder_ripple_filter_epochs_decoder_result_dict : Dict[str, DecodedFilterEpochsResult] = deepcopy(real_decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "# real_decoder_ripple_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "new_wcorr_shuffle_app, new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window, new_wcorr_shuffle_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "    # decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "    decoder_decoded_epochs_result_dict=real_decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "    # decoder_decoded_epochs_result_dict=high_wcorr_only_filtered_decoder_filter_epochs_decoder_result_dict,\n",
    "    epochs_name='ripple',\n",
    "    included_epoch_indicies=None, debug_print=False,\n",
    "    params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "        'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "        'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "        # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "        # 'disable_y_label': True,\n",
    "        'isPaginatorControlWidgetBackedMode': True,\n",
    "        'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "        # 'debug_print': True,\n",
    "        'max_subplots_per_page': 10,\n",
    "        'scrollable_figure': False,\n",
    "        # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "        'use_AnchoredCustomText': False,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f2633",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window.add_data_overlays(None, real_decoder_ripple_filter_epochs_decoder_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4453253",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window.remove_data_overlays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304948c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "_tmp_out_selections = new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations(source='diba_evt_file') # : # gets the annotations for the kdiba-evt file exported ripples, consistent with his 2009 paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d034fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wcorr_shuffle_paginated_multi_decoder_decoded_epochs_window.setWindowTitle(f'PhoPaginatedMultiDecoderDecodedEpochsWindow: NEW Decoded Epoch Slices - real_decoder_ripple_filter_epochs_decoder_result_dict')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400fa60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuropy\n",
    "\n",
    "all_directional_decoder_dict: Dict[str, neuropy.analyses.placefields.PfND] = alt_directional_merged_decoders_result.all_directional_decoder_dict\n",
    "all_directional_decoder_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60921549",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('alt_directional_merged_decoders_result.all_directional_decoder_dict', alt_directional_merged_decoders_result.all_directional_decoder_dict, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc12642",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_container = alt_directional_merged_decoders_result.all_directional_decoder_dict\n",
    "num_elements: int = len(a_container)\n",
    "\n",
    "\n",
    "if isinstance(a_container, dict):\n",
    "    for i in np.arange(num_elements):\n",
    "        for k, v in a_container.items()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ce09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _perform_compute_custom_epoch_decoding\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_all_df_score_metrics\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "pos_bin_size: float = track_templates.get_decoders()[0].pos_bin_size\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict = _perform_compute_custom_epoch_decoding(curr_active_pipeline, directional_merged_decoders_result, track_templates) # Dict[str, Optional[DecodedFilterEpochsResult]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fefaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# From `General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions._decode_and_evaluate_epochs_using_directional_decoders`\n",
    "## Recompute the epoch scores/metrics such as radon transform and wcorr:\n",
    "(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict), merged_df_outputs_tuple, raw_dict_outputs_tuple = _compute_all_df_score_metrics(directional_merged_decoders_result, track_templates,\n",
    "                                                                                                                                                                                    decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                                                                    spikes_df=deepcopy(curr_active_pipeline.sess.spikes_df),\n",
    "                                                                                                                                                                                    should_skip_radon_transform=True)\n",
    "laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df, laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df = merged_df_outputs_tuple\n",
    "decoder_laps_radon_transform_df_dict, decoder_ripple_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict, decoder_ripple_radon_transform_extras_dict, decoder_laps_weighted_corr_df_dict, decoder_ripple_weighted_corr_df_dict = raw_dict_outputs_tuple\n",
    "## INPUT: ripple_weighted_corr_merged_df, wcorr_ripple_shuffle\n",
    "# Synchronize `ripple_weighted_corr_merged_df` to match `wcorr_ripple_shuffle.filtered_epochs_df` to compare wcorr values:\n",
    "filtered_epoch_start_times = deepcopy(wcorr_ripple_shuffle.filtered_epochs_df)['start'].to_numpy() # get the included times from `wcorr_ripple_shuffle`\n",
    "## Apply the filter to `ripple_weighted_corr_merged_df`\n",
    "filtered_epoch_indicies = find_data_indicies_from_epoch_times(ripple_weighted_corr_merged_df, epoch_times=np.squeeze(filtered_epoch_start_times), t_column_names=['ripple_start_t',], atol=0.001, not_found_action='skip_index', debug_print=False)\n",
    "# filtered_epoch_indicies\n",
    "assert len(filtered_epoch_indicies) > 0\n",
    "# filtered_epoch_indicies\n",
    "# ripple_weighted_corr_merged_df.epochs.matching_epoch_times_slice(epoch_times=np.squeeze(filtered_epoch_start_times), t_column_names=['ripple_start_t',])\n",
    "filtered_ripple_weighted_corr_merged_df: pd.DataFrame = ripple_weighted_corr_merged_df.loc[filtered_epoch_indicies].copy().reset_index(drop=True)\n",
    "filtered_ripple_weighted_corr_merged_df\n",
    "\n",
    "## OUTPUT: filtered_ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bfe145",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare real_decoder_ripple_wcorr_df and filtered_ripple_weighted_corr_merged_df\n",
    "\n",
    "## INPUT: filtered_ripple_weighted_corr_merged_df, real_decoder_ripple_wcorr_df\n",
    "assert len(real_decoder_ripple_wcorr_df) == len(filtered_ripple_weighted_corr_merged_df), f\"len(real_decoder_ripple_wcorr_df): {len(real_decoder_ripple_wcorr_df)} != len(filtered_ripple_weighted_corr_merged_df): {len(filtered_ripple_weighted_corr_merged_df)}\"\n",
    "assert np.all(np.isclose(real_decoder_ripple_wcorr_df['start_t'].to_numpy(), filtered_ripple_weighted_corr_merged_df['ripple_start_t'].to_numpy())), f\"all epoch start times must be the same!\"\n",
    "real_decoder_ripple_wcorr_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9855dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.enable_middle_click_selected_epoch_times_to_clipboard()\n",
    "\n",
    "# clicked_epoch = np.array([132.51138943410479, 132.79100273095537])\n",
    "\n",
    "# clicked_epoch = np.array([149.95935746072792, 150.25439218967222])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77930766",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_epoch_index: int = filtered_epoch_indicies[0]\n",
    "print(f'selected_epoch_index: {selected_epoch_index}')\n",
    "print(f'{clicked_epoch_start_times = }')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f869b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_wcorr_df: pd.DataFrame = pd.DataFrame({a_name:v['wcorr'].to_numpy() for a_name, v in decoder_ripple_weighted_corr_df_dict.items()})\n",
    "# original_wcorr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474fa734",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_epoch_indicies = find_data_indicies_from_epoch_times(wcorr_ripple_shuffle.filtered_epochs_df, epoch_times=np.squeeze(clicked_epoch_start_times), t_column_names=['start',], atol=0.001, not_found_action='skip_index', debug_print=False)\n",
    "# selected_epoch_indicies\n",
    "\n",
    "assert len(selected_epoch_indicies) > 0\n",
    "\n",
    "selected_epoch_index: int = selected_epoch_indicies[0]\n",
    "print(f'selected_epoch_index: {selected_epoch_index}')\n",
    "print(f'{clicked_epoch_start_times = }')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8357ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_decoder_ripple_wcorr_df[np.isclose(real_decoder_ripple_wcorr_df['start_t'], 637.7847819341114)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting complete results:\n",
    "a_shuffle_outcome: Dict[types.DecoderName, DecodedFilterEpochsResult] = output_all_shuffles_decoded_results_list[-1]\n",
    "a_shuffle_wcorrs = output_extracted_result_wcorrs_list[-1]\n",
    "\n",
    "## start with one decoder:\n",
    "a_decoder_name: types.DecoderName = 'long_LR'\n",
    "a_decoder_idx: int = 0\n",
    "a_shuffle_decoder_result: DecodedFilterEpochsResult = a_shuffle_outcome[a_decoder_name]\n",
    "# a_shuffle_decoder_result.filter_epochs\n",
    "\n",
    "a_shuffle_decoder_wcorr_result: NDArray = np.squeeze(a_shuffle_wcorrs[a_decoder_name].to_numpy()) # (n_epochs, )\n",
    "\n",
    "# a_shufle_wcorrs\n",
    "a_shuffle_decoder_wcorr_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4846e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: a_decoder_name\n",
    "_out_shuffle_wcorr_arr = np.stack([np.squeeze(v[a_decoder_name].to_numpy()) for v in output_extracted_result_wcorrs_list]) # .shape ## (n_shuffles, n_epochs) \n",
    "print(f'_out_shuffle_wcorr_arr.shape: {np.shape(_out_shuffle_wcorr_arr)}') # _out_shuffle_wcorr_arr.shape: (n_shuffles, n_epochs)\n",
    "n_shuffles: int = np.shape(_out_shuffle_wcorr_arr)[0]\n",
    "print(f'n_shuffles: {n_shuffles}')\n",
    "n_epochs: int = np.shape(_out_shuffle_wcorr_arr)[1]\n",
    "print(f'n_epochs: {n_epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: `wcorr_ripple_shuffle`\n",
    "wcorr_ripple_shuffle.n_completed_shuffles\n",
    "(_out_p, _out_p_dict), (_out_shuffle_wcorr_ZScore_LONG, _out_shuffle_wcorr_ZScore_SHORT), (total_n_shuffles_more_extreme_than_real_df, total_n_shuffles_more_extreme_than_real_dict), all_shuffles_wcorr_array = wcorr_ripple_shuffle.post_compute(curr_active_pipeline=curr_active_pipeline)\n",
    "## OUTPUTS: all_shuffles_wcorr_array, \n",
    "all_shuffles_wcorr_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c91a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all shuffles for a single epoch:\n",
    "## INPUTS: all_shuffles_wcorr_array, a_decoder_idx, selected_epoch_index\n",
    "\n",
    "## start with one decoder:\n",
    "a_decoder_name: types.DecoderName = 'long_LR'\n",
    "a_decoder_idx: int = 0\n",
    "selected_epoch_index: int = 0\n",
    "\n",
    "# _single_epoch_all_shuffles_wcorr_arr = _out_shuffle_wcorr_arr[:, selected_epoch_index]\n",
    "_single_epoch_all_shuffles_wcorr_arr = wcorr_ripple_shuffle.all_shuffles_wcorr_array[:, selected_epoch_index, a_decoder_idx]\n",
    "print(f'np.shape(_single_epoch_all_shuffles_wcorr_arr): {np.shape(_single_epoch_all_shuffles_wcorr_arr)}') # (n_shuffles, )\n",
    "_single_epoch_all_shuffles_wcorr_arr\n",
    "\n",
    "_single_epoch_real_wcorr: float = wcorr_ripple_shuffle.real_decoder_ripple_weighted_corr_arr[selected_epoch_index, a_decoder_idx]\n",
    "_single_epoch_real_wcorr # -0.35003949543741564"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2030bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_single_decoder_epoch_z_scored_values: NDArray = wcorr_ripple_shuffle.compute_z_transformed_scores(_single_epoch_all_shuffles_wcorr_arr)\n",
    "a_single_decoder_epoch_z_scored_values\n",
    "a_single_decoder_epoch_z_score: float = wcorr_ripple_shuffle.compute_z_score(_single_epoch_all_shuffles_wcorr_arr, _single_epoch_real_wcorr)\n",
    "print(f'a_single_decoder_epoch_z_score: {a_single_decoder_epoch_z_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba84417",
   "metadata": {},
   "source": [
    "### :🟢 Build Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot, plot_histograms\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "import plotly.io as pio\n",
    "import plotly.subplots as sp\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.plotly_templates import PlotlyHelpers\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms_across_sessions, plot_stacked_histograms\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_helper_save_figures, _helper_build_figure, plotly_pre_post_delta_scatter, plot_across_sessions_scatter_results\n",
    "\n",
    "# Plotly Imports:\n",
    "fig_size_kwargs = {'width': 1650, 'height': 480}\n",
    "is_dark_mode, template = PlotlyHelpers.get_plotly_template(is_dark_mode=False)\n",
    "pio.templates.default = template\n",
    "\n",
    "df: pd.DataFrame = deepcopy(wcorr_ripple_shuffle_all_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new scatter plot:\n",
    "# px_scatter_kwargs = {'x': 'epoch_idx', 'y': 'shuffle_wcorr', 'color':\"decoder_idx\", 'title': f\"'wcorr scatter results'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# df = all_shuffles_wcorr_df\n",
    "\n",
    "## INPUTS: wcorr_ZScore_real_LR_df\n",
    "# px_scatter_kwargs = {'x': 'start_t', 'y': 'long', 'title': f\"'wcorr scatter results LONG'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# df = wcorr_ZScore_real_LR_df\n",
    "\n",
    "## INPUTS: real_decoder_ripple_wcorr_df\n",
    "px_scatter_kwargs = {'x': 'start', 'y': 'wcorr_z_long', 'title': f\"'real_decoder_ripple_wcorr_df long_RL'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "# df = real_decoder_ripple_wcorr_df\n",
    "\n",
    "\n",
    "# px_scatter_kwargs.pop('color')\n",
    "out_scatter_fig = px.scatter(df, **px_scatter_kwargs)\n",
    "out_scatter_fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da466ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_bins = 25\n",
    "concatenated_ripple_df = deepcopy(all_shuffles_wcorr_df)\n",
    "# variable_name = 'P_Long'\n",
    "variable_name = 'P_Short' # Shows expected effect - short-only replay prior to delta and then split replays post-delta\n",
    "# variable_name = 'long_best_pf_peak_x_pearsonr'\n",
    "# variable_name = 'long_best_jump'\n",
    "# variable_name = 'wcorr_abs_diff'\n",
    "# variable_name = 'pearsonr_abs_diff'\n",
    "# variable_name = 'direction_change_bin_ratio_diff'\n",
    "# variable_name = 'longest_sequence_length_ratio_diff'\n",
    "# variable_name = 'long_best_longest_sequence_length_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'congruent_dir_bins_ratio_diff'\n",
    "# variable_name = 'total_congruent_direction_change_diff'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# variable_name = 'long_best_direction_change_bin_ratio'\n",
    "# variable_name = 'long_best_congruent_dir_bins_ratio'\n",
    "# 'color':'is_user_annotated_epoch'\n",
    "# 'color': 'is_user_annotated_epoch', \n",
    "\n",
    "px_scatter_kwargs = {'x': 'delta_aligned_start_t', 'y': variable_name, 'color':\"is_user_annotated_epoch\", 'title': f\"'{variable_name}'\"} # , 'color': 'time_bin_size', 'range_y': [-1.0, 1.0], 'labels': {'session_name': 'Session', 'time_bin_size': 'tbin_size', 'is_user_annotated_epoch':'user_sel'}\n",
    "\n",
    "px_scatter_kwargs.pop('color')\n",
    "\n",
    "# hist_kwargs = dict(color=\"time_bin_size\")\n",
    "hist_kwargs = dict(color=\"is_user_annotated_epoch\") # , histnorm='probability density'\n",
    "hist_kwargs.pop('color')\n",
    "new_fig_ripples, new_fig_ripples_context = plotly_pre_post_delta_scatter(data_results_df=concatenated_ripple_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                        px_scatter_kwargs=px_scatter_kwargs, histogram_variable_name=variable_name, hist_kwargs=hist_kwargs, forced_range_y=None,\n",
    "                        time_delta_tuple=(earliest_delta_aligned_t_start, 0.0, latest_delta_aligned_t_end), legend_title_text='Is User Selected', is_dark_mode=is_dark_mode)\n",
    "new_fig_ripples = new_fig_ripples.update_layout(fig_size_kwargs)\n",
    "\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_fig_ripples.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "figure_out_paths = save_plotly(a_fig=new_fig_ripples, a_fig_context=figure_ripples_context)\n",
    "new_fig_ripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4fd2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "# mpg = sns.load_dataset(\"mpg\")\n",
    "\n",
    "## INPUT: pd.DataFrame\n",
    "sns.catplot(\n",
    "    data=all_shuffles_wcorr_df, x=\"epoch_idx\", y=\"shuffle_wcorr\", hue=\"decoder_idx\",\n",
    "    native_scale=True, zorder=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89aac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pd.DataFrame(_out_shuffle_wcorr_Zscore_val, columns=['LongLR', 'LongRL', 'ShortLR', 'ShortRL'])\n",
    "\n",
    "# _out_wcorr_ZScore_LR_dict = dict(zip(['LongLR', 'LongRL', 'ShortLR', 'ShortRL'], [v for v in _out_shuffle_wcorr_Zscore_val.T]))\n",
    "# _out_wcorr_ZScore_LR_dict\n",
    "\n",
    "figure_identifier: str = f\"wcorr (best dir selected for each event) fig\"\n",
    "fig = plt.figure(num=figure_identifier, clear=True, figsize=(6, 2))\n",
    "# for time_bin_size in time_bin_sizes:\n",
    "#     df_tbs = pre_delta_df[pre_delta_df['time_bin_size']==time_bin_size]\n",
    "#     df_tbs['P_Long'].hist(alpha=0.5, label=str(time_bin_size)) \n",
    "    \n",
    "\n",
    "n_shuffles: int = wcorr_ripple_shuffle.n_completed_shuffles\n",
    "print(f'n_shuffles')\n",
    "\n",
    "_out_dfs = []\n",
    "# for i, (name, v) in enumerate(total_n_shuffles_more_extreme_than_real_dict.items()):\n",
    "# for i, (name, v) in enumerate(_out_p_dict.items()):\n",
    "# for i, (name, v) in enumerate(_out_shuffle_wcorr_arr_ZScores_LR_dict.items()):\n",
    "for i, (name, v) in enumerate(_out_wcorr_ZScore_LR_dict.items()):\n",
    "\n",
    "    # if i == 0:\n",
    "    assert np.shape(epoch_start_t) == np.shape(_out_shuffle_wcorr_ZScore_LONG)\n",
    "    assert np.shape(epoch_start_t) == np.shape(_out_shuffle_wcorr_ZScore_SHORT)\n",
    "    # curr_is_valid_epoch_shuffle_indicies = np.any(valid_shuffle_indicies[:,:,i]) # (n_shuffles, n_epochs)\n",
    "    # curr_t = np.squeeze(epoch_start_t[curr_is_valid_epoch_shuffle_indicies])\n",
    "    curr_t = np.squeeze(epoch_start_t)\n",
    "    print(f'np.shape(curr_t): {np.shape(curr_t)}')\n",
    "    print(f'np.shape(v): {np.shape(v)}')\n",
    "    curr_shuffle_wcorr_arr = wcorr_ripple_shuffle.all_shuffles_wcorr_array[:,:,i] # (n_shuffles, n_epochs)\n",
    "\n",
    "    # curr_shuffle_wcorr_df[name] = v\n",
    "    # curr_shuffle_wcorr_df = pd.DataFrame(np.hstack([curr_shuffle_wcorr_arr, np.repeat(i, n_shuffles)])) # , columns=[]\n",
    "\n",
    "    n_shuffles, n_epochs = np.shape(curr_shuffle_wcorr_arr)\n",
    "    print(f\"{n_shuffles = }, {n_epochs = }\")\n",
    "    # curr_shuffle_wcorr_df = pd.DataFrame(curr_shuffle_wcorr_arr) # , columns=[]\n",
    "    # curr_shuffle_wcorr_df = pd.DataFrame(np.hstack([np.atleast_2d(np.repeat(i, n_shuffles)).T, curr_shuffle_wcorr_arr]), columns=(['epoch_idx'] + [f'{int(i)}' for i in np.arange(n_epochs)]))\n",
    "    # curr_shuffle_wcorr_df = pd.DataFrame(np.hstack([np.atleast_2d(np.repeat(i, n_shuffles)).T, np.atleast_2d(np.arange(n_shuffles)).T, curr_shuffle_wcorr_arr]), columns=(['epoch_idx', 'shuffle_idx'] + [f'{int(i)}' for i in np.arange(n_epochs)]))\n",
    "\n",
    "    curr_shuffle_wcorr_df = pd.DataFrame(np.hstack([np.atleast_2d(np.repeat(i, n_shuffles)).T, np.atleast_2d(np.arange(n_shuffles)).T]), columns=(['epoch_idx', 'shuffle_idx']))\n",
    "\n",
    "    epoch_id_sequence = np.array([f'{int(i)}' for i in np.arange(n_epochs)])\n",
    "\n",
    "    curr_shuffle_wcorr_df['epoch_idx'] = np.tile(epoch_id_sequence, n_shuffles)\n",
    "    \n",
    "    # curr_shuffle_wcorr_arr\n",
    "    # \n",
    "    curr_shuffle_wcorr_df['epoch_idx'] = curr_shuffle_wcorr_df['epoch_idx'].astype(int)\n",
    "    curr_shuffle_wcorr_df['shuffle_idx'] = curr_shuffle_wcorr_df['shuffle_idx'].astype(int)\n",
    "    curr_shuffle_wcorr_df['track_id'] = name\n",
    "    # curr_shuffle_wcorr_df\n",
    "\n",
    "    _out_dfs.append(curr_shuffle_wcorr_df)\n",
    "    \n",
    "    # _flat_v = np.nanmean(v, axis=0)\n",
    "    # _flat_v = np.abs(v)\n",
    "    # _flat_v = v\n",
    "    # _temp_df = pd.DataFrame({'epoch_start_t': curr_t, 'p': v})\n",
    "    # _temp_df = pd.DataFrame({'epoch_start_t': curr_t, 'flat_Z_corr': _flat_v})\n",
    "    # plt.scatter(np.arange(np.shape(v)[0]), v, label=name)\n",
    "    # plt.scatter(epoch_start_t, _flat_v, label=name)\n",
    "\n",
    "    # _temp_df.hist(column='flat_Z_corr', alpha=0.5, label=str(name)) \n",
    "\n",
    "    # plot_histograms('Laps', 'One Session', several_time_bin_sizes_time_bin_laps_df, \"several\")\n",
    "\n",
    "\n",
    "all_shuffles_wcorr_df: pd.DataFrame = pd.concat(_out_dfs)\n",
    "all_shuffles_wcorr_df\n",
    "\n",
    "\n",
    "all_shuffles_wcorr_df['epoch_idx'].unique()\n",
    "# plt.title(f'{figure_identifier}')\n",
    "# plt.xlabel('time')\n",
    "# plt.ylabel('Z-scored Wcorr')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c401f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how would I represent the results of 1000 shuffles for each epoch. (n_shuffles, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d395c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_shuffle_wcorr_df.co\n",
    "\n",
    "curr_shuffle_wcorr_df.columns[-1] = 'epoch_idx'\n",
    "# curr_shuffle_wcorr_df.set_axis(labels=['n_shuffles', 'n_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_shuffle_wcorr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aed53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "\n",
    "# \"Melt\" the dataset to \"long-form\" or \"tidy\" representation\n",
    "iris = iris.melt(id_vars=\"species\", var_name=\"measurement\")\n",
    "\n",
    "# Initialize the figure\n",
    "f, ax = plt.subplots()\n",
    "sns.despine(bottom=True, left=True)\n",
    "\n",
    "# Show each observation with a scatterplot\n",
    "sns.stripplot(\n",
    "    data=iris, x=\"value\", y=\"measurement\", hue=\"species\",\n",
    "    dodge=True, alpha=.25, zorder=1, legend=False,\n",
    ")\n",
    "\n",
    "# Show the conditional means, aligning each pointplot in the\n",
    "# center of the strips by adjusting the width allotted to each\n",
    "# category (.8 by default) by the number of hue levels\n",
    "sns.pointplot(\n",
    "    data=iris, x=\"value\", y=\"measurement\", hue=\"species\",\n",
    "    dodge=.8 - .8 / 3, palette=\"dark\", errorbar=None,\n",
    "    markers=\"d\", markersize=4, linestyle=\"none\",\n",
    ")\n",
    "\n",
    "# Improve the legend\n",
    "sns.move_legend(\n",
    "    ax, loc=\"lower right\", ncol=3, frameon=True, columnspacing=1, handletextpad=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35184d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_shuffle_wcorr_ZScore_LONG\n",
    "_out_shuffle_wcorr_ZScore_SHORT\n",
    "epoch_start_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b378dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "common_kwargs = dict(ylim=(0,1), hue='time_bin_size') # , marginal_kws=dict(bins=25, fill=True)\n",
    "# sns.jointplot(data=a_laps_all_epoch_bins_marginals_df, x='lap_start_t', y='P_Long', kind=\"scatter\", color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per epoch') #color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per epoch')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per time bin')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per time bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcorr_ripple_shuffle_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2943319",
   "metadata": {},
   "outputs": [],
   "source": [
    "pho_jointplot(data=wcorr_ripple_shuffle_all_df, x='start', y='wcorr_z_long', kind=\"scatter\", title='Ripple: wcorr long per epoch')\n",
    "pho_jointplot(data=wcorr_ripple_shuffle_all_df, x='start', y='wcorr_z_short', kind=\"scatter\", title='Ripple: wcorr short per epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_shuffle_wcorr_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_decoder_ripple_weighted_corr_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1384c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.logical_not(a_decoder_ripple_weighted_corr_df.notna()))\n",
    "\n",
    "a_shuffle_is_more_extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c84388",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoder_ripple_weighted_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49403abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_decoder_ripple_weighted_corr_df_dicts = np.hstack([output_extracted_result_tuples[i][-1] for i, v in enumerate(output_extracted_result_tuples)])\n",
    "output_decoder_ripple_weighted_corr_df_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd4cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df), (decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict) = _subfn_compute_complete_df_metrics(directional_merged_decoders_result, track_templates, decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                                                                                            decoder_laps_df_dict=deepcopy(decoder_laps_weighted_corr_df_dict), decoder_ripple_df_dict=deepcopy(decoder_ripple_weighted_corr_df_dict), active_df_columns = ['wcorr'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a82089d",
   "metadata": {},
   "source": [
    "# 🎯🟢 2024-05-29 - Trial-by-Trial Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f3cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\n",
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrialByTrialActivityResult\n",
    "\n",
    "# 'trial_by_trial_metrics'\n",
    "\n",
    "# # spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "# rank_order_results = global_computation_results.computed_data['RankOrder'] # : \"RankOrderComputationsContainer\"\n",
    "# minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "# # included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "# directional_laps_results: DirectionalLapsResult = global_computation_results.computed_data['DirectionalLaps']\n",
    "# track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# # long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\n",
    "\n",
    "# # Unpack all directional variables:\n",
    "# ## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "# long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "# # Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "# long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "\n",
    "## INPUTS: curr_active_pipeline, track_templates, global_epoch_name, (long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj)\n",
    "any_decoder_neuron_IDs: NDArray = deepcopy(track_templates.any_decoder_neuron_IDs)\n",
    "# long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "# ## Directional Trial-by-Trial Activity:\n",
    "if 'pf1D_dt' not in curr_active_pipeline.computation_results[global_epoch_name].computed_data:\n",
    "    # if `KeyError: 'pf1D_dt'` recompute\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['pfdt_computation'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "active_pf_1D_dt: PfND_TimeDependent = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf1D_dt'])\n",
    "active_pf_2D_dt: PfND_TimeDependent = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf2D_dt'])\n",
    "\n",
    "active_pf_dt: PfND_TimeDependent = active_pf_1D_dt\n",
    "# Limit only to the placefield aclus:\n",
    "active_pf_dt = active_pf_dt.get_by_id(ids=any_decoder_neuron_IDs)\n",
    "\n",
    "# active_pf_dt: PfND_TimeDependent = deepcopy(active_pf_2D_dt) # 2D\n",
    "long_LR_name, long_RL_name, short_LR_name, short_RL_name = track_templates.get_decoder_names()\n",
    "\n",
    "directional_lap_epochs_dict = dict(zip((long_LR_name, long_RL_name, short_LR_name, short_RL_name), (long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj)))\n",
    "directional_active_lap_pf_results_dicts: Dict[str, TrialByTrialActivity] = TrialByTrialActivity.directional_compute_trial_by_trial_correlation_matrix(active_pf_dt=active_pf_dt, directional_lap_epochs_dict=directional_lap_epochs_dict, included_neuron_IDs=any_decoder_neuron_IDs)\n",
    "\n",
    "## OUTPUTS: directional_active_lap_pf_results_dicts\n",
    "a_trial_by_trial_result: TrialByTrialActivityResult = TrialByTrialActivityResult(any_decoder_neuron_IDs=any_decoder_neuron_IDs,\n",
    "                                                                                active_pf_dt=active_pf_dt,\n",
    "                                                                                directional_lap_epochs_dict=directional_lap_epochs_dict,\n",
    "                                                                                directional_active_lap_pf_results_dicts=directional_active_lap_pf_results_dicts,\n",
    "                                                                                is_global=True)  # type: Tuple[Tuple[Dict[str, Any], Dict[str, Any]], Dict[str, BasePositionDecoder], Any]\n",
    "\n",
    "a_trial_by_trial_result\n",
    "\n",
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af83d268",
   "metadata": {},
   "outputs": [],
   "source": [
    "aTbyT:TrialByTrialActivity = a_trial_by_trial_result.directional_active_lap_pf_results_dicts['long_LR']\n",
    "aTbyT.C_trial_by_trial_correlation_matrix.shape # (40, 21, 21)\n",
    "aTbyT.z_scored_tuning_map_matrix.shape # (21, 40, 57) (n_epochs, n_neurons, n_pos_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63c773",
   "metadata": {},
   "source": [
    "### 2024-06-25 - Advanced Time-dependent decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d831fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directional Versions: 'long_LR':\n",
    "from neuropy.core.epoch import subdivide_epochs, ensure_dataframe\n",
    "\n",
    "## INPUTS: long_LR_epochs_obj, long_LR_results\n",
    "\n",
    "a_pf1D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf1D_dt)\n",
    "a_pf2D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf2D_dt)\n",
    "\n",
    "# Example usage\n",
    "df: pd.DataFrame = ensure_dataframe(deepcopy(long_LR_epochs_obj)) \n",
    "df['epoch_type'] = 'lap'\n",
    "df['interval_type_id'] = 666\n",
    "\n",
    "subdivide_bin_size = 0.200  # Specify the size of each sub-epoch in seconds\n",
    "subdivided_df: pd.DataFrame = subdivide_epochs(df, subdivide_bin_size)\n",
    "# print(subdivided_df)\n",
    "\n",
    "## Evolve the ratemaps:\n",
    "_a_pf1D_dt_snapshots = a_pf1D_dt.batch_snapshotting(subdivided_df, reset_at_start=True)\n",
    "_a_pf2D_dt_snapshots = a_pf2D_dt.batch_snapshotting(subdivided_df, reset_at_start=True)\n",
    "# a_pf2D_dt.plot_ratemaps_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f4a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWidget, BasicBinnedImageRenderingWindow\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "\n",
    "active_pf_2D = deepcopy(a_pf2D_dt)\n",
    "figure_format_config = {}\n",
    "out_all_pf_2D_pyqtgraph_binned_image_fig = display_all_pf_2D_pyqtgraph_binned_image_rendering(active_pf_2D, figure_format_config) # output is BasicBinnedImageRenderingWindow\n",
    "for a_name in out_all_pf_2D_pyqtgraph_binned_image_fig.plot_names:\n",
    "    local_plots_data = out_all_pf_2D_pyqtgraph_binned_image_fig.plots_data[a_name]\n",
    "    local_plots = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name]\n",
    "    newPlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14366a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(directional_viewer, directional_image_layer_dict, custom_direction_split_layers_dict) = aTbyT.plot_napari_trial_by_trial_correlation_matrix(directional_active_lap_pf_results_dicts=a_trial_by_trial_result.directional_active_lap_pf_results_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_xbins = len(active_pf_dt.xbin_centers)\n",
    "n_xbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be70f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "\n",
    "# f\"{DAY_DATE_TO_USE}\"\n",
    "saveData(f'{DAY_DATE_TO_USE}-test_a_trial_by_trial_result_data.pkl', a_trial_by_trial_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038c7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_a_trial_by_trial_result = loadData('test_a_trial_by_trial_result_data.pkl')\n",
    "loaded_a_trial_by_trial_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5148cc20",
   "metadata": {},
   "source": [
    "### ✅🎯🟢 2024-08-14-:🖼️  Normal Matplotlib-based figure output for the `trial_by_trial_correlation_matrix.z_scored_tuning_map_matrix` to show the reliably of each place cell across laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import display_all_pf_2D_pyqtgraph_binned_image_rendering, pyqtplot_plot_image_array\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import TrialByTrialActivityWindow\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "# from pyphoplacecellanalysis.External.pyqtgraph.Qt import QtCore, QtGui\n",
    "\n",
    "\n",
    "## Uses `plot_trial_to_trial_reliability_all_decoders_image_stack` to plot the reliability trial-by-trial indicators over time\n",
    "\n",
    "active_pf_dt = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf2D_dt']) # PfND_TimeDependent\n",
    "# active_pf_dt = a_pf2D_dt\n",
    "\n",
    "\n",
    "## INPUTS: a_pf2D_dt, z_scored_tuning_map_matrix\n",
    "directional_active_lap_pf_results_dicts: Dict[types.DecoderName, TrialByTrialActivity] = deepcopy(a_trial_by_trial_result.directional_active_lap_pf_results_dicts)\n",
    "drop_below_threshold = 0.0000001\n",
    "# app, parent_root_widget, root_render_widget, plot_array, img_item_array, other_components_array, plot_data_array, additional_img_items_dict, legend_layout = plot_trial_to_trial_reliability_all_decoders_image_stack(directional_active_lap_pf_results_dicts=directional_active_lap_pf_results_dicts, active_one_step_decoder=deepcopy(active_pf_dt), drop_below_threshold=drop_below_threshold)\n",
    "\n",
    "_a_trial_by_trial_window = TrialByTrialActivityWindow.plot_trial_to_trial_reliability_all_decoders_image_stack(directional_active_lap_pf_results_dicts=directional_active_lap_pf_results_dicts, active_one_step_decoder=deepcopy(active_pf_dt), drop_below_threshold=drop_below_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5eb300",
   "metadata": {},
   "outputs": [],
   "source": [
    "_final_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='plot_trial_to_trial_reliability_all_decoders_image_stack')\n",
    "\n",
    "\n",
    "curr_active_pipeline.output_figure(_final_context, root_render_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23960a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "_a_trial_by_trial_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df3a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_pf_2D = deepcopy(a_pf2D_dt)\n",
    "figure_format_config = {}\n",
    "out_all_pf_2D_pyqtgraph_binned_image_fig = display_all_pf_2D_pyqtgraph_binned_image_rendering(active_pf_2D, figure_format_config) # output is BasicBinnedImageRenderingWindow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8418e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name in out_all_pf_2D_pyqtgraph_binned_image_fig.plot_names:\n",
    "    local_plots_data = out_all_pf_2D_pyqtgraph_binned_image_fig.plots_data[a_name]\n",
    "    local_plots = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name]\n",
    "    newPlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem\n",
    "    set_small_title(newPlotItem, a_name)\n",
    "    # Adjust margins to reduce space between rows\n",
    "    # newPlotItem.getAxis('left').setWidth(30)  # Adjust left margin if needed\n",
    "    # newPlotItem.getAxis('bottom').setHeight(30)  # Adjust bottom margin if needed\n",
    "    # setMaximumHeight \n",
    "    # no clue why 2 is a good value for this...\n",
    "    # newPlotItem.titleLabel.setMaximumHeight(2)\n",
    "    # newPlotItem.layout.setRowFixedHeight(0, 2)\n",
    "    # Set the plot title:\n",
    "    # formatted_title = self.build_formatted_title_string(title=title)        \n",
    "    # newPlotItem.setTitle(formatted_title)\n",
    "    \n",
    "    newPlotItem.setDefaultPadding(0.0)  # plot without padding data range\n",
    "    newPlotItem.setMouseEnabled(x=False, y=False)\n",
    "    \n",
    "# out_all_pf_2D_pyqtgraph_binned_image_fig.toolBarArea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70334863",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_layout: pg.GraphicsLayoutWidget = out_all_pf_2D_pyqtgraph_binned_image_fig.ui.graphics_layout\n",
    "\n",
    "# main_layout\n",
    "num_rows = 5\n",
    "row_height = 80\n",
    "# Set fixed row height using stretch factors\n",
    "for i in range(num_rows):\n",
    "    main_layout.layout().setRowStretchFactor(i, row_height)\n",
    "    # main_layout.setFixedHeight("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942afb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set fixed row height using stretch factors\n",
    "for i in range(num_rows):\n",
    "    root_render_widget.setRowStretchFactor(i, row_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdbf1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the image data layers for each\n",
    "# for an_epoch_name, (active_laps_df, C_trial_by_trial_correlation_matrix, z_scored_tuning_map_matrix, aclu_to_matrix_IDX_map, neuron_ids) in directional_active_lap_pf_results_dicts.items():\n",
    "for a_decoder_name, active_trial_by_trial_activity_obj in directional_active_lap_pf_results_dicts.items():\n",
    "    # (active_laps_df, C_trial_by_trial_correlation_matrix, z_scored_tuning_map_matrix, aclu_to_matrix_IDX_map, neuron_ids)\n",
    "    z_scored_tuning_map_matrix = active_trial_by_trial_activity_obj.z_scored_tuning_map_matrix\n",
    "    custom_direction_split_layers_dict[f'{a_decoder_name}_z_scored_tuning_maps'] = dict(blending='translucent', colormap='viridis', name=f'{a_decoder_name}_z_scored_tuning_maps', img_data=z_scored_tuning_map_matrix.transpose(1, 0, 2)) # reshape to be compatibile with C_i's dimensions\n",
    "    if include_trial_by_trial_correlation_matrix:\n",
    "        C_trial_by_trial_correlation_matrix = active_trial_by_trial_activity_obj.C_trial_by_trial_correlation_matrix\n",
    "        custom_direction_split_layers_dict[f'{a_decoder_name}_C_trial_by_trial_correlation_matrix'] = dict(blending='translucent', colormap='viridis', name=f'{a_decoder_name}_C_trial_by_trial_correlation_matrix', img_data=C_trial_by_trial_correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5523071",
   "metadata": {},
   "source": [
    "# 2024-05-30 - Continuous decoded posterior output videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "spikes_df = directional_decoders_decode_result.spikes_df\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n",
    "# continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "\n",
    "continuously_decoded_dict = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "pseudo2D_decoder_continuously_decoded_result\n",
    "\n",
    "a_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('long_LR', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import save_array_as_video\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import save_posterior_to_video\n",
    "\n",
    "a_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('long_LR', None)\n",
    "save_posterior_to_video(a_decoder_continuously_decoded_result=a_decoder_continuously_decoded_result, result_name='continuous_long_LR')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca8a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_posterior_to_video(a_decoder_continuously_decoded_result=pseudo2D_decoder_continuously_decoded_result, result_name='continuous_pseudo2D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f828c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: global_results, global_epoch_name\n",
    "\n",
    "# Get the decoders from the computation result:\n",
    "active_one_step_decoder = global_results['pf2D_Decoder']\n",
    "active_two_step_decoder = global_results.get('pf2D_TwoStepDecoder', None)\n",
    "if active_two_step_decoder is None:\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['position_decoding_two_step'], computation_kwargs_list=[{}], enabled_filter_names=[global_epoch_name, global_LR_name, global_RL_name], fail_on_exception=True, debug_print=False)\n",
    "    active_two_step_decoder = global_results.get('pf2D_TwoStepDecoder', None)\n",
    "    assert active_two_step_decoder is not None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pyphocorehelpers.plotting.media_output_helpers import get_array_as_image, colormap_and_save_as_video, save_array_as_video\n",
    "\n",
    "# image = get_array_as_image(img_data, desired_height=100, desired_width=None, skip_img_normalization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_input_posterior = deepcopy(active_two_step_decoder.p_x_given_n_and_x_prev)\n",
    "result_name: str = f'two_step_maze_all'\n",
    "\n",
    "# an_input_posterior = deepcopy(active_one_step_decoder.p_x_given_n)\n",
    "# result_name: str = f'one_step_2D_maze_all'\n",
    "\n",
    "n_x_bins, n_y_bins, n_time_bins = np.shape(an_input_posterior)\n",
    "transpose_axes_tuple = (2, 1, 0,)\n",
    "an_input_posterior = np.transpose(an_input_posterior, transpose_axes_tuple)\n",
    "decoding_realtime_FPS: float = 1.0 / float(active_one_step_decoder.time_bin_size)\n",
    "print(f'decoding_realtime_FPS: {decoding_realtime_FPS}')\n",
    "## save video\n",
    "video_out_path = save_array_as_video(array=an_input_posterior, video_filename=f'output/videos/{result_name}.avi', isColor=True, fps=decoding_realtime_FPS, colormap=cv2.COLORMAP_VIRIDIS)\n",
    "# video_out_path = colormap_and_save_as_video(array=an_input_posterior, video_filename=f'output/videos/{result_name}.avi', fps=decoding_realtime_FPS)\n",
    "\n",
    "print(f'video_out_path: {video_out_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc44dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['position_decoding_two_step'], computation_kwargs_list=[{}], enabled_filter_names=[global_epoch_name, global_LR_name, global_RL_name], fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96151def",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "time_binned_position_df: pd.DataFrame = global_results.get('extended_stats', {}).get('time_binned_position_df', None)\n",
    "time_binned_position_df\n",
    "# active_measured_positions = computation_result.sess.position.to_dataframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde2025",
   "metadata": {},
   "source": [
    "# 2024-06-07 - PhoDiba2023Paper figure generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed9ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import main_complete_figure_generations\n",
    "\n",
    "main_complete_figure_generations(curr_active_pipeline, save_figure=True, save_figures_only=True, enable_default_neptune_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaaf32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d262f",
   "metadata": {},
   "source": [
    "### 2024-09-25 - Manual Decoded Epoch Slices Output to test Qt resiliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figure = True\n",
    "## TODO 2023-06-02 NOW, NEXT: this might not work in 'AGG' mode because it tries to render it with QT, but we can see.\n",
    "try:\n",
    "    #TODO 2023-07-06 14:46: - [ ] This is quite slow - can I do defer_render=True?\n",
    "    _out = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', curr_active_pipeline.get_session_context(), defer_render=False, save_figure=save_figure)\n",
    "except BaseException as e:\n",
    "    print(f'batch_extended_programmatic_figures(...): _prepare_plot_long_and_short_epochs failed with error: {e}\\n skipping.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0624a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _display_directional_merged_pf_decoded_epochs ______________________________________________________________________ #\n",
    "# Produces: this open the Yellow-Blue plots and various marginals\n",
    "try:\n",
    "    # # Interactive-mode parameters:\n",
    "    # _interactive_mode_kwargs = dict(should_use_MatplotlibTimeSynchronizedWidget=True, scrollable_figure=True, defer_render=False)\n",
    "    # _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "    # _curr_interaction_mode_kwargs = _interactive_mode_kwargs # interactive mode\n",
    "\n",
    "    # Non-interactive:\n",
    "    _non_interactive_mode_kwargs = dict(should_use_MatplotlibTimeSynchronizedWidget=False, scrollable_figure=False, defer_render=True)\n",
    "    # _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=False, backend='AGG')\n",
    "    _curr_interaction_mode_kwargs = _non_interactive_mode_kwargs # non-interactive mode\n",
    "\n",
    "    _out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs', curr_active_pipeline.get_session_context(),\n",
    "                max_num_lap_epochs = 240, max_num_ripple_epochs = 500,\n",
    "                render_directional_marginal_laps=True, render_directional_marginal_ripples=True, render_track_identity_marginal_laps=True, render_track_identity_marginal_ripples=True,\n",
    "                # render_directional_marginal_laps=True, render_directional_marginal_ripples=False, render_track_identity_marginal_laps=False, render_track_identity_marginal_ripples=False,\n",
    "                # constrained_layout=True, # layout='none',\n",
    "                build_fn='basic_view', constrained_layout=True, \n",
    "                # build_fn='insets_view', constrained_layout=None, layout='none', # , constrained_layout=False constrained_layout=None, layout='none', # , constrained_layout=None, layout='none' extrodinarily fast\n",
    "                **_curr_interaction_mode_kwargs, # interactive mode\n",
    "                skip_plotting_measured_positions=True, skip_plotting_most_likely_positions=True, save_figure=save_figure)\n",
    "    \n",
    "except BaseException as e:\n",
    "    print(f'batch_extended_programmatic_figures(...): \"_display_directional_merged_pf_decoded_epochs\" failed with error: {e}\\n skipping.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327c41f7",
   "metadata": {},
   "source": [
    "# 2024-06-10 - Across Sessions Bar Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae95fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "## long_short_post_decoding:\n",
    "inst_spike_rate_groups_result: InstantaneousSpikeRateGroupsComputation = curr_active_pipeline.global_computation_results.computed_data.long_short_inst_spike_rate_groups\n",
    "inst_spike_rate_groups_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_instantaneous_spike_rates_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "instantaneous_time_bin_size_seconds_list: float = [1000.000] # 10ms #TODO 2024-09-12 19:48: - [ ] This is where the time_bin_size is changed\n",
    "save_pickle = True\n",
    "save_hdf = False\n",
    "save_across_session_hdf = False\n",
    "\n",
    "_across_session_results_extended_dict = {}\n",
    "## Combine the output of `compute_and_export_session_instantaneous_spike_rates_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_instantaneous_spike_rates_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, instantaneous_time_bin_size_seconds_list=instantaneous_time_bin_size_seconds_list,\n",
    "                                                save_hdf=save_hdf, save_pickle=save_pickle, save_across_session_hdf=save_across_session_hdf,\n",
    "                                                epoch_handling_mode='UseAllEpochsMode',\n",
    "                                            )\n",
    "\n",
    "# '_perform_long_short_instantaneous_spike_rate_groups_analysis'\n",
    "# global_computation_results = curr_active_pipeline.global_computation_results\n",
    "# global_computation_results.get('computation_config', {})\n",
    "\n",
    "\n",
    "# instantaneous_time_bin_size_seconds_list: float = global_computation_results.computation_config.instantaneous_time_bin_size_seconds_list # 0.01 # 10ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a7920",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict\n",
    "# '2024-09-12_recomputed_inst_fr_comps_0.001.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bff872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Specify the output file:\n",
    "common_file_path = Path('output/active_across_session_scatter_plot_results.h5')\n",
    "print(f'common_file_path: {common_file_path}')\n",
    "InstantaneousFiringRatesDataframeAccessor.add_results_to_inst_fr_results_table(inst_fr_comps=inst_spike_rate_groups_result, curr_active_pipeline=curr_active_pipeline, common_file_path=common_file_path, file_mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22878176",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Specify the output file:\n",
    "common_file_path = Path('output/active_across_session_scatter_plot_results.h5')\n",
    "print(f'common_file_path: {common_file_path}')\n",
    "InstantaneousFiringRatesDataframeAccessor.add_results_to_inst_fr_results_table(inst_fr_comps=inst_spike_rate_groups_result, curr_active_pipeline=curr_active_pipeline, common_file_path=common_file_path, file_mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible(curr_key='pipeline', curr_value=_out, max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a979a",
   "metadata": {},
   "source": [
    "# New Replay Events from Diba-2009-style quiescent period detection followed by active period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import compute_diba_quiescent_style_replay_events, overwrite_replay_epochs_and_recompute, try_load_neuroscope_EVT_file_epochs, replace_replay_epochs, _get_custom_suffix_for_replay_filename, finalize_output_shuffled_wcorr\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "# %pdb on\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "a_dummy.should_suppress_errors = False\n",
    "\n",
    "## Settings:\n",
    "\n",
    "# SimpleBatchComputationDummy = make_class('SimpleBatchComputationDummy', attrs=['BATCH_DATE_TO_USE', 'collected_outputs_path'])\n",
    "# a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path)\n",
    "\n",
    "_across_session_results_extended_dict = {}\n",
    "## Combine the output of `compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # save_hdf=save_hdf, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                # desired_shared_decoding_time_bin_sizes=desired_shared_decoding_time_bin_sizes,\n",
    "                                                )\n",
    "\n",
    "\n",
    "# 60m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae803054",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e318bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completed overwrite_replay_epochs_and_recompute(...). custom_save_filepaths: {'pipeline_pkl': WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl'), 'global_computation_pkl': 'global_computation_results_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.pkl', 'pipeline_h5': 'pipeline_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0.h5', 'csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-05_Apogee_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0-2006-6-07_16-40-19_time_bin_size_sweep_results.h5'), 'ripple_csv_out_path': WindowsPath('K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19-(ripple_marginals_df).csv'), 'standalone_wcorr_pkl': WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/2024-07-05_0505PM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_27.pkl'), 'standalone_mat_pkl': WindowsPath('W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/output/2024-07-05_0505PM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_all_shuffles_wcorr_array.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d33e58e",
   "metadata": {},
   "source": [
    "# Serialize: `replay_epoch_variations and _across_session_results_extended_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db50f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Extract results and save to pickle:\n",
    "replay_epoch_variations = deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function']['replay_epoch_variations'])\n",
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results: Dict = deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'])\n",
    "# compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7021df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData\n",
    "# Saving (file mode 'w+b') session pickle file results :... saved session pickle file\n",
    "\n",
    "_specific_out_file_path = curr_active_pipeline.get_output_path().joinpath('compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results.pkl').resolve()\n",
    "saveData(_specific_out_file_path, deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function']))\n",
    "# saveData('output/compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results.pkl', deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25445fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function', _across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'], max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "_curr_outpaths = compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results['replay_epoch_outputs']['diba_quiescent_method_replay_epochs']['custom_save_filepaths']\n",
    "_curr_outpaths\n",
    "# _curr_outpaths['pipeline_pkl'].exists()\n",
    "_curr_outpaths['csv_out_path'].exists()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b18dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _drop_non_existing_file_values(a_dict):\n",
    "    return {k:Path(v).resolve() for k, v in a_dict.items() if Path(v).exists()}\n",
    "\n",
    "# _curr_outpaths_dict = {a_replay_name:v['custom_save_filepaths'] for a_replay_name, v in compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results['replay_epoch_outputs'].items()}\n",
    "_curr_outpaths_dict = {a_replay_name:_drop_non_existing_file_values(v['custom_save_filepaths']) for a_replay_name, v in compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results['replay_epoch_outputs'].items()}\n",
    "_curr_outpaths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "_drop_non_existing_file_values(_curr_outpaths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c0743",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Document `compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results`\n",
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=doc_output_parent_folder, doc_name='compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results')\n",
    "doc_printer.save_documentation('compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results', compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results,\n",
    "                                non_expanded_item_keys=['_reverse_cellID_index_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd27d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import loadData\n",
    "\n",
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results = loadData('output/compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results.pkl')\n",
    "replay_epoch_variations = deepcopy(compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results['replay_epoch_variations'])\n",
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b70fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'standalone_pkl_filepath': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-01_1000AM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_wcorr_ripple_shuffle_data_only_29.pkl'),\n",
    "# 'standalone_mat_filepath': WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-07-01_1000AM_withNewKamranExportedReplays-qclu_[1,2]-frateThresh_5.0_standalone_all_shuffles_wcorr_array.mat'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de49582",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e403f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## See how the Long/Short replay detection looks using the Diba-loaded intervals:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413dd9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['RankOrder']\n",
    "minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# spikes_df = curr_active_pipeline.sess.spikes_df # inferior way\n",
    "spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e214f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'] #['out_hist_fig_result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c91d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute new epochs: \n",
    "included_qclu_values=[1,2]\n",
    "minimum_inclusion_fr_Hz=5.0\n",
    "spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "(qclu_included_aclus, active_track_templates, active_spikes_df, quiescent_periods), (diba_quiescent_method_replay_epochs_df, diba_quiescent_method_replay_epochs) = compute_diba_quiescent_style_replay_events(curr_active_pipeline=curr_active_pipeline,\n",
    "                                                                                                                                                                            included_qclu_values=included_qclu_values, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, spikes_df=spikes_df)\n",
    "\n",
    "## OUTPUTS: diba_quiescent_method_replay_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "included_qclu_values=[1,2]\n",
    "minimum_inclusion_fr_Hz=5.0\n",
    "spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "(qclu_included_aclus, active_track_templates, active_spikes_df, quiescent_periods), (diba_quiescent_method_replay_epochs_df, diba_quiescent_method_replay_epochs) = compute_diba_quiescent_style_replay_events(curr_active_pipeline=curr_active_pipeline,\n",
    "                                                                                                                                                                            included_qclu_values=included_qclu_values, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, spikes_df=spikes_df)\n",
    "\n",
    "## OUTPUTS: diba_quiescent_method_replay_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b2fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FROM .evt file\n",
    "## Load exported epochs from a neuroscope .evt file:\n",
    "diba_evt_file_replay_epochs: Epoch = try_load_neuroscope_EVT_file_epochs(curr_active_pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64495b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Use `diba_evt_file_replay_epochs` as `new_replay_epochs`\n",
    "new_replay_epochs = deepcopy(diba_evt_file_replay_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ec361",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use `diba_quiescent_method_replay_epochs` as `new_replay_epochs`:\n",
    "new_replay_epochs = deepcopy(diba_quiescent_method_replay_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08597aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_replay_epochs_df = ensure_dataframe(new_replay_epochs)\n",
    "new_replay_epochs_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b99020",
   "metadata": {},
   "outputs": [],
   "source": [
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-overwrite_replay_epochs_and_recompute.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    did_change, custom_save_filenames, custom_save_filepaths = overwrite_replay_epochs_and_recompute(curr_active_pipeline=curr_active_pipeline, new_replay_epochs=new_replay_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a9a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "did_change, custom_save_filenames, custom_save_filepaths = overwrite_replay_epochs_and_recompute(curr_active_pipeline=curr_active_pipeline, new_replay_epochs=new_replay_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_replay_epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec3a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.replay_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1547be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add ALL of the possible replay periods to the session as a new `replay_epoch_variations` variable:\n",
    "# if not hasattr(curr_active_pipeline.sess, 'replay_epoch_variations'):\n",
    "#     curr_active_pipeline.sess.replay_epoch_variations = {}\n",
    "\n",
    "\n",
    "# curr_active_pipeline.sess.replay_epoch_variations.update({\n",
    "#     'initial_loaded': deepcopy(curr_active_pipeline.sess.replay_backup),\n",
    "#     'diba_evt_file': deepcopy(diba_evt_file_replay_epochs),\n",
    "#     'diba_quiescent_method_replay_epochs': deepcopy(diba_quiescent_method_replay_epochs),\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3017a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch, ensure_Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import compute_all_replay_epoch_variations\n",
    "\n",
    "replay_epoch_variations = compute_all_replay_epoch_variations(curr_active_pipeline)\n",
    "replay_epoch_variations\n",
    "## OUTPUT: replay_epoch_variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e400e",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": [
     "2024-07-03"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import CustomDecodeEpochsResult, decoder_name, epoch_split_key, get_proper_global_spikes_df, _compute_arbitrary_epochs_decoding_for_decoder\n",
    "\n",
    "active_decoding_epochs: Epoch = deepcopy(replay_epoch_variations['diba_quiescent_method_replay_epochs'])\n",
    "active_decoding_time_bin_size: float = 0.02 # 20ms\n",
    "minimum_inclusion_fr_Hz: float = active_decoding_epochs.metadata.get('minimum_inclusion_fr_Hz', 1.0)\n",
    "included_qclu_values: List[int] = active_decoding_epochs.metadata.get('included_qclu_values', [1,2])\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# spikes_df = curr_active_pipeline.sess.spikes_df # inferior way\n",
    "spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "## Decode epochs for all four decoders:\n",
    "new_epochs_decoder_result_dict: Dict[str, Optional[\"DecodedFilterEpochsResult\"]] = {}\n",
    "for a_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    new_epochs_decoder_result_dict[a_name] = _compute_arbitrary_epochs_decoding_for_decoder(a_decoder, spikes_df=deepcopy(spikes_df), decoding_epochs=active_decoding_epochs, desired_epoch_decoding_time_bin_size=active_decoding_time_bin_size)\n",
    "\n",
    "## OUTPUTS: new_epochs_decoder_result_dict,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c06f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUTS: new_epochs_decoder_result_dict\n",
    "new_epochs_decoder_result_dict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2951da7",
   "metadata": {
    "tags": [
     "2024-07-03"
    ]
   },
   "outputs": [],
   "source": [
    "# rank_order_results = curr_active_pipeline.global_computation_results.computed_data['RankOrder'] # : \"RankOrderComputationsContainer\"\n",
    "# minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "# included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "# print(f'included_qclu_values: {included_qclu_values}')\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: \"DirectionalPseudo2DDecodersResult\" = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "pos_bin_size: float = track_templates.get_decoders()[0].pos_bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d664c4",
   "metadata": {
    "tags": [
     "2024-07-03"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_all_df_score_metrics\n",
    "\n",
    "\n",
    "## Recompute the epoch scores/metrics such as radon transform and wcorr:\n",
    "spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict), merged_df_outputs_tuple, raw_dict_outputs_tuple = _compute_all_df_score_metrics(directional_merged_decoders_result, track_templates,\n",
    "                                                                                                                                                                                    decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                                                                    spikes_df=deepcopy(spikes_df),\n",
    "                                                                                                                                                                                    should_skip_radon_transform=should_skip_radon_transform)\n",
    "laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df, laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df = merged_df_outputs_tuple\n",
    "decoder_laps_radon_transform_df_dict, decoder_ripple_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict, decoder_ripple_radon_transform_extras_dict, decoder_laps_weighted_corr_df_dict, decoder_ripple_weighted_corr_df_dict = raw_dict_outputs_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Document `curr_active_pipeline.sess`\n",
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=doc_output_parent_folder, doc_name='curr_active_pipeline.sess')\n",
    "doc_printer.save_documentation('curr_active_pipeline.sess', curr_active_pipeline.sess, non_expanded_item_keys=['_reverse_cellID_index_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "from pyphocorehelpers.gui.PhoUIContainer import PhoUIContainer\n",
    "from pyphoplacecellanalysis.GUI.Qt.Menus.PhoMenuHelper import PhoMenuHelper\n",
    "from pyphoplacecellanalysis.GUI.Qt.Menus.LocalMenus_AddRenderable.LocalMenus_AddRenderable import LocalMenus_AddRenderable\n",
    "from qtpy.QtWidgets import QAction\n",
    "from pyphoplacecellanalysis.GUI.Qt.Menus.LocalMenus_AddRenderable.LocalMenus_AddRenderable import LocalMenus_AddRenderable\n",
    "\n",
    "epoch_variations_name_list = list(replay_epoch_variations.keys())\n",
    "epoch_variations_name_list\n",
    "\n",
    "\n",
    "## GOAL: build (CUSTOM_submenu_addTimeIntervals, CUSTOM_submenu_addTimeIntervals_ONLY_NEW, CUSTOM_submenu_addTimeIntervalCallbacks, CUSTOM_submenu_addTimeIntervals_Connections)\n",
    "\n",
    "## Add new dynamic intervals:\n",
    "\n",
    "# Assuming add_renderables_menu and add_time_intervals_menu are already defined\n",
    "add_renderables_menu: benedict[str, benedict[str, QAction]] = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "# print(type(add_renderables_menu))\n",
    "add_renderables_menu\n",
    "add_time_intervals_menu: benedict[str, QAction] = add_renderables_menu['AddTimeIntervals']\n",
    "# print(type(add_time_intervals_menu))\n",
    "add_time_intervals_menu\n",
    "\n",
    "_gui_menu_parent: LocalMenus_AddRenderable = add_time_intervals_menu['Laps'].parent()\n",
    "print(_gui_menu_parent.ui)\n",
    "_gui_menu_parent.ui.menuAdd_Renderable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf9971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Epoch/Interval Rectangles:\n",
    "debug_print = True\n",
    "interval_datasource_names = active_2d_plot.interval_datasource_names # ['CustomPBEs', 'PBEs', 'Ripples', 'Laps', 'Replays', 'SessionEpochs']\n",
    "if debug_print:\n",
    "    print(f'interval_datasource_names: {interval_datasource_names}')\n",
    "restore_epoch_menu_commands = [f'AddTimeIntervals.{a_name}' for a_name in interval_datasource_names]\n",
    "if debug_print:\n",
    "    print(f'restore_epoch_menu_commands: {restore_epoch_menu_commands}')\n",
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "for a_command in restore_epoch_menu_commands:\n",
    "    if a_command not in add_renderables_menu:\n",
    "        print(f\"WARNING: command '{a_command}' is not present in add_renderables_menu, so restore will not work for this item!\")\n",
    "    # add_renderables_menu[a_command].trigger()\n",
    "\n",
    "variations_epoch_menu_commands = [f'AddTimeIntervals.{a_name}' for a_name in epoch_variations_name_list]\n",
    "if debug_print:\n",
    "    print(f'variations_epoch_menu_commands: {variations_epoch_menu_commands}')\n",
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "for a_command in variations_epoch_menu_commands:\n",
    "    if a_command not in add_renderables_menu:\n",
    "        print(f\"WARNING: command '{a_command}' is not present in add_renderables_menu, so restore will not work for this item!\")\n",
    "    # add_renderables_menu[a_command].trigger()\n",
    "\n",
    "\n",
    "# add_time_intervals_menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687de0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import Replays_2DRenderTimeEpochs\n",
    "## Callbacks to render the epochs:\n",
    "## INPUTS: destination_plot\n",
    "destination_plot = active_2d_plot\n",
    "\n",
    "# class CustomReplays_2DRenderTimeEpochs(General2DRenderTimeEpochs):\n",
    "#     default_datasource_name = 'NewRipples'\n",
    "    \n",
    "#     @classmethod\n",
    "#     def build_epochs_dataframe_formatter(cls, **kwargs):\n",
    "#         def _add_interval_dataframe_visualization_columns_general_epoch(active_df):\n",
    "#             ## parameters:\n",
    "#             y_location = 0.0\n",
    "#             height = 2.0\n",
    "#             pen_color = pg.mkColor('cyan')\n",
    "#             brush_color = pg.mkColor('cyan')\n",
    "#             brush_color.setAlphaF(0.5)\n",
    "            \n",
    "#             ## Add the missing parameters to the dataframe:\n",
    "#             active_df = cls._update_df_visualization_columns(active_df, y_location, height, pen_color, brush_color, **kwargs)\n",
    "#             return active_df\n",
    "\n",
    "#         return _add_interval_dataframe_visualization_columns_general_epoch\n",
    "    \n",
    "# from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, Ripples_2DRenderTimeEpochs, inline_mkColor\n",
    "# ## Inline Concise: Position Replays, PBEs, and Ripples all below the scatter:\n",
    "# # active_2d_plot.interval_datasources.Replays.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-10.0, height=7.5, pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5), **kwargs)) ## Fully inline\n",
    "# # active_2d_plot.interval_datasources.PBEs.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-2.0, height=1.5, pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5), **kwargs)) ## Fully inline\n",
    "# # active_2d_plot.interval_datasources.Ripples.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5), **kwargs)) ## Fully inline\n",
    "# # active_2d_plot.interval_datasources.SessionEpochs .update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5), **kwargs)) ## Fully inline\n",
    "# epochs_update_dict = {\n",
    "#     'Replays':dict(y_location=-10.0, height=7.5, pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5)),\n",
    "#     'PBEs':dict(y_location=-2.0, height=1.5, pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5)),\n",
    "#     'Ripples':dict(y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5)),\n",
    "#     'SessionEpochs ':dict(y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5)),\n",
    "# }\n",
    "# active_2d_plot.update_rendered_intervals_visualization_properties(epochs_update_dict)\n",
    "\n",
    "\n",
    "# submenu_addTimeIntervalCallbacks: List[Callable] = [lambda evt=None: Replays_2DRenderTimeEpochs.add_render_time_epochs(curr_sess=v, destination_plot=destination_plot) for k, v in replay_epoch_variations.items()]\n",
    "\n",
    "# CUSTOM_submenu_addTimeIntervalCallbacks: List[Callable] = [lambda evt=None: General2DRenderTimeEpochs.add_render_time_epochs(curr_sess=v, destination_plot=destination_plot, name=interval_name) for interval_name, v in replay_epoch_variations.items()]\n",
    "# CUSTOM_submenu_addTimeIntervalCallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a2e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: destination_plot\n",
    "destination_plot = active_2d_plot\n",
    "\n",
    "# # Define the new intervals and their callbacks\n",
    "# new_intervals = [\n",
    "#     (\"New Interval 1\", lambda: print(\"Interval 1 callback\")),\n",
    "#     (\"New Interval 2\", lambda: print(\"Interval 2 callback\")),\n",
    "#     (\"New Interval 3\", lambda: print(\"Interval 3 callback\")),\n",
    "#     (\"New Interval 4\", lambda: print(\"Interval 4 callback\"))\n",
    "# ]\n",
    "\n",
    "CUSTOM_submenu_addTimeIntervals: List[QAction] = []\n",
    "CUSTOM_submenu_addTimeIntervals_ONLY_NEW: List[QAction] = []\n",
    "CUSTOM_submenu_addTimeIntervalCallbacks: List[Callable] =[]\n",
    "CUSTOM_submenu_addTimeIntervals_Connections = []\n",
    "# only_new_time_intervals_menu: benedict[str, QAction] = benedict()\n",
    "\n",
    "\n",
    "# Add new actions to the add_time_intervals_menu\n",
    "# for interval_name, a_callback in new_intervals:\n",
    "for interval_name, a_replay_epoch in replay_epoch_variations.items():\n",
    "\n",
    "    # action = QAction(interval_name, add_time_intervals_menu)\n",
    "    an_action = QAction(interval_name, parent=_gui_menu_parent)  # Set parent to None\n",
    "    an_action.setText(interval_name)\n",
    "    an_action.setObjectName(f\"actionAddTimeIntervals_{interval_name}\")\n",
    "\n",
    "    a_callback = (lambda evt=None: General2DRenderTimeEpochs.add_render_time_epochs(curr_sess=a_replay_epoch, destination_plot=destination_plot, name=interval_name))\n",
    "    CUSTOM_submenu_addTimeIntervalCallbacks.append(a_callback)\n",
    "\n",
    "    # QtWidgets.QAction(LocalMenus_AddRenderable)\n",
    "    _curr_conn = an_action.triggered.connect(a_callback)\n",
    "    CUSTOM_submenu_addTimeIntervals_Connections.append(_curr_conn)\n",
    "    extracted_menu_path = PhoMenuHelper.parse_QAction_for_menu_path(an_action)\n",
    "    print(f'extracted_menu_path: {extracted_menu_path}')\n",
    "    new_key: str = '.'.join(extracted_menu_path)\n",
    "    CUSTOM_submenu_addTimeIntervals.append(an_action)\n",
    "\n",
    "    if new_key not in add_time_intervals_menu:\n",
    "        ## completely new\n",
    "        # only_new_time_intervals_menu[new_key] = an_action\n",
    "        CUSTOM_submenu_addTimeIntervals_ONLY_NEW.append(an_action)\n",
    "\n",
    "    add_time_intervals_menu[new_key] = an_action # have to use a string keypath because `out_command_dict[*extracted_menu_path]` is not allowed\n",
    "    # add_time_intervals_menu.addAction(an_action)\n",
    "    # Add the action to the actual menu\n",
    "    _gui_menu_parent.ui.menuAdd_Renderable.addAction(an_action)\n",
    "\n",
    "\n",
    "# add_time_intervals_menu\n",
    "# only_new_time_intervals_menu\n",
    "\n",
    "\n",
    "# cls.add_dynamic_time_intervals(widget, new_intervals)\n",
    "\n",
    "## INPUTS: add_time_intervals_menu, _gui_menu_parent.ui.menuAdd_Renderable\n",
    "\n",
    "\n",
    "## OUTPUTS: CUSTOM_submenu_addTimeIntervals, CUSTOM_submenu_addTimeIntervals_ONLY_NEW, CUSTOM_submenu_addTimeIntervals_Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9386c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_epoch_name: str = curr_active_pipeline.find_LongShortGlobal_epoch_names()[-1]\n",
    "active_2d_plot_renderable_menus_tuple: Tuple = LocalMenus_AddRenderable._build_renderable_menu(destination_plot=active_2d_plot, curr_active_pipeline=curr_active_pipeline, active_config_name=global_epoch_name)\n",
    "widget, renderable_menu, (submenu_addTimeIntervals, submenu_addTimeIntervalCallbacks, submenu_addTimeIntervals_Connections), (submenu_addTimeCurves, submenu_addTimeCurvesCallbacks, submenu_addTimeCurves_Connections), (submenu_addMatplotlibPlot, submenu_addMatplotlibPlotCallbacks, submenu_addMatplotlibPlot_Connections) = active_2d_plot_renderable_menus_tuple ## Unpack\n",
    "\n",
    "# extend: (submenu_addTimeIntervals, submenu_addTimeIntervalCallbacks, submenu_addTimeIntervals_Connections)\n",
    "\n",
    "# my items (CUSTOM_submenu_addTimeIntervals, CUSTOM_submenu_addTimeIntervals_ONLY_NEW, CUSTOM_submenu_addTimeIntervalCallbacks, CUSTOM_submenu_addTimeIntervals_Connections)\n",
    "\n",
    "\n",
    "# submenu_addTimeIntervals\n",
    "# submenu_addTimeIntervals\n",
    "submenu_addTimeIntervals.extend(CUSTOM_submenu_addTimeIntervals_ONLY_NEW)\n",
    "submenu_addTimeIntervalCallbacks.extend(CUSTOM_submenu_addTimeIntervalCallbacks)\n",
    "submenu_addTimeIntervals_Connections.extend(CUSTOM_submenu_addTimeIntervals_Connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_epoch_name: str = curr_active_pipeline.find_LongShortGlobal_epoch_names()[-1]\n",
    "global_epoch_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b74d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Menus.LocalMenus_AddRenderable.LocalMenus_AddRenderable import LocalMenus_AddRenderable\n",
    "\n",
    "# active_2d_plot = spike_raster_window.spike_raster_plt_2d \n",
    "menuAdd_Renderable: QtWidgets.QMenu = LocalMenus_AddRenderable.add_renderable_context_menu(active_2d_plot=active_2d_plot, curr_active_pipeline=curr_active_pipeline, active_config_name=global_epoch_name)\n",
    "menuAdd_Renderable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e40ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_renderable_context_menu(active_2d_plot, curr_active_pipeline, active_config_name, override_custom_menu: Optional[QtWidgets.QMenu]=None, additional_menu_items=None) -> QtWidgets.QMenu:\n",
    "    \"\"\" \n",
    "    Usage:\n",
    "        active_2d_plot = spike_raster_window.spike_raster_plt_2d \n",
    "        menuAdd_Renderable = LocalMenus_AddRenderable.add_renderable_context_menu(active_2d_plot, sess)\n",
    "        \n",
    "    \"\"\"\n",
    "    def _subFn_append_custom_menu_to_context_menu(parent_widget, additional_menu: QtWidgets.QMenu, debug_print=False):\n",
    "        \"\"\" Adds the custom menu, such as one loaded from a .ui file, to the end of the context menu\n",
    "        parent_widget: PlotItem\n",
    "        additional_menu: QMenu\n",
    "        \n",
    "        Example:\n",
    "            from pyphoplacecellanalysis.Resources import GuiResources, ActionIcons\n",
    "            from pyphoplacecellanalysis.GUI.Qt.GlobalApplicationMenus.LocalMenus_AddRenderable import LocalMenus_AddRenderable\n",
    "            widget = LocalMenus_AddRenderable()\n",
    "            append_custom_menu_to_context_menu(main_plot_widget, widget.ui.menuAdd_Renderable)\n",
    "            append_custom_menu_to_context_menu(background_static_scroll_plot_widget, widget.ui.menuAdd_Renderable)\n",
    "        \"\"\"\n",
    "        \n",
    "        plot_options_context_menu = parent_widget.getContextMenus(None) # This gets the \"Plot Options\" menu\n",
    "        # top_level_parent_context_menu = parent_context_menus.parent()\n",
    "        top_level_parent_context_menu = parent_widget.vb.menu # ViewBoxMenu\n",
    "        \n",
    "        active_parent_menu = top_level_parent_context_menu\n",
    "        active_parent_menu.addSeparator()\n",
    "        active_parent_menu.addMenu(additional_menu)\n",
    "        if debug_print:\n",
    "            print(f'parent_context_menus.actions: {[an_action.text() for an_action in active_parent_menu.actions()]}') # parent_context_menus.actions: ['Transforms', 'Downsample', 'Average', 'Alpha', 'Grid', 'Points']\n",
    "            \n",
    "        ## Build `partial` versions of the functions specific to each raster plotter that can be called with no arguments (capturing the destination plotter and the session\n",
    "    # build_renderable_menu_to_Spike2DRaster = partial(cls.build_renderable_menu, active_2d_plot, sess) # destination_plot\n",
    "    # active_2d_plot_renderable_menus = cls._build_renderable_menu(active_2d_plot, sess)\n",
    "    \n",
    "\n",
    "\n",
    "    if override_custom_menu is None:\n",
    "        active_2d_plot_renderable_menus: Tuple = LocalMenus_AddRenderable._build_renderable_menu(active_2d_plot, curr_active_pipeline, active_config_name)\n",
    "        menuAdd_Renderable: QtWidgets.QMenu = widget_2d_menu.ui.menuAdd_Renderable\n",
    "    else:\n",
    "        active_2d_plot_renderable_menus: Tuple = LocalMenus_AddRenderable._build_renderable_menu(active_2d_plot, curr_active_pipeline, active_config_name) # not sure where they should come from, the flat dict?\n",
    "        menuAdd_Renderable: QtWidgets.QMenu = override_custom_menu\n",
    "\n",
    "\n",
    "\n",
    "    if additional_menu_items is not None:\n",
    "        ## add them\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    # active_2d_plot_renderable_menus: Tuple = LocalMenus_AddRenderable._build_renderable_menu(active_2d_plot, curr_active_pipeline, active_config_name)\n",
    "    widget_2d_menu: LocalMenus_AddRenderable = active_2d_plot_renderable_menus[0]\n",
    "    \n",
    "    # programmatic_actions_dict = widget_2d_menu.programmatic_actions_dict\n",
    "    print(f'active_2d_plot_renderable_menus: {active_2d_plot_renderable_menus}, type(active_2d_plot_renderable_menus): {type(active_2d_plot_renderable_menus)}')\n",
    "    print(f'widget_2d_menu: {widget_2d_menu}, type(widget_2d_menu): {type(widget_2d_menu)}')\n",
    "    print(f'menuAdd_Renderable: {menuAdd_Renderable}, type(menuAdd_Renderable): {type(menuAdd_Renderable)}')\n",
    "    # print(f'menuAdd_Renderable: {menuAdd_Renderable}, type(menuAdd_Renderable): {type(menuAdd_Renderable)}')\n",
    "\n",
    "\n",
    "\n",
    "    ## Specific to SpikeRaster2D:        \n",
    "    ## Add the custom menu to the context menus of the plots in SpikeRaster2D:        \n",
    "    main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "    background_static_scroll_plot_widget = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "    _subFn_append_custom_menu_to_context_menu(main_plot_widget, menuAdd_Renderable)\n",
    "    _subFn_append_custom_menu_to_context_menu(background_static_scroll_plot_widget, menuAdd_Renderable)\n",
    "    \n",
    "    # Add the reference to the context menus to owner, so it isn't released:\n",
    "    ## TODO: currently replaces the dict entry, which we might want to use for other menus\n",
    "    active_2d_plot.ui.menus = PhoUIContainer.init_from_dict({'custom_context_menus': PhoUIContainer.init_from_dict({'add_renderables': active_2d_plot_renderable_menus})})\n",
    "\n",
    "    # # Build final programmatic dict from nested PhoUIContainers:\n",
    "    # out_final = PhoUIContainer.init_from_dict({})\n",
    "    # for k, v in programmatic_actions_dict.items_sorted_by_keys(reverse=False):\n",
    "    #     out_final[k] = PhoUIContainer.init_from_dict(v)\n",
    "    #     # print(k, v)\n",
    "    # widget_2d_menu.programmatic_actions_dict = out_final\n",
    "\n",
    "\n",
    "    return menuAdd_Renderable # try returning just the menu and not the stupid references to everything # Works when we hold a reference\n",
    "\n",
    "\n",
    "## INPUTS: add_time_intervals_menu, _gui_menu_parent.ui.menuAdd_Renderable\n",
    "\n",
    "menuAdd_Renderable: QtWidgets.QMenu = add_renderable_context_menu(active_2d_plot=active_2d_plot, curr_active_pipeline=curr_active_pipeline, active_config_name=global_epoch_name,\n",
    "                                                                  override_custom_menu=_gui_menu_parent.ui.menuAdd_Renderable,\n",
    "                                                                    # additional_menu_items=add_time_intervals_menu,\n",
    "                                                                    )\n",
    "menuAdd_Renderable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submenu_addTimeIntervals_Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb1fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force a refresh of the context menu\n",
    "def rebuild_context_menu():\n",
    "    _gui_menu_parent.ui.menuAdd_Renderable.clear()\n",
    "    for action in add_time_intervals_menu.values():\n",
    "        _gui_menu_parent.ui.menuAdd_Renderable.addAction(action)\n",
    "\n",
    "rebuild_context_menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01629e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_epochs_key = 'diba_quiescent_method_replay_epochs'\n",
    "a_replay_epochs = replay_epoch_variations[replay_epochs_key]\n",
    "\n",
    "# for replay_epochs_key, a_replay_epochs in replay_epoch_variations.items():\n",
    "_temp_curr_active_pipeline = deepcopy(curr_active_pipeline)\n",
    "did_change, custom_save_filenames, custom_save_filepaths = overwrite_replay_epochs_and_recompute(curr_active_pipeline=_temp_curr_active_pipeline, new_replay_epochs=a_replay_epochs, enable_save_pipeline_pkl=True, enable_save_global_computations_pkl=False, enable_save_h5=False)\n",
    "\n",
    "## modifies `_temp_curr_active_pipeline`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1cd763",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_save_filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63846311",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "custom_save_filepaths = helper_perform_pickle_pipeline(a_curr_active_pipeline=_temp_curr_active_pipeline, custom_save_filenames=custom_save_filenames, custom_save_filepaths=custom_save_filepaths, enable_save_pipeline_pkl=True, enable_save_global_computations_pkl=False, enable_save_h5=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc661c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_save_filepaths # 'pipeline_pkl': PosixPath('/Users/pho/data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0.pkl'),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf10b54",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5df735b",
   "metadata": {},
   "source": [
    "# 🎯🔷💯 2024-07-02 - New epoch decoding and CSV export: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992bc1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context().adding_context_if_missing(custom_\n",
    "\n",
    "# session_name: str = curr_active_pipeline.session_name\n",
    "\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "session_name: str = f\"{curr_active_pipeline.session_name}{custom_suffix}\" ## appending this here is a hack, but it makes the correct filename\n",
    "active_context = active_context.adding_context_if_missing(suffix=custom_suffix)\n",
    "session_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=(IdentifyingContext._get_session_context_keys() + ['suffix']))\n",
    "\n",
    "\n",
    "earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "active_context\n",
    "session_ctxt_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c0fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifts the absolute times to delta-relative values, as would be needed to draw on a 'delta_aligned_start_t' axis:\n",
    "delta_relative_t_start, delta_relative_t_delta, delta_relative_t_end = np.array([earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end]) - t_delta\n",
    "# decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline)\n",
    "# any_good_selected_epoch_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(any_good_selected_epoch_times)\n",
    "# df = filter_epochs_dfs_by_annotation_times(curr_active_pipeline, any_good_selected_epoch_times, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, filtered_ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df)\n",
    "# df\n",
    "\n",
    "# collected_outputs_path = self.collected_outputs_path.resolve()\n",
    "\n",
    "collected_outputs_path = collected_outputs_path.resolve()\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_output_csv_paths = directional_decoders_epochs_decode_result.export_csvs(parent_output_path=collected_outputs_path, active_context=active_context, session_name=curr_session_name, curr_session_t_delta=t_delta,\n",
    "                                                                        # user_annotation_selections={'ripple': any_good_selected_epoch_times},\n",
    "                                                                        # valid_epochs_selections={'ripple': filtered_valid_epoch_times},\n",
    "                                                                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c7a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'\\t\\tsuccessfully exported directional_decoders_epochs_decode_result to {collected_outputs_path}!')\n",
    "_output_csv_paths_info_str: str = '\\n'.join([f'{a_name}: \"{file_uri_from_path(a_path)}\"' for a_name, a_path in _output_csv_paths.items()])\n",
    "# print(f'\\t\\t\\tCSV Paths: {_output_csv_paths}\\n')\n",
    "print(f'\\t\\t\\tCSV Paths: {_output_csv_paths_info_str}\\n')\n",
    "\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "for a_ripple_df in (directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df, directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df):\n",
    "    if ('time_bin_size' not in a_ripple_df.columns) and (ripple_decoding_time_bin_size is not None):\n",
    "        ## add the column\n",
    "        a_ripple_df['time_bin_size'] = ripple_decoding_time_bin_size\n",
    "        # ripple_simple_pf_pearson_merged_df['time_bin_size'] = ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "    # Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "    a_ripple_df = DecoderDecodedEpochsResult.add_session_df_columns(a_ripple_df, session_name=session_name, time_bin_size=None, curr_session_t_delta=t_delta, time_col='ripple_start_t')\n",
    "    # df = _add_maze_id_to_epochs(df, t_delta)\n",
    "    # df[\"time_bin_size\"] = ripple_decoding_time_bin_size\n",
    "    # df['is_user_annotated_epoch'] = True # if it's filtered here, it's true\n",
    "for a_ripple_df in (ripple_weighted_corr_merged_df, ripple_simple_pf_pearson_merged_df):\n",
    "    if ('time_bin_size' not in a_ripple_df.columns) and (ripple_decoding_time_bin_size is not None):\n",
    "        ## add the column\n",
    "        a_ripple_df['time_bin_size'] = ripple_decoding_time_bin_size\n",
    "        # ripple_simple_pf_pearson_merged_df['time_bin_size'] = ripple_simple_pf_pearson_merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72763c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_simple_pf_pearson_merged_df\n",
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "# directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict # vector for each decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea151325",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot: directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "\n",
    "ripple_weighted_corr_merged_df = deepcopy(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df)\n",
    "ripple_weighted_corr_merged_df\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c440a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram_bins = 'auto'\n",
    "histogram_bins: int = 25\n",
    "\n",
    "# ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "new_ripple_fig, new_ripple_fig_context = plotly_pre_post_delta_scatter(data_results_df=ripple_weighted_corr_merged_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                                                                        px_scatter_kwargs=dict(title='Ripple'), histogram_variable_name='P_Short')\n",
    "\n",
    "# new_laps_fig = new_laps_fig.update_layout(fig_size_kwargs, \n",
    "#     xaxis_title=\"X Axis Title\",\n",
    "#     yaxis_title=\"Y Axis Title\",\n",
    "#     legend_title=\"Legend Title\",\n",
    "#     font=dict(\n",
    "#         family=\"Courier New, monospace\",\n",
    "#         size=18,\n",
    "#         color=\"RebeccaPurple\"\n",
    "#     ),\n",
    "# )\n",
    "# Update x-axis labels\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=1)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Delta-aligned Event Time (seconds)\", row=1, col=2)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=3)\n",
    "\n",
    "\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_ripple_fig.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "new_ripple_fig\n",
    "\n",
    "\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "\n",
    "# new_laps_fig_context: IdentifyingContext = new_laps_fig_context.adding_context_if_missing(epoch='withNewKamranExportedReplays', num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "# figure_out_paths = save_plotly(a_fig=new_laps_fig, a_fig_context=new_laps_fig_context)\n",
    "# new_laps_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.__getstate__()\n",
    "curr_active_pipeline.sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.__getstate__()\n",
    "\n",
    "# _temp_pipeline_dict = get_dict_subset(curr_active_pipeline.__getstate__(), dummy_pipeline_attrs_names_list)\n",
    "_temp_pipeline_dict = get_dict_subset(curr_active_pipeline.stage.__getstate__(), dummy_pipeline_attrs_names_list) | {'sess': deepcopy(curr_active_pipeline.sess)}\n",
    "_temp_pipeline_dict\n",
    "\n",
    "print_keys_if_possible('curr_active_pipeline.stage.__getstate__()', _temp_pipeline_dict, max_depth=2)\n",
    "\n",
    "a_dummy_pipeline: SimpleCurrActivePipelineComputationDummy = SimpleCurrActivePipelineComputationDummy(**_temp_pipeline_dict)\n",
    "a_dummy_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf39ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a_dummy_pipeline = SimpleCurrActivePipelineComputationDummy(**curr_active_pipeline.__getstate__())\n",
    "a_dummy_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9596e88",
   "metadata": {},
   "source": [
    "## 2024-07-18 - Find Exported .h5 files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519a4763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.get_output_path()\n",
    "\n",
    "curr_active_pipeline.h5_export_path\n",
    "\n",
    "## find exported .h5, .pkl, and .csv files:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c08be",
   "metadata": {},
   "source": [
    "### ✅🖼️ 2024-08-08 - Napari Stack of Predictions with slider for prediction time bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2689d97d",
   "metadata": {},
   "source": [
    "### 🖼️🎨 Plot laps to observe `agreement_with_observation`:\n",
    "TODO 💯❗ 2024-08-15 22:58: - [ ] PhoPaginatedMultiDecoderDecodedEpochsWindow renders the list of subplots on a page with the first being on the BOTTOM and then increasing up towards the top. This is very counter-intuitive and potentially explains issues with ordering and indexing of plots. 💯❗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e8dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow, DecodedEpochSlicesPaginatedFigureController, EpochSelectionsObject, ClickActionCallbacks\n",
    "\n",
    "laps_app, laps_paginated_multi_decoder_decoded_epochs_window, laps_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                            decoder_decoded_epochs_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epochs_name='laps',\n",
    "                            # decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                            included_epoch_indicies=None, \n",
    "    params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': False, \n",
    "    'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "    # 'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': True, 'enable_weighted_correlation_info': True,\n",
    "    # 'disable_y_label': True,\n",
    "    # 'isPaginatorControlWidgetBackedMode': True,\n",
    "    # 'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "    # 'debug_print': True,\n",
    "    # 'max_subplots_per_page': 10,\n",
    "    # 'scrollable_figure': False,\n",
    "    'max_subplots_per_page': 50,\n",
    "    'scrollable_figure': True,\n",
    "    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "    'use_AnchoredCustomText': False,\n",
    "    # 'build_fn': 'insets_view',\n",
    "    })\n",
    "\n",
    "#TODO 💯❗ 2024-08-15 22:58: - [ ] PhoPaginatedMultiDecoderDecodedEpochsWindow renders the list of subplots on a page with the first being on the BOTTOM and then increasing up towards the top. This is very counter-intuitive and potentially explains issues with ordering and indexing of plots. 💯❗\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f504490",
   "metadata": {},
   "source": [
    "# 2024-08-15 - Computer Vision Approches to line recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0531682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.computer_vision import ComputerVisionComputations\n",
    "from pyphocorehelpers.plotting.media_output_helpers import img_data_to_greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314fb011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parent_output_folder = Path(r'output/_temp_individual_posteriors').resolve()\n",
    "parent_output_folder = Path(r\"E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Pho-Kamran-Meetings\\2024-08-20 - Finalizing Transition Matrix\\_temp_individual_posteriors\").resolve()\n",
    "posterior_out_folder = parent_output_folder.joinpath(DAY_DATE_TO_USE).resolve()\n",
    "posterior_out_folder.mkdir(parents=True, exist_ok=True)\n",
    "save_path = posterior_out_folder.resolve()\n",
    "_parent_save_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('perform_export_all_decoded_posteriors_as_images')\n",
    "out_paths = ComputerVisionComputations.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict, _save_context=_parent_save_context, parent_output_folder=save_path, desired_height=None)\n",
    "# out_paths\n",
    "fullwidth_path_widget(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91449226",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.computer_vision import ComputerVisionComputations\n",
    "\n",
    "\n",
    "# save_path = Path('output/all_decoded_epoch_posteriors.h5').resolve()\n",
    "# save_path = Path(r\"E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Pho-Kamran-Meetings\\2024-08-20 - Finalizing Transition Matrix/all_decoded_epoch_posteriors.h5\").resolve()\n",
    "parent_output_folder = Path(r\"E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Pho-Kamran-Meetings\\2024-08-20 - Finalizing Transition Matrix\\_temp_individual_posteriors\").resolve()\n",
    "posterior_out_folder = parent_output_folder.joinpath(DAY_DATE_TO_USE).resolve()\n",
    "posterior_out_folder.mkdir(parents=True, exist_ok=True)\n",
    "save_path = posterior_out_folder.joinpath(\"all_decoded_epoch_posteriors.h5\").resolve()\n",
    "_parent_save_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('save_decoded_posteriors_to_HDF5')\n",
    "out_contexts = ComputerVisionComputations.perform_save_all_decoded_posteriors_to_HDF5(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict, _save_context=_parent_save_context, save_path=save_path)\n",
    "out_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600786d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ndarray_preview height=200, width=None, include_plaintext_repr=False, include_shape=False, horizontal_layout=True\n",
    "\n",
    "from pyphocorehelpers.plotting.media_output_helpers import img_data_to_greyscale\n",
    "\n",
    "a_decoder_decoded_epochs_result = decoder_ripple_filter_epochs_decoder_result_dict['long_LR']\n",
    "active_captured_single_epoch_result: SingleEpochDecodedResult = a_decoder_decoded_epochs_result.get_result_for_epoch(active_epoch_idx=28)\n",
    "most_likely_position_indicies = deepcopy(active_captured_single_epoch_result.most_likely_position_indicies)\n",
    "most_likely_position_indicies = np.squeeze(most_likely_position_indicies)\n",
    "t_bin_centers = deepcopy(active_captured_single_epoch_result.time_bin_container.centers)\n",
    "t_bin_indicies = np.arange(len(np.squeeze(most_likely_position_indicies)))\n",
    "# most_likely_position_indicies\n",
    "p_x_given_n = deepcopy(active_captured_single_epoch_result.marginal_x.p_x_given_n)\n",
    "# p_x_given_n_image = active_captured_single_epoch_result.get_posterior_as_image(skip_img_normalization=False, export_grayscale=True)\n",
    "p_x_given_n_image = img_data_to_greyscale(p_x_given_n)\n",
    "\n",
    "active_captured_single_epoch_result.epoch_info_tuple # EpochTuple(Index=28, start=971.8437469999772, stop=983.9541530000279, label='28', duration=12.110406000050716, lap_id=29, lap_dir=1, score=0.36769430044232587, velocity=1.6140523749028528, intercept=1805.019565924132, speed=1.6140523749028528, wcorr=-0.9152062701244238, P_decoder=0.6562437078530542, pearsonr=-0.7228173157676305, travel=0.0324318935144031, coverage=0.19298245614035087, jump=0.0005841121495327102, sequential_correlation=16228.563177472019, monotonicity_score=16228.563177472019, laplacian_smoothness=16228.563177472019, longest_sequence_length=22, longest_sequence_length_ratio=0.4583333333333333, direction_change_bin_ratio=0.19148936170212766, congruent_dir_bins_ratio=0.574468085106383, total_congruent_direction_change=257.92556950947574, total_variation=326.1999849678664, integral_second_derivative=7423.7044320722935, stddev_of_diff=8.368982188902695)\n",
    "\n",
    "p_x_given_n\n",
    "p_x_given_n_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef643f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "win.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f7d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ndarray_preview height=200, width=None, include_plaintext_repr=False, include_shape=False, horizontal_layout=True\n",
    "\n",
    "from ipywidgets import interact, IntSlider, FloatSlider, FloatRangeSlider\n",
    "from pyphocorehelpers.plotting.media_output_helpers import img_data_to_greyscale\n",
    "\n",
    "# a_decoder_decoded_epochs_result.filter_epochs\n",
    "\n",
    "a_decoder_decoded_epochs_result: DecodedFilterEpochsResult = decoder_ripple_filter_epochs_decoder_result_dict['long_LR']\n",
    "num_filter_epochs: int = a_decoder_decoded_epochs_result.num_filter_epochs\n",
    "active_epoch_idx: int = 6 #28\n",
    "active_captured_single_epoch_result: SingleEpochDecodedResult = a_decoder_decoded_epochs_result.get_result_for_epoch(active_epoch_idx=active_epoch_idx)\n",
    "most_likely_position_indicies = deepcopy(active_captured_single_epoch_result.most_likely_position_indicies)\n",
    "most_likely_position_indicies = np.squeeze(most_likely_position_indicies)\n",
    "t_bin_centers = deepcopy(active_captured_single_epoch_result.time_bin_container.centers)\n",
    "t_bin_indicies = np.arange(len(np.squeeze(most_likely_position_indicies)))\n",
    "# most_likely_position_indicies\n",
    "p_x_given_n = deepcopy(active_captured_single_epoch_result.marginal_x.p_x_given_n)\n",
    "# p_x_given_n_image = active_captured_single_epoch_result.get_posterior_as_image(skip_img_normalization=False, export_grayscale=True)\n",
    "p_x_given_n_image = img_data_to_greyscale(p_x_given_n)\n",
    "\n",
    "active_captured_single_epoch_result.epoch_info_tuple # EpochTuple(Index=28, start=971.8437469999772, stop=983.9541530000279, label='28', duration=12.110406000050716, lap_id=29, lap_dir=1, score=0.36769430044232587, velocity=1.6140523749028528, intercept=1805.019565924132, speed=1.6140523749028528, wcorr=-0.9152062701244238, P_decoder=0.6562437078530542, pearsonr=-0.7228173157676305, travel=0.0324318935144031, coverage=0.19298245614035087, jump=0.0005841121495327102, sequential_correlation=16228.563177472019, monotonicity_score=16228.563177472019, laplacian_smoothness=16228.563177472019, longest_sequence_length=22, longest_sequence_length_ratio=0.4583333333333333, direction_change_bin_ratio=0.19148936170212766, congruent_dir_bins_ratio=0.574468085106383, total_congruent_direction_change=257.92556950947574, total_variation=326.1999849678664, integral_second_derivative=7423.7044320722935, stddev_of_diff=8.368982188902695)\n",
    "\n",
    "# p_x_given_n\n",
    "# p_x_given_n_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.DockPlanningHelperWindow import DockPlanningHelperWindow\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.DockAreaWrapper import PhoDockAreaContainingWindow\n",
    "\n",
    "_out_img_CV_pipeline = DockPlanningHelperWindow.init_dock_area_builder(n_dock_planning_helper_widgets=1)\n",
    "root_dockAreaWindow: PhoDockAreaContainingWindow = _out_img_CV_pipeline.root_dockAreaWindow\n",
    "_out_img_CV_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock_helper_widget, a_dock_config, a_dock_widget = _out_img_CV_pipeline.perform_create_new_dock_widget('p_x_given_n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30151d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock_helper_widget.contentsFrameWidget.setEnabled(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b214a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD\n",
    "import h5py\n",
    "from pyphocorehelpers.Filesystem.HDF5.hdf5_file_helpers import HDF5_Helper\n",
    "\n",
    "\n",
    "\n",
    "# kdiba/gor01/one/2006-6-08_14-26-15/save_decoded_posteriors_to_HDF5/long_LR/laps/00/most_likely_position_indicies[00]\n",
    "\n",
    "\n",
    "\n",
    "load_path = Path('output/all_decoded_epoch_posteriors.h5').resolve()\n",
    "assert load_path.exists()\n",
    "\n",
    "_out_dict = ComputerVisionComputations.load_decoded_posteriors_from_HDF5(load_path=load_path, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7133428",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _out_dict['laps']['long_LR']['p_x_given_n_grey']\n",
    "ripple_0_img = _out_dict['long_LR']['ripple']['p_x_given_n_grey'][0]\n",
    "lap_0_img = _out_dict['long_LR']['laps']['p_x_given_n_grey'][0]\n",
    "lap_0_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0552c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_given_n_image = deepcopy(lap_0_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a03f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imv.getProcessedImage()\n",
    "imv.getLevels()\n",
    "imv.getLookupTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed082f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mw.close()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71acea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "from IPython.display import display #, Image, HTML, Javascript\n",
    "from ipywidgets import widgets, VBox\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Assuming img_stage_outputs is your list of 2D NDArray objects\n",
    "def display_images_in_row(images, xbin_edges=None, ybin_edges=None, **img_kwargs):\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "    for ax, img in zip(axes, images):\n",
    "        img_shape = np.shape(img)\n",
    "        if xbin_edges is None:\n",
    "            xbin_edges = np.arange(img_shape[0]+1) # + 0.5\n",
    "        if ybin_edges is None:\n",
    "            ybin_edges = np.arange(img_shape[1]+1) #+ 0.5\n",
    "        xmin, xmax, ymin, ymax = (xbin_edges[0], xbin_edges[-1], ybin_edges[0], ybin_edges[-1])\n",
    "        y_first_extent = (ymin, ymax, xmin, xmax) # swapped the order of the extent axes.\n",
    "        main_plot_kwargs = {\n",
    "            # 'cmap': 'viridis',\n",
    "            'cmap': 'gray',\n",
    "            'origin':'lower',\n",
    "            'extent':y_first_extent,\n",
    "        }\n",
    "        \n",
    "        ax.imshow(img, **main_plot_kwargs)\n",
    "        ax.axis('off')\n",
    "        \n",
    "    buf = BytesIO()\n",
    "    fig.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    buf.seek(0)\n",
    "\n",
    "    if buf is not None:\n",
    "        # Create an IPython Image object\n",
    "        img_kwargs = dict(width=None, height=img_kwargs.get('height', 100), format='png') | img_kwargs\n",
    "        img = IPython.display.Image(data=buf.getvalue(), **img_kwargs)\n",
    "        return img\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # return fig, axes\n",
    "    # return buf\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "# Example usage\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=False, backend='agg') #  ['GTK3Agg', 'GTK3Cairo', 'GTK4Agg', 'GTK4Cairo', 'MacOSX', 'nbAgg', 'QtAgg', 'QtCairo', 'Qt5Agg', 'Qt5Cairo', 'TkAgg', 'TkCairo', 'WebAgg', 'WX', 'WXAgg', 'WXCairo', 'agg', 'cairo', 'pdf', 'pgf', 'ps', 'svg', 'template']\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='nbAgg') #  ['GTK3Agg', 'GTK3Cairo', 'GTK4Agg', 'GTK4Cairo', 'MacOSX', 'nbAgg', 'QtAgg', 'QtCairo', 'Qt5Agg', 'Qt5Cairo', 'TkAgg', 'TkCairo', 'WebAgg', 'WX', 'WXAgg', 'WXCairo', 'agg', 'cairo', 'pdf', 'pgf', 'ps', 'svg', 'template']\n",
    "\n",
    "\n",
    "# fig, axes = display_images_in_row(img_stage_outputs)\n",
    "img = display_images_in_row(img_stage_outputs)\n",
    "display(fig)\n",
    "_restore_previous_matplotlib_settings_callback()\n",
    "\n",
    "# widgets.hstack(img_stage_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f877ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import _subfn_update_decoded_epoch_slices\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController # `plot_decoded_epoch_slices_paginated`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import WeightedCorrelationPaginatedPlotDataProvider\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import DecodedPositionsPlotDataProvider, DecodedAndActualPositionsPlotData\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import perform_plot_1D_single_most_likely_position_curve\n",
    "\n",
    "# Inputs: epochs_name, decoder_ripple_filter_epochs_decoder_result_dict, curr_active_pipeline\n",
    "epochs_name = 'ripple'\n",
    "\n",
    "(a_name, a_decoder) = tuple(track_templates.get_decoders_dict().items())[0]\n",
    "\n",
    "# a_decoder_decoded_epochs_result = decoder_ripple_filter_epochs_decoder_result_dict[a_name]\n",
    "\n",
    "# a_decoder_decoded_epochs_result = decoder_ripple_filter_epochs_decoder_result_dict[a_name]\n",
    "a_decoder_decoded_epochs_result = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict[a_name]) ## FILTERED\n",
    "\n",
    "_out_pagination_controller = DecodedEpochSlicesPaginatedFigureController.init_from_decoder_data(active_filter_epochs=a_decoder_decoded_epochs_result.filter_epochs,\n",
    "                                                                                    filter_epochs_decoder_result= a_decoder_decoded_epochs_result,\n",
    "                                                                                    xbin=a_decoder.xbin, global_pos_df=curr_active_pipeline.sess.position.df,\n",
    "                                                                                    a_name=f'DecodedEpochSlices[{a_name}]', active_context=curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs=epochs_name, decoder=a_name),\n",
    "                                                                                    max_subplots_per_page=12,\n",
    "                                                                                    params_kwargs={'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, 'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': True, #'enable_radon_transform_info': True, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 12,\n",
    "                                                                                                    'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': True,\n",
    "                                                                                                    'disable_toolbar': False,\n",
    "                                                                                                    # 'build_fn': 'insets_view',\n",
    "                                                                                    }, \n",
    "                                                                                    # disable_toolbar=False\n",
    "                                                                                    )\n",
    "\n",
    "_out_pagination_controller.params.should_suppress_callback_exceptions = False\n",
    "_out_pagination_controller.add_data_overlays(a_decoder_decoded_epochs_result)\n",
    "_tmp_out_selections = _out_pagination_controller.restore_selections_from_user_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce98ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = _out_pagination_controller.plots.fig\n",
    "# fig.toolbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(_out_pagination_controller)\n",
    "\n",
    "_out_pagination_controller.plot_widget._buildUI_setup_statusbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2bf375",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.plot(np.squeeze(most_likely_position_indicies))\n",
    "plt.scatter(t_bin_centers, most_likely_position_indicies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09733224",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(most_likely_position_indicies) # , title='most likely positions'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b664d0",
   "metadata": {},
   "source": [
    "### Generate test position posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ef856",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Span mode:\n",
    "start_idx: int = 9\n",
    "\n",
    "span_size: int = 5 # span 5 bins sequentially, then step\n",
    "step_size: int = 3\n",
    "num_repeats: int = 4\n",
    "step_arr = np.array(list(np.repeat(1.0, span_size)) + list(np.repeat(0.0, step_size)))\n",
    "step_arr\n",
    "test_posterior = np.tile(step_arr, num_repeats)\n",
    "test_posterior\n",
    "# [5, 3] # 5 ON, 3 OFF (8 total)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# stop_idx = (n_generated_t_bins * step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3581d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.binning_helpers import compute_spanning_bins\n",
    "\n",
    "long_LR_pf1D_Decoder.time_window_centers\n",
    "# long_LR_pf1D_Decoder.decode_specific_epochs\n",
    "long_LR_pf1D_Decoder.p_x_given_n\n",
    "\n",
    "# time_bin_size = 0.25\n",
    "time_bin_size = 0.1\n",
    "manual_time_bin_start_t = curr_active_pipeline.sess.t_start\n",
    "manual_time_bin_end_t = curr_active_pipeline.sess.t_stop\n",
    "\n",
    "print(f'time_bin_size: {time_bin_size}, manual_time_bins: (start_t: {manual_time_bin_start_t}, end_t: {manual_time_bin_end_t})')\n",
    "manual_time_window_edges, manual_time_window_edges_binning_info = compute_spanning_bins(None, bin_size=time_bin_size, variable_start_value=manual_time_bin_start_t, variable_end_value=manual_time_bin_end_t) # np.shape(out_digitized_variable_bins)[0] == np.shape(spikes_df)[0]\n",
    "# debug_print_1D_bin_infos(manual_time_window_edges, 'manual_time_window_edges')\n",
    "\n",
    "## Build the new decoder with custom params:\n",
    "new_decoder_pf_params = deepcopy(active_computation_config.pf_params) # should be a PlacefieldComputationParameters\n",
    "# override some settings before computation:\n",
    "new_decoder_pf_params.time_bin_size = time_bin_size\n",
    "\n",
    "## 1D Decoder\n",
    "new_decoder_pf1D = active_pf_1D\n",
    "new_1D_decoder_spikes_df = new_decoder_pf1D.filtered_spikes_df.copy()\n",
    "new_1D_decoder_spikes_df = new_1D_decoder_spikes_df.spikes.add_binned_time_column(manual_time_window_edges, manual_time_window_edges_binning_info, debug_print=False)\n",
    "new_1D_decoder = BayesianPlacemapPositionDecoder(new_decoder_pf_params.time_bin_size, new_decoder_pf1D, new_1D_decoder_spikes_df, manual_time_window_edges=manual_time_window_edges, manual_time_window_edges_binning_info=manual_time_window_edges_binning_info, debug_print=False)\n",
    "new_1D_decoder.compute_all() #  --> n = self.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bbdb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_LR_pf1D_Decoder.unit_specific_time_binned_spike_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f3a479",
   "metadata": {},
   "source": [
    "# 2024-09-03 - Testing Output Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-interactive:\n",
    "_non_interactive_mode_kwargs = dict(should_use_MatplotlibTimeSynchronizedWidget=False, scrollable_figure=False, defer_render=True)\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=False, backend='AGG')\n",
    "_curr_interaction_mode_kwargs = _non_interactive_mode_kwargs # non-interactive mode\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs', curr_active_pipeline.get_session_context(),\n",
    "            max_num_lap_epochs = 240, max_num_ripple_epochs = 500,\n",
    "            render_directional_marginal_laps=True, render_directional_marginal_ripples=True, render_track_identity_marginal_laps=True, render_track_identity_marginal_ripples=True,\n",
    "            # render_directional_marginal_laps=True, render_directional_marginal_ripples=False, render_track_identity_marginal_laps=False, render_track_identity_marginal_ripples=False,\n",
    "            # constrained_layout=True, # layout='none',\n",
    "            # build_fn='basic_view', constrained_layout=True, \n",
    "            build_fn='insets_view', constrained_layout=None, layout='none', # , constrained_layout=False constrained_layout=None, layout='none', # , constrained_layout=None, layout='none' extrodinarily fast\n",
    "            **_curr_interaction_mode_kwargs, # interactive mode\n",
    "            skip_plotting_measured_positions=True, skip_plotting_most_likely_positions=True, save_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41422f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_full\n",
    "\n",
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics, fig_1c_figures_out_dict = PAPER_FIGURE_figure_1_full(curr_active_pipeline,\n",
    "                                                                                                        should_plot_example_rasters=False, should_plot_pf1d_compare=False,\n",
    "                                                                                                        ) # did not display the pf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c183a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_epoch_rasters_L.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4644e1",
   "metadata": {},
   "source": [
    "### 💾🖼️ 2024-04-27 - Save Posteriors as Yellow-Blue plots to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04910321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid\n",
    "\n",
    "# Open the images\n",
    "_raster_imgs = [Image.open(i) for i in _out_rasters_save_paths]\n",
    "# _out_vstack = vertical_image_stack(_raster_imgs, padding=5)\n",
    "# _out_vstack\n",
    "_out_hstack = horizontal_image_stack(_raster_imgs, padding=5)\n",
    "_out_hstack\n",
    "\n",
    "\n",
    "\n",
    "# directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "# laps_marginals_df\n",
    "\n",
    "# ## Get the result after computation:\n",
    "# directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "# all_directional_decoder_dict_value = directional_merged_decoders_result.all_directional_decoder_dict\n",
    "# all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "# # long_directional_pf1D_Decoder_value = directional_merged_decoders_result.long_directional_pf1D_Decoder\n",
    "# # long_directional_decoder_dict_value = directional_merged_decoders_result.long_directional_decoder_dict\n",
    "# # short_directional_pf1D_Decoder_value = directional_merged_decoders_result.short_directional_pf1D_Decoder\n",
    "# # short_directional_decoder_dict_value = directional_merged_decoders_result.short_directional_decoder_dict\n",
    "\n",
    "# all_directional_laps_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "# all_directional_ripple_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\n",
    "\n",
    "# laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\n",
    "# laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = directional_merged_decoders_result.laps_track_identity_marginals_tuple\n",
    "# ripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.ripple_directional_marginals_tuple\n",
    "# ripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = directional_merged_decoders_result.ripple_track_identity_marginals_tuple\n",
    "\n",
    "# ripple_decoding_time_bin_size: float = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.decoding_time_bin_size\n",
    "# ripple_decoding_time_bin_size\n",
    "# laps_decoding_time_bin_size: float = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size\n",
    "# laps_decoding_time_bin_size\n",
    "\n",
    "# laps_all_epoch_bins_marginals_df = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "# ripple_all_epoch_bins_marginals_df = directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df\n",
    "\n",
    "# ripple_all_epoch_bins_marginals_df\n",
    "# ripple_directional_marginals\n",
    "\n",
    "directional_merged_decoders_result.perform_compute_marginals()\n",
    "directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df\n",
    "\n",
    "# parent_array_as_image_output_folder = Path(r'E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Presentations\\2024-05-30 - Pho iNAV Poster\\Exports\\array_as_image').resolve()\n",
    "parent_array_as_image_output_folder = Path('output/Exports/array_as_image').resolve()\n",
    "parent_array_as_image_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "assert parent_array_as_image_output_folder.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d42335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicked_epoch = np.array([169.95631618227344, 170.15983607806265])\n",
    "clicked_epoch = np.array([91.57839279191103, 91.857145929])\n",
    "clicked_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe39b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.p_x_given_n_list[1])\n",
    "         \n",
    "# directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.marginal_x_list\n",
    "active_marginals_df: pd.DataFrame = deepcopy(directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df)\n",
    "# active_marginals_df.ripple_idx\n",
    "# directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result.marginal_x_list\n",
    "active_filter_epochs_decoder_result: DecodedFilterEpochsResult = deepcopy(directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result)\n",
    "active_filter_epochs_decoder_result.filter_epochs.epochs.find_data_indicies_from_epoch_times(np.atleast_1d(clicked_epoch[0]))\n",
    "\n",
    "# active_filter_epochs_decoder_result.all_directional_ripple_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72e64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import save_marginals_arrays_as_image\n",
    "\n",
    "PosteriorExporting.save_marginals_arrays_as_image(directional_merged_decoders_result=directional_merged_decoders_result, parent_array_as_image_output_folder=parent_array_as_image_output_folder, epoch_id_identifier_str='ripple', epoch_ids=[31])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf1be5",
   "metadata": {},
   "source": [
    "# 2024-09-16 - LxC and SxC\n",
    "- [ ] Unfortunately the manually selected LxCs/SxCs do not match those computed based on thresholds for firing rate differences, albiet with both laps and replays included. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74958a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import compute_spatial_information\n",
    "\n",
    "global_spikes_df: pd.DataFrame = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].spikes_df).drop(columns=['neuron_type'], inplace=False)\n",
    "an_active_pf = deepcopy(global_pf1D)\n",
    "spatial_information, all_spikes_df, epoch_averaged_activity_per_pos_bin, global_all_spikes_counts = compute_spatial_information(all_spikes_df=global_spikes_df, an_active_pf=an_active_pf, global_session_duration=global_session.duration)\n",
    "spatial_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e526371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_averaged_activity_per_pos_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ebf158",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_laps_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b38de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_laps\n",
    "long_laps\n",
    "short_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d5a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute number of spikes in each epoch\n",
    "long_pf1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943db46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import add_spikes_df_placefield_inclusion_columns\n",
    "\n",
    "\n",
    "# BayesianPlacemapPositionDecoder: long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder\n",
    "# long_LR_pf1D_Decoder\n",
    "# long_RL_pf1D_Decoder\n",
    "# short_LR_pf1D_Decoder\n",
    "# short_RL_pf1D_Decoder\n",
    "\n",
    "# PfND: long_pf1D, short_pf1D\n",
    "# long_pf1D\n",
    "# short_pf1D\n",
    "\n",
    "# @function_attributes(short_name=None, tags=['long_short', 'firing_rate'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2024-09-17 05:22', related_items=[])\n",
    "def compute_all_cells_long_short_firing_rate_df(global_spikes_df: pd.DataFrame):\n",
    "    \"\"\" computes the firing rates for all cells (not just placecells or excitatory cells) for the long and short track periods, and then their differences\n",
    "    These firing rates are not spatially binned because they aren't just place cells.\n",
    "    \n",
    "    columns: ['LS_diff_firing_rate_Hz']: will be positive for Short-preferring cells and negative for Long-preferring ones.\n",
    "    \n",
    "    \"\"\"\n",
    "    ## Needs to consider not only place cells but interneurons as well\n",
    "    # global_all_spikes_counts # 73 rows\n",
    "    # global_spikes_df.aclu.unique() # 108\n",
    "\n",
    "    ## Split into the pre- and post- delta epochs\n",
    "    # global_spikes_df['t_rel_seconds']\n",
    "    # global_spikes_df\n",
    "\n",
    "    # is_theta, is_ripple, maze_id, maze_relative_lap\n",
    "\n",
    "    ## Split on 'maze_id'\n",
    "    # partition\n",
    "\n",
    "    from pyphocorehelpers.indexing_helpers import partition_df, reorder_columns_relative\n",
    "\n",
    "    ## INPUTS: global_spikes_df\n",
    "\n",
    "    ## Compute effective epoch duration by finding the earliest and latest spike in epoch.\n",
    "    def _add_firing_rates_from_computed_durations(a_df: pd.DataFrame):\n",
    "        spike_times = a_df['t_rel_seconds'].values\n",
    "        end_t = np.nanmax(spike_times)\n",
    "        start_t = np.nanmin(spike_times)\n",
    "        duration_t: float = end_t - start_t    \n",
    "        return duration_t, (start_t, end_t)\n",
    "\n",
    "\n",
    "    partitioned_dfs = dict(zip(*partition_df(global_spikes_df, partitionColumn='maze_id'))) # non-maze is also an option, right?\n",
    "    long_all_spikes_df: pd.DataFrame = partitioned_dfs[1]\n",
    "    short_all_spikes_df: pd.DataFrame = partitioned_dfs[2]\n",
    "    \n",
    "    ## sum total number of spikes over the entire duration\n",
    "    # Performed 1 aggregation grouped on column: 'aclu'\n",
    "    long_all_spikes_count_df = long_all_spikes_df.groupby(['aclu']).agg(num_spikes_count=('t_rel_seconds', 'count')).reset_index()[['aclu', 'num_spikes_count']].set_index('aclu')\n",
    "    # Performed 1 aggregation grouped on column: 'aclu'\n",
    "    short_all_spikes_count_df = short_all_spikes_df.groupby(['aclu']).agg(num_spikes_count=('t_rel_seconds', 'count')).reset_index()[['aclu', 'num_spikes_count']].set_index('aclu')\n",
    "\n",
    "    ## TODO: exclude replay periods\n",
    "\n",
    "    ## OUTPUTS: long_all_spikes_count_df, short_all_spikes_count_df\n",
    "        \n",
    "    long_duration_t, _long_start_end_tuple = _add_firing_rates_from_computed_durations(long_all_spikes_df)\n",
    "    long_all_spikes_count_df['firing_rate_Hz'] = long_all_spikes_count_df['num_spikes_count'] / long_duration_t\n",
    "\n",
    "    short_duration_t, _short_start_end_tuple = _add_firing_rates_from_computed_durations(short_all_spikes_df)\n",
    "    short_all_spikes_count_df['firing_rate_Hz'] = short_all_spikes_count_df['num_spikes_count'] / short_duration_t\n",
    "\n",
    "    global_duration_t: float = long_duration_t + short_duration_t\n",
    "    \n",
    "    ## OUTPUTS: long_all_spikes_count_df, short_all_spikes_count_df\n",
    "\n",
    "    # long_all_spikes_count_df\n",
    "    # short_all_spikes_count_df\n",
    "\n",
    "    # Performed 2 aggregations grouped on column: 't_rel_seconds'\n",
    "    # long_all_spikes_df[['t_rel_seconds']].agg(t_rel_seconds_min=('t_rel_seconds', 'min'), t_rel_seconds_max=('t_rel_seconds', 'max')).reset_index()\n",
    "\n",
    "    # short_all_spikes_df[['t_rel_seconds']].agg(t_rel_seconds_min=('t_rel_seconds', 'min'), t_rel_seconds_max=('t_rel_seconds', 'max')).reset_index()\n",
    "    # long_all_spikes_df = long_all_spikes_df.groupby(['t_rel_seconds']).agg(t_rel_seconds_min=('t_rel_seconds', 'min'), t_rel_seconds_max=('t_rel_seconds', 'max')).reset_index()\n",
    "\n",
    "    # Add prefixes to column names\n",
    "    df1_prefixed = long_all_spikes_count_df.add_prefix(\"long_\")\n",
    "    df2_prefixed = short_all_spikes_count_df.add_prefix(\"short_\")\n",
    "\n",
    "    # Combine along the index\n",
    "    df_combined = pd.concat([df1_prefixed, df2_prefixed], axis=1)\n",
    "\n",
    "    ## Move the \"height\" columns to the end\n",
    "    # df_combined = reorder_columns_relative(df_combined, column_names=list(filter(lambda column: column.endswith('_firing_rate_Hz'), existing_columns)), relative_mode='end')\n",
    "    # df_combined = reorder_columns_relative(df_combined, column_names=['long_firing_rate_Hz', 'short_firing_rate_Hz'], relative_mode='end')\n",
    "\n",
    "    df_combined = reorder_columns_relative(df_combined, column_names=['long_num_spikes_count', 'short_num_spikes_count', 'long_firing_rate_Hz', 'short_firing_rate_Hz'], relative_mode='end')\n",
    "    \n",
    "    # ['long_firing_rate_Hz', 'short_firing_rate_Hz', 'long_num_spikes_count', 'short_num_spikes_count', 'LS_diff_firing_rate_Hz', 'firing_rate_percent_diff']\n",
    "        \n",
    "    ## Compare the differnece between the two periods\n",
    "    df_combined['LS_diff_firing_rate_Hz'] = df_combined['long_firing_rate_Hz'] - df_combined['short_firing_rate_Hz']\n",
    "    \n",
    "    # Calculate the percent difference in firing rate\n",
    "    df_combined[\"firing_rate_percent_diff\"] = (df_combined['LS_diff_firing_rate_Hz'] / df_combined[\"long_firing_rate_Hz\"]) * 100\n",
    "\n",
    "    df_combined['global_num_spikes_count'] = df_combined['long_num_spikes_count'] + df_combined['short_num_spikes_count']\n",
    "    df_combined['global_firing_rate_Hz'] = df_combined['global_num_spikes_count'] / global_duration_t\n",
    "    \n",
    "    df_combined = reorder_columns_relative(df_combined, column_names=['long_num_spikes_count', 'short_num_spikes_count', 'global_num_spikes_count', 'long_firing_rate_Hz', 'short_firing_rate_Hz', 'global_firing_rate_Hz'], relative_mode='start')\\\n",
    "        \n",
    "        \n",
    "    # df_combined[\"long_num_spikes_percent\"] = (df_combined['long_num_spikes_count'] / df_combined[\"global_num_spikes_count\"]) * 100\n",
    "    # df_combined[\"short_num_spikes_percent\"] = (df_combined['short_num_spikes_count'] / df_combined[\"global_num_spikes_count\"]) * 100\n",
    "    \n",
    "    # df_combined[\"firing_rate_percent_diff\"] = (df_combined['LS_diff_firing_rate_Hz'] / df_combined[\"long_firing_rate_Hz\"]) * 100\n",
    "    \n",
    "    \n",
    "    return df_combined\n",
    "\n",
    "df_combined = compute_all_cells_long_short_firing_rate_df(global_spikes_df=global_spikes_df)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b98f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df_combined.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rate_required_diff_Hz: float = 1.0 # minimum difference required for a cell to be considered Long- or Short-\"preferring\"\n",
    "maximum_opposite_period_firing_rate_Hz: float = 1.0 # maximum allowed firing rate in the opposite period to be considered exclusive\n",
    "\n",
    "# Sort by column: 'LS_diff_firing_rate_Hz' (ascending)\n",
    "df_combined = df_combined.sort_values(['LS_diff_firing_rate_Hz'])\n",
    "# df_combined = df_combined.sort_values(['firing_rate_percent_diff'])\n",
    "df_combined\n",
    "\n",
    "# df_combined['LS_diff_firing_rate_Hz']\n",
    "\n",
    "# df_combined['firing_rate_percent_diff']\n",
    "\n",
    "LpC_df = df_combined[df_combined['LS_diff_firing_rate_Hz'] > firing_rate_required_diff_Hz]\n",
    "SpC_df = df_combined[df_combined['LS_diff_firing_rate_Hz'] < -firing_rate_required_diff_Hz]\n",
    "\n",
    "LxC_df = LpC_df[LpC_df['short_firing_rate_Hz'] <= maximum_opposite_period_firing_rate_Hz]\n",
    "SxC_df = SpC_df[SpC_df['long_firing_rate_Hz'] <= maximum_opposite_period_firing_rate_Hz]\n",
    "\n",
    "\n",
    "## Let's consider +/- 50% diff XxC cells\n",
    "# LpC_df = df_combined[df_combined['firing_rate_percent_diff'] > 50.0]\n",
    "# SpC_df = df_combined[df_combined['firing_rate_percent_diff'] < -50.0]\n",
    "\n",
    "## Extract the aclus\"\n",
    "LpC_aclus = LpC_df.index.values\n",
    "SpC_aclus = SpC_df.index.values\n",
    "\n",
    "print(f'LpC_aclus: {LpC_aclus}')\n",
    "print(f'SpC_aclus: {SpC_aclus}')\n",
    "\n",
    "LxC_aclus = LxC_df.index.values\n",
    "SxC_aclus = SxC_df.index.values\n",
    "\n",
    "print(f'LxC_aclus: {LxC_aclus}')\n",
    "print(f'SxC_aclus: {SxC_aclus}')\n",
    "\n",
    "## OUTPUTS: LpC_aclus, SpC_aclus, LxC_aclus, SxC_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e781fbf",
   "metadata": {},
   "source": [
    "### User Hand-Selected LxCs and SxCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager, SessionCellExclusivityRecord\n",
    "\n",
    "## Extract from manual user-annotations:\n",
    "session_cell_exclusivity_annotations: Dict[IdentifyingContext, SessionCellExclusivityRecord] = UserAnnotationsManager.get_hardcoded_specific_session_cell_exclusivity_annotations_dict()\n",
    "curr_session_cell_exclusivity_annotation: SessionCellExclusivityRecord = session_cell_exclusivity_annotations[curr_context] # SessionCellExclusivityRecord(LxC=[109], LpC=[], Others=[], SpC=[67, 52], SxC=[23, 4, 58])\n",
    "\n",
    "df_SxC = df_combined[np.isin(df_combined.index, curr_session_cell_exclusivity_annotation.SxC)]\n",
    "df_SpC = df_combined[np.isin(df_combined.index, curr_session_cell_exclusivity_annotation.SpC)]\n",
    "df_LxC = df_combined[np.isin(df_combined.index, curr_session_cell_exclusivity_annotation.LxC)]\n",
    "df_LpC = df_combined[np.isin(df_combined.index, curr_session_cell_exclusivity_annotation.LpC)]\n",
    "\n",
    "df_SxC\n",
    "df_SpC\n",
    "df_LxC\n",
    "df_LpC\n",
    "\n",
    "# [23,4,58]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed89ab",
   "metadata": {},
   "source": [
    "# PhoJonathanPlotHelpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223fa610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.neuron_identities import NeuronIdentityDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import LongShortTrackComparingDisplayFunctions, PhoJonathanPlotHelpers\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', active_identifying_session_ctx) # MatplotlibRenderPlots\n",
    "# graphics_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d4fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_print = True\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Batch Output of Figures                                                                                              #\n",
    "# ==================================================================================================================== #\n",
    "## 🗨️🟢 2022-11-05 - Pho-Jonathan Batch Outputs of Firing Rate Figures\n",
    "# %matplotlib qt\n",
    "short_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.RIGHT_ONLY]\n",
    "short_only_aclus = short_only_df.index.values.tolist()\n",
    "long_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.LEFT_ONLY]\n",
    "long_only_aclus = long_only_df.index.values.tolist()\n",
    "shared_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.SHARED]\n",
    "shared_aclus = shared_df.index.values.tolist()\n",
    "if debug_print:\n",
    "    print(f'shared_aclus: {shared_aclus}')\n",
    "    print(f'long_only_aclus: {long_only_aclus}')\n",
    "    print(f'short_only_aclus: {short_only_aclus}')\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'    \n",
    "## MODE: this mode creates a special folder to contain the outputs for this session.\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Output Figures to File                                                                                               #\n",
    "# ==================================================================================================================== #\n",
    "active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, n_max_page_rows=10)\n",
    "\n",
    "# /home/halechr/repos/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2024-09-24/kdiba/vvp01/two/2006-4-17_12-52-15/BatchPhoJonathanReplayFRC_shared_4of4_(39,41,42).png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2113cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "jonathan_firing_rate_analysis_result = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.2)\n",
    "## all cells:\n",
    "fig_1c_figures_all_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=None, n_max_page_rows=20, write_vector_format=False, write_png=True, show_only_refined_cells=False, disable_top_row=False)\n",
    "# fig_1c_figures_all_dict\n",
    "\n",
    "\n",
    "## find the output figures from the `curr_active_pipeline.registered_output_files`\n",
    "_found_contexts_dict: Dict[IdentifyingContext, Path] = {}\n",
    "for a_figure_path, an_output_dict in curr_active_pipeline.registered_output_files.items():\n",
    "    a_ctxt = an_output_dict['context']\n",
    "    _found_contexts_dict[a_ctxt] = a_figure_path\n",
    "\n",
    "\n",
    "relevant_figures_dict: Dict[IdentifyingContext, Path] = IdentifyingContext.matching(_found_contexts_dict, criteria={'display_fn_name': 'BatchPhoJonathanReplayFRC'})\n",
    "relevant_figures_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b3270",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1c_figures_all_dict\n",
    "\n",
    "# print_keys_if_possible('registered_output_files', curr_active_pipeline.registered_output_files, max_depth=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc90f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:active_out_figures_dict[k] for k in relevant_figures_dict.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ba646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "# PhoJonathan Results:\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "jonathan_firing_rate_analysis_result = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.2)\n",
    "## all cells:\n",
    "fig_1c_figures_all_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=LpC_aclus, n_max_page_rows=20, write_vector_format=False, write_png=False, show_only_refined_cells=False, disable_top_row=False, split_by_short_long_shared=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab2057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_spikes_df\n",
    "global_results.sess.spikes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b05b88",
   "metadata": {},
   "source": [
    "# Recover Session Parameters ( from `preprocessing_parameters`, default function kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c1453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.active_sess_config # 'preprocessing_parameters'\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import ParametersContainer\n",
    "\n",
    "# print_keys_if_possible('active_sess_config', curr_active_pipeline.active_sess_config, max_depth=4)\n",
    "\n",
    "\t# │   ├── preprocessing_parameters: neuropy.core.session.Formats.SessionSpecifications.ParametersContainer  = ParametersContainer(epoch_estimation_parameters=DynamicContainer({'laps': DynamicContainer({'N': 20, 'should_backup_extant_laps_obj': True, 'use_direction_dependent_laps': True}), 'PBEs': DynamicContainer({'thresh': (0, 1.5), 'min_dur': 0.03, 'merge_dur': 0.1, 'max_dur': 0.6})...\n",
    "\t# \t│   ├── epoch_estimation_parameters: neuropy.utils.dynamic_container.DynamicContainer  = DynamicContainer({'laps': DynamicContainer({'N': 20, 'should_backup_extant_laps_obj': True, 'use_direction_dependent_laps': True}), 'PBEs': DynamicContainer({'thresh': (0, 1.5), 'min_dur': 0.03, 'merge_dur': 0.1, 'max_dur': 0.6}), 'replays': DynamicContainer({'require_intersec...\n",
    "\t# \t\t│   ├── laps: neuropy.utils.dynamic_container.DynamicContainer  = DynamicContainer({'N': 20, 'should_backup_extant_laps_obj': True, 'use_direction_dependent_laps': True})\n",
    "\t# \t\t\t│   ├── N: int  = 20\n",
    "\t# \t\t\t│   ├── should_backup_extant_laps_obj: bool  = True\n",
    "\t# \t\t\t│   ├── use_direction_dependent_laps: bool  = True\n",
    "\t# \t\t│   ├── PBEs: neuropy.utils.dynamic_container.DynamicContainer  = DynamicContainer({'thresh': (0, 1.5), 'min_dur': 0.03, 'merge_dur': 0.1, 'max_dur': 0.6})\n",
    "\t# \t\t\t│   ├── thresh: tuple  = (0, 1.5) - (2,)\n",
    "\t# \t\t\t│   ├── min_dur: float  = 0.03\n",
    "\t# \t\t\t│   ├── merge_dur: float  = 0.1\n",
    "\t# \t\t\t│   ├── max_dur: float  = 0.6\n",
    "\t# \t\t│   ├── replays: neuropy.utils.dynamic_container.DynamicContainer  = DynamicContainer({'require_intersecting_epoch': 85 epochs<br>array([[-inf, 10.578],<br>       [13.1822, 18.7536],<br>       [21.4567, 32.9346],<br>       [35.6037, 35.6373],<br>       [41.2429, 46.6152],<br>       [49.9527, 52.5542],<br>       [56.4928, 59.9956],<br>       [62...\n",
    "\t# \t\t\t│   ├── require_intersecting_epoch: neuropy.core.epoch.Epoch  = 85 epochs<br>array([[-inf, 10.578],<br>       [13.1822, 18.7536],<br>       [21.4567, 32.9346],<br>       [35.6037, 35.6373],<br>       [41.2429, 46.6152],<br>       [49.9527, 52.5542],<br>       [56.4928, 59.9956],<br>       [62.5318, 67.8689],<br>       [73.1757, 75.2434],<b...\n",
    "\t# \t\t\t│   ├── min_epoch_included_duration: float  = 0.06\n",
    "\t# \t\t\t│   ├── max_epoch_included_duration: float  = 0.6\n",
    "\t# \t\t\t│   ├── maximum_speed_thresh: NoneType  = None\n",
    "\t# \t\t\t│   ├── min_inclusion_fr_active_thresh: float  = 1.0\n",
    "\t# \t\t\t│   ├── min_num_unique_aclu_inclusions: int  = 5\n",
    "\n",
    "\n",
    "preprocessing_parameters: ParametersContainer = deepcopy(curr_active_pipeline.active_sess_config)\n",
    "preprocessing_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.registered_global_computation_function_docs_dict\n",
    "# curr_active_pipeline.registered_merged_computation_function_dict\n",
    "from benedict import benedict\n",
    "import neuropy.utils.type_aliases as types\n",
    "from pyphocorehelpers.function_helpers import get_fn_kwargs_with_defaults\n",
    "\n",
    "ignore_kwarg_names = ['include_includelist', 'debug_print']\n",
    "registered_merged_computation_function_default_kwargs_dict = {fn_best_name(v):get_fn_kwargs_with_defaults(v, ignore_kwarg_names=ignore_kwarg_names) for k, v in curr_active_pipeline.registered_merged_computation_function_dict.items()}\n",
    "registered_merged_computation_function_default_kwargs_dict = {k:v for k, v in registered_merged_computation_function_default_kwargs_dict.items() if len(v)>0} # filter empty lists\n",
    "registered_merged_computation_function_default_kwargs_dict\n",
    "# print(get_kwargs_with_defaults(example_function))\n",
    "\n",
    "{'computation_params': registered_merged_computation_function_default_kwargs_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56920dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.function_helpers import get_decorated_function_attributes\n",
    "from pyphocorehelpers.function_helpers import fn_best_name\n",
    "\n",
    "\n",
    "{k:fn_best_name(v) for k, v in curr_active_pipeline.registered_merged_computation_function_dict.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a530ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_merged_computation_function_default_kwargs_dict['computation_params._build_merged_directional_placefields']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ec4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf6ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import benedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb52bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import benedict.core\n",
    "\n",
    "\n",
    "benedict.core.flatten("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becec465",
   "metadata": {},
   "outputs": [],
   "source": [
    "_curr_epoch_config_dict: Dict[types.DecoderName, Dict] = {k:benedict(deepcopy(v.computation_config).to_dict()) for k, v in curr_active_pipeline.computation_results.items()}\n",
    "_curr_epoch_config_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9683fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
